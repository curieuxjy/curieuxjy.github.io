---
title: "ğŸ“ƒGN-Block"
description: Graph Networks as Learnable Physics Engines for Inference and Control
date: "2022-08-07"
categories: [gnn, system identification, mpc, rl, paper]
toc: true
execute:
  freeze: auto 
---


ì´ë²ˆ postëŠ” [Graph Networks as Learnable Physics Engines for Inference and Control](https://arxiv.org/abs/1806.01242) ë¼ëŠ” ë…¼ë¬¸ì„ ì½ê³  ë¦¬ë·°í•œ ë‚´ìš©ì…ë‹ˆë‹¤.

# Abstract

> Understanding and interacting with everyday physical scenes requires rich knowledge about the structure of the world, represented either implicitly in a value or policy function, or explicitly in a transition model. Here we introduce a new class of learnable modelsâ€”`based on graph networksâ€”which implement an inductive bias` for object- and relation-centric representations of complex, dynamical systems. Our results show that as a `forward model`, our approach supports accurate predictions from real and simulated data, and surprisingly strong and efficient generalization, across eight distinct physical systems which we varied parametrically and structurally. We also found that our `inference model` can perform system identification. Our models are also `differentiable, and support online planning via gradient-based trajectory optimization`, as well as `offline policy optimization`. Our framework offers new opportunities for harnessing and exploiting rich knowledge about the world and takes a key step toward building machines with `more human-like representations of the world`.
> 

# 1. Introduction

ì‚¬ëŒì€ ê±¸ì„ë•Œ ë§ˆì°°ë ¥, ì‘ìš© ë°˜ì‘ìš© ë²•ì¹™ì„ ìƒê°í•˜ë©´ì„œ ê±·ì§€ ì•ŠìŠµë‹ˆë‹¤. ë§ì€ ë¬¼ë¦¬ ë¬¸ì œë“¤ê³¼ ë²•ì¹™ë“¤ì„ ì´í•´í•˜ê¸° ì–´ë µì§€ë§Œ ë³µì¡í•œ ë¬¼ë¦¬ì  ì‘ìš©ë“¤ì´ ì¼ì–´ë‚˜ëŠ” ê±·ëŠ” í–‰ë™ì— ìˆì–´ì„œ ì–´ë ¤ì›€ì´ ì—†ìŠµë‹ˆë‹¤. ì‚¬ì‹¤ ì‚¬ëŒì´ íƒœì–´ë‚˜ì„œ ìˆ˜ì—†ì´ ë§ì€ ê²½í—˜ë“¤ì˜ ëˆ„ì ìœ¼ë¡œ ìš°ë¦¬ëŠ” í¬ê²Œ ì‹ ê²½ì“°ì§€ ì•Šì•„ë„ ì–´ë–»ê²Œ í˜ì„ ì£¼ë©´ ë‹¤ë¦¬ê°€ ì›€ì§ì´ëŠ” ì§€ ì•Œê³ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ì´ì²˜ëŸ¼ ì¸ê³µì§€ëŠ¥ë„ *ì–´ë–»ê²Œ í•˜ë©´ ë³µì¡í•œ ì‹œìŠ¤í…œì„ ì´í•´í•˜ê³  ì˜ ì‘ë™í•  ìˆ˜ ìˆì„ê¹Œ?* ë¼ëŠ” ë¬¼ìŒì„ **GN-Block**ì´ë¼ëŠ” Graph ì•„ì´ë””ì–´ë¡œ í•´ê²°í•  ìˆ˜ ìˆë‹¤ê³  ì£¼ì¥í•˜ëŠ” ë…¼ë¬¸ì…ë‹ˆë‹¤.

<aside>
â“ How can an intelligent agent understand and control such complex systems?
</aside>

ì¸ê³µì§€ëŠ¥ì´ ì´ë ‡ê²Œ ì‚¬ëŒì´ ìì—°ìŠ¤ëŸ½ê²Œ ìµíˆëŠ” ì„¸ìƒì˜ ë¬¼ë¦¬ì ì¸ í˜„ìƒì„ ì´í•´í•˜ê³  ìƒí˜¸ì‘ìš© ì‘ìš©í•˜ë ¤ë©´  ì•”ì‹œì ì´ë“  ëª…ì‹œì ìœ¼ë¡œë“  ì„¸ê³„ì— ëŒ€í•œ í’ë¶€í•œ(rich) í‘œí˜„ê³¼ ì§€ì‹ì´ í•„ìš”í•©ë‹ˆë‹¤. ë‹¤ì‹œ ë§í•´, ì‹œìŠ¤í…œì— ìˆëŠ” objectsë“¤ê³¼ objectsê°„ì˜ ê´€ê³„ë¥¼ í‘œí˜„í•´ì„œ ë™ì¼ objectì—ëŠ” ë™ì¼í•œ **object-wiseí•œ ê³„ì‚°**ì„, ì´ë“¤ ì‚¬ì´ì— ì¼ì–´ë‚˜ëŠ” interationë“¤ì— ëŒ€í•´ì„œëŠ” **relation-wise ê³„ì‚°**ì„ ì ìš©í•´ì„œ í•™ìŠµì„ í•  ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤. ë§ˆì¹˜ ë ˆê³  ë¸”ëŸ­ë“¤ í•˜ë‚˜í•˜ë‚˜ë¥¼ ì´í•´í•˜ê³  ì–´ë–»ê²Œ í•˜ë©´ ì„±ì„ ìŒ“ì„ ìˆ˜ ìˆëŠ”ì§€ ì•„ëŠ” ê²ƒì²˜ëŸ¼ `combinatorial generalization` ëŠ¥ë ¥ì„ ê°€ì§ˆ ìˆ˜ ìˆëŠ” ê²ƒì´ë¼ê³  ìƒê°í•´ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

í•´ë‹¹ ë…¼ë¬¸ì˜ ëª©í‘œëŠ” **physical dynamics modelsì„ ê·¸ë˜í”„ ê¸°ë°˜ì˜ ë°©ë²•ìœ¼ë¡œ í•™ìŠµ**í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. Graph Neural Network(GN)ì˜ `node update function`ì„ ê°€ì§€ê³  bodyì˜ dynamicsì— ëŒ€í•œ í•™ìŠµì„ í•  ìˆ˜ ìˆê³ , `edge update function`ì„ ê°€ì§€ê³  interactionì˜ dynamicsë¥¼ ì¸ì½”ë”©í•  ìˆ˜ ìˆìœ¼ë©°, `global update function`ì„ ê°€ì§€ê³  global systemì˜ ì†ì„±ë“¤ì„ ì¸ì½”ë”© í•  ìˆ˜ ìˆë‹¤ê³  ì£¼ì¥í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œ ë‹¤ë¥¸ ë…¼ë¬¸ë“¤ê³¼ ë‹¤ë¥´ê²Œ íŠ¹ì´í•œ ì ì€ globalí•œ ì‹œìŠ¤í…œì˜ ì†ì„±ì´ë¼ëŠ” ë¶€ë¶„ì„ ë”°ë¡œ ê³ ë ¤ë¥¼ í–ˆë‹¤ëŠ” ì ì´ë¼ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ë…¼ë¬¸ì˜ contributionì€ í¬ê²Œ 3ê°€ì§€ forward model, inference model, control algorithm ì…ë‹ˆë‹¤. (í•˜ì§€ë§Œ ë¦¬ë·°í•˜ë©´ì„œ ëŠë‚€ ì ì€ *control algorithm* ë¶€ë¶„ì€ contributionì´ë¼ê³  í•˜ê¸°ë³´ë‹¤ëŠ” GN-based modelì„ ê°€ì§€ê³  control pipelineì„ ì˜ ë¶™ì¸ ê²ƒì´ë¼ê³  ìƒê°ë©ë‹ˆë‹¤.) ë‹¤ë¥¸ physics engineë“¤ê³¼ ë‹¤ë¥´ê²Œ ë¬¼ë¦¬ë²•ì¹™ì— ëŒ€í•œ ì‚¬ì „ ì§€ì‹(prior knowledge)ì„ ì „í˜€ ê°€ì •í•˜ì§€ ì•Šì§€ë§Œ ëŒ€ì‹  `object- and relation-centric inductive bias`ë¥¼ ì´ìš©í•˜ì—¬ **current-state/next-state pairs**ì— ëŒ€í•œ í•™ìŠµì„ í•©ë‹ˆë‹¤. ê·¸ë˜í”„ ê¸°ë°˜ìœ¼ë¡œ ë¬¼ë¦¬ ì‹œìŠ¤í…œì„ forward modelê³¼ inference modelì´ í•™ìŠµí•˜ê²Œ ë˜ë©´ control algorithmì€ ì´ ëª¨ë¸ë“¤ì„ ì´ìš©í•˜ì—¬ planningì´ë‚˜ policy learningì„ í•˜ê²Œ ë©ë‹ˆë‹¤.

|Model|Role|
|-|-|
|GN-based forward models|ì •í™•í•˜ê³  ì¼ë°˜í™”ëœ predictionì„ í•  ìˆ˜ ìˆìŒ|
|GN-based inference models|observationì— ìˆ¨ê²¨ì ¸ ìˆëŠ” ì†ì„±ë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ system identificationì„ í•  ìˆ˜ ìˆìŒ|
|NOT GN-based control algorithms|ë‹¤ë¥¸ ë² ì´ìŠ¤ë¼ì¸ë“¤ë³´ë‹¤ ì¢‹ì€ control í¼í¬ë¨¼ìŠ¤ë¥¼ ë³´ì—¬ì¤Œ|


# 2. Model

## Graph representation of a physical system

ë¬¼ë¦¬ì‹œìŠ¤í…œì„ ì–´ë–»ê²Œ ê·¸ë˜í”„ë¡œ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆëŠ”ì§€ ëª‡ê°€ì§€ ìš©ì–´ì™€ ìˆ˜ì‹ë“¤ì„ ì •ë¦¬í•´ë³´ê² ìŠµë‹ˆë‹¤.

- ë¬¼ë¦¬ ì‹œìŠ¤í…œì˜ bodyëŠ” ê·¸ë˜í”„ì˜ `node`ë¡œ í‘œí˜„í•©ë‹ˆë‹¤.
- ë¬¼ë¦¬ ì‹œìŠ¤í…œì˜ jointëŠ” ê·¸ë˜í”„ì˜ `edge`ë¡œ í‘œí˜„í•©ë‹ˆë‹¤.
- ë¬¼ë¦¬ ì‹œìŠ¤í…œì˜ globalí•œ ì†ì„±ì€ `global feature`ë¡œ í‘œí˜„í•©ë‹ˆë‹¤.

ì•„ë˜ ì‚¬ì§„ì—ì„œ ë³´ì´ëŠ” half-cheetahì—ì„œ ì§ê´€ì ìœ¼ë¡œ ì–´ë–»ê²Œ ê·¸ë˜í”„ê°€ ê·¸ë ¤ì§ˆ ìˆ˜ ìˆëŠ”ì§€ ì•Œ ìˆ˜ ìˆê³  ì´ ê·¸ë˜í”„ë¥¼ $G$ë¡œ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

![](https://i.imgur.com/yN3GlTK.png?1){fig-align="default"}

ì•ì„œ ì„¤ëª…í•œ ë¶€ë¶„ì„ ìˆ˜ì‹ìœ¼ë¡œ ë‚˜íƒ€ë‚´ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

$$
G=\left(\mathbf{g},\left\{\mathbf{n}_{i}\right\}_{i=1 \cdots N_{n}},\left\{\mathbf{e}_{j}, s_{j}, r_{j}\right\}_{j=1 \cdots N_{e}}\right)
$$

    
- $g$ : global features ì‹œìŠ¤í…œì˜ ì¤‘ë ¥ì´ë‚˜ time stepê³¼ ê°™ì€ ì†ì„±ì„ ë‚˜íƒ€ë‚´ëŠ” ë²¡í„°ì…ë‹ˆë‹¤.
- $\mathbf{n}_{i}$ : node featuresë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë²¡í„°ì…ë‹ˆë‹¤.
- $\mathbf{e}_{j}$ : edge featuresë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë²¡í„°ì…ë‹ˆë‹¤.
- $s_{j}$ : ì´ edgeë¥¼ í†µí•´ì„œ messageë¥¼ ë³´ë‚´ëŠ” sender nodesì˜ ì¸ë±ìŠ¤ì…ë‹ˆë‹¤.
- $r_{j}$ : ì´ edgeë¥¼ í†µí•´ì„œ messageë¥¼ ë°›ëŠ” receiver nodesì˜ ì¸ë±ìŠ¤ì…ë‹ˆë‹¤.

## Static & Dynamic properties

ì—¬ê¸°ì„œ static graph $G_s$ì™€ dynamic graph $G_d$ ë¼ëŠ” ê·¸ë˜í”„ëŠ” 2ê°€ì§€ ì¢…ë¥˜ê°€ ìˆìŠµë‹ˆë‹¤. ì´ 2ê°œì˜ ê·¸ë˜í”„ëŠ” ê°ê° ì‹œìŠ¤í…œì˜ ì†ì„±ì´ ì‹œê°„ì— ë”°ë¼ ë³€í™”í•˜ëŠ”ì§€(dynamic/time-variant) ì•ˆí•˜ëŠ”ì§€(static/time-invaritant)ì— ë”°ë¼ ê·¸ë˜í”„ë¥¼ êµ¬ì„±í•˜ëŠ” ì •ë³´ì˜ ì¢…ë¥˜ê°€ ë‹¤ë¦…ë‹ˆë‹¤.(ìì„¸í•œ ì •ë³´ëŠ” Appendix G sectionì—ì„œ Mujoco ê¸°ë°˜ì˜ ì–´ë–¤ ì •ë³´ë¡œ ê° ê·¸ë˜í”„ë¥¼ êµ¬ì„±í–ˆëŠ”ì§€ ë‚˜ì™€ìˆìŠµë‹ˆë‹¤.)

- A static graph $G_s$: ì‹œìŠ¤í…œì˜ staticí•œ ì •ë³´ë¥¼ ê°€ì§€ê³  ìˆëŠ” ê·¸ë˜í”„
    - `global parameters`: the time step, viscosity, gravity, etc
    - `body/node parameters`: mass, inertia tensor, etc.
    - `joint/edge parameters`: joint typeê³¼ properties, motor type and properties, etc
- A dynamic graph $G_d$: ì‹œìŠ¤í…œì˜ ì¼ì‹œì ì¸ state ì •ë³´ë¥¼ ê°€ì§€ê³  ìˆëŠ” ê·¸ë˜í”„
    - `body/node`: 3D Cartesian position, 4D quaternion orientation, 3D linear velocity, 3D angular velocity
    - `joint/edge`: jointì— ì ìš©ëœ actionë“¤ì˜ í¬ê¸°

## Graph networks

- `graph2graph` ëª¨ë“ˆì„ í™œìš©í•˜ì—¬ ì¸í’‹ì„ ê·¸ë˜í”„ë¡œ ë°›ê³  ì•„ì›ƒí’‹ë„ ê·¸ë˜í”„ë¡œ ë°›ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤. ë”°ë¼ì„œ ì•„ì›ƒí’‹ì˜ ê·¸ë˜í”„ëŠ” ì¸í’‹ ê·¸ë˜í”„ì™€ ë‹¤ë¥¸ edge, node, global featuresë¥¼ ê°€ì§€ê²Œ ë©ë‹ˆë‹¤.

ë³¸ ë…¼ë¬¸ì˜ í•µì‹¬ ì•„ì´ë””ì–´ì¸ GN ë¸”ë¡ì˜ êµ¬ì¡°ì— ëŒ€í•´ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.
- A core GN block

    ![](https://i.imgur.com/3PffG3H.png?1){fig-align="default"}
    
    - 3ê°œì˜ sub function, MLPë¡œ ì´ë£¨ì–´ì ¸ ìˆìŠµë‹ˆë‹¤.
        - edge-wise $f_e$ : ëª¨ë“  edgeë“¤ì— ëŒ€í•œ updateë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.
        - node-wise $f_n$ : ëª¨ë“  nodeë“¤ì— ëŒ€í•œ updateë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.
        - global $f_g$ : ë§ˆì§€ë§‰ìœ¼ë¡œ global featureë“¤ì„ update í•©ë‹ˆë‹¤.

í•˜ë‚˜ì˜ feedforward GN passëŠ” ê·¸ë˜í”„ ìƒì—ì„œ message-passing ë‹¨ê³„ì˜ í•œ ìŠ¤í…ìœ¼ë¡œ ê°„ì£¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ GN-block ë‚´ì—ì„œì˜ ì•Œê³ ë¦¬ì¦˜ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤. 
        
![](https://i.imgur.com/TjghKvm.png?1){fig-align="default"}
        

## Forward models

Forward modelì˜ ëª©ì ì€ **í˜„ì¬ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒ stepì˜ ìƒíƒœë¥¼ ì˜ˆì¸¡(prediction)í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.** (ì´ëŠ” ì˜ì–´ ë‹¨ì–´ì˜ ë¹„ìŠ·í•œ ì˜ë¯¸ë•Œë¬¸ì— ë‹¤ìŒì— ë‚˜ì˜¤ëŠ” inference modelì˜ ëª©ì ê³¼ ë§ì´ í˜¼ë™ë  ìˆ˜ ìˆìœ¼ë‹ˆ ì˜ ì •ì˜í•˜ê³  ë„˜ì–´ê°€ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.) forward modelì€ *RNN(GRU)ë¥¼ ë„ì…í–ˆëŠ”ì§€ ì—¬ë¶€ì— ë”°ë¼* 2ê°€ì§€ íƒ€ì…ì´ ìˆìŠµë‹ˆë‹¤.

**Type1. GNN feed-forward**

![](https://i.imgur.com/2tN81Kd.png?1){fig-align="default"}

ê°€ì¥ ê°„ë‹¨í•œ GNN feed-forward ëª¨ë¸ì…ë‹ˆë‹¤. ê·¸ë˜í”„ëŠ” ì²˜ìŒì— $GN_1$ì„ ê±°ì³ latent graphì¸ $G'$ì´ ë©ë‹ˆë‹¤. ê·¸ë¦¬ê³  ë‹¤ìŒ $GN_2$ì˜ ì¸í’‹ìœ¼ë¡œëŠ” $GN_1$ì„ ê±°ì¹˜ê¸´ ì „ì˜ ê·¸ë˜í”„ì˜€ë˜ $G$ì™€ $G'$ë¥¼ concatenateë¥¼ í•´ì„œ ë„£ì–´ì£¼ê²Œ ë©ë‹ˆë‹¤. ì €ìë“¤ì€ ì´ë ‡ê²Œ ë””ìì¸í•œ ì´ìœ ë¡œ, ê·¸ë˜í”„ì˜ ëª¨ë“  ë…¸ë“œë“¤ê³¼ ì—£ì§€ë“¤ì´ ëª¨ë‘ communicateí•˜ê²Œ í•˜ê¸° ìœ„í•¨ì´ë¼ê³  ì´ì•¼ê¸°í•©ë‹ˆë‹¤. ì´ë ‡ê²Œ $GN_1$, $GN_2$ë¥¼ ê±°ì³ ìµœì¢…ì ìœ¼ë¡œ ë‚˜ì˜¤ëŠ” $G^*$ì˜ node featureë“¤ì´ ê° bodyì˜ ìƒíƒœ prediction ê°’ì´ ë˜ëŠ” ê²ƒ ì…ë‹ˆë‹¤.

**Type2. RNN+GNN**

![](https://i.imgur.com/7ZKlooE.png?1){fig-align="default"}

ë‹¤ìŒìœ¼ë¡œ ì•ì„œ ê¸°ë³¸ì´ ë˜ëŠ” ëª¨ë¸ì— G-GRUë¥¼ ì¶”ê°€í•œ íƒ€ì…ë‹ˆë‹¤. Type 1ê³¼ ë¹„ìŠ·í•˜ê²Œ skip connection, latent graphë¥¼ ëª¨ë‘ ì‚¬ìš©í•˜ëŠ”ë° GN blockì˜ GRU ë²„ì ¼ì¸ G-GRUê°€ ë“¤ì–´ê°€ë©´ì„œ $G_h$ë¼ëŠ” RNNì—ì„œ hidden vectorì™€ ê°™ì€ ê°œë…ì˜ hidden graphê°€ ì¶”ê°€ëœ ê²ƒì…ë‹ˆë‹¤. ëª¨ë“  edge, node, global featureë“¤ì— ëŒ€í•´ ê°ê° RNNì´ ì ìš©ë˜ì–´ ì´ 3ê°œì˜ RNN sub-modulesì´ ìˆìŠµë‹ˆë‹¤.

**ë‘ê°€ì§€ íƒ€ì…ì˜ GNN forward ëª¨ë¸ì— ê³µí†µì ì¸ ì‚¬í•­**

1. `state differences`ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì„ í•™ìŠµí•´ì„œ state predictionì˜ ì ˆëŒ“ê°’(absolute)ì„ ê³„ì‚°í•©ë‹ˆë‹¤. ì´ ê³„ì‚°ëœ absolute state predictionì„ ê°€ì§€ê³  stateë¥¼ updateí•˜ê²Œ ë˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

2. `long-range rollout` trajectoryë¥¼ ë§Œë“¤ì–´ë‚´ê¸° ìœ„í•´ì„œ state prediction ê°’ê³¼ control inputì„ ë°˜ë³µì ìœ¼ë¡œ modelì— ë„£ì–´ì£¼ì–´ì„œ ì—¬ëŸ¬ ìŠ¤í…ì˜ trajectoryë¥¼ ìƒì„±í•˜ê²Œ ë©ë‹ˆë‹¤.
 
3. GN modelì˜ ì¸í’‹ê³¼ ì•„ì›ƒí’‹ë“¤ì€ normalize ë©ë‹ˆë‹¤.

ì‚¬ì‹¤ ë¦¬ë·°ë¥¼ í•˜ë©´ì„œ forward modelê³¼ inference model ì‚¬ì´ì˜ êµ¬ë¶„ì´ë‚˜ ëª¨ë¸ì˜ êµ¬ì²´ì ì¸ í”„ë¡œì„¸ìŠ¤ ì´í•´ê°€ pseudo algorithmì„ ë³´ê¸° ì „ê¹Œì§€ ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Appendixì— ë‚˜ì™€ìˆì–´ì„œ ì˜ ë³´ì§€ ì•Šì„ í™•ë¥ ì´ ë†’ì§€ë§Œ ë…¼ë¬¸ì˜ ê°œë…ì„ ëŒ€ëµì ìœ¼ë¡œ ì´í•´í•˜ê³  ë‚œ í›„ì—ëŠ” ê¼­ line by lineìœ¼ë¡œ ë³´ì‹œê¸¸ ì¶”ì²œí•©ë‹ˆë‹¤.

ë¨¼ì € **forward modelì˜ í•™ìŠµê³¼ì •**ì„ ë³´ì—¬ì£¼ëŠ” pseudo algorithm ì…ë‹ˆë‹¤. ë‹¤ì‹œí•œë²ˆ ì´ ëª¨ë¸ì˜ ëª©ì ì„ ìƒê¸°ì‹œì¼œë³´ìë©´, í˜„ì¬ ìƒíƒœ $x^{t_0}$ ë¥¼ ê¸°ë°˜ìœ¼ë¡œ $a^{t_0}$ì™€ í•¨ê»˜ ì£¼ì–´ì¡Œì„ ë•Œ, $x^{t_0+1}$ì„ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì•ì„œ ì„¤ëª…í•œ ë¶€ë¶„ë“¤ì¸, stateì˜ ì”ì°¨ë¥¼ í•™ìŠµí•˜ëŠ” ë¶€ë¶„ì´ë‚˜ normalization ë“±ì´ ì•Œê³ ë¦¬ì¦˜ë‚´ì— ì˜ ë‚˜ì™€ìˆìŠµë‹ˆë‹¤.

![](https://i.imgur.com/Fzex7GV.png?1){fig-align="default"}

ë‹¤ìŒì€ **í•™ìŠµëœ forward model**ì„ ê°€ì§€ê³  ë‹¤ìŒ ìƒíƒœì¸ $x^{t_0+1}$ì„ ì–´ë–»ê²Œ ì˜ˆì¸¡í•˜ëŠ”ì§€ ë³´ì—¬ì£¼ëŠ” ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤.

![](https://i.imgur.com/ztG7ZuO.png?1){fig-align="default"}

ë§ˆì§€ë§‰ìœ¼ë¡œ ë°”ë¡œ ìœ„ ì•Œê³ ë¦¬ì¦˜ê³¼ ë™ì¼í•˜ê²Œ **í•™ìŠµëœ forward model**ì„ ê°€ì§€ê³  ë‹¤ìŒ ìƒíƒœì¸ $x^{t_0+1}$ì„ ì–´ë–»ê²Œ ì˜ˆì¸¡í•˜ëŠ”ì§€ ë³´ì—¬ì£¼ëŠ” ì•Œê³ ë¦¬ì¦˜ì´ì§€ë§Œ inference modelì—ì„œ í•™ìŠµëœ $GN_p$ë¥¼ ê°€ì§€ê³  `system identification`ì´ ì¶”ê°€ëœ ìƒíƒœì—ì„œ ì–´ë–»ê²Œ ì•Œê³ ë¦¬ì¦˜ì´ í˜ëŸ¬ê°€ëŠ”ì§€ ë³´ì—¬ì¤ë‹ˆë‹¤.(ì´ì „ì— ì•Œê³ ë¦¬ì¦˜ì—ì„œëŠ” system parameter $p$ë¼ê³  í‘œì‹œë˜ì—ˆë˜ ë¶€ë¶„ì´ ëŒ€ì²´ëœ ê²ƒì…ë‹ˆë‹¤.)

![](https://i.imgur.com/Snfkuwb.png?1){fig-align="default"}

## Inference Models

Inference modelì˜ ëª©ì ì„ í•œ ë§ˆë””ë¡œ í‘œí˜„í•˜ìë©´ `System identification`ì´ë¼ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. System identificationì´ë€ **ê´€ì°°í•  ìˆ˜ ì—†ëŠ”(unobserved) dynamic systemì˜ ì†ì„±ë“¤ì„ ê´€ì°°ë˜ëŠ”(observed) behavior(ë˜ëŠ” ì–´ë–¤ ì–‘ìƒ)ë¥¼ ê°€ì§€ê³  ì¶”ë¡ í•˜ëŠ” ê²ƒ**ì„ ë§í•©ë‹ˆë‹¤. ì¦‰ ì•”ì‹œì ìœ¼ë¡œ systemì„ êµ¬ì„±í•˜ëŠ” ìš”ì†Œë“¤ì„ (ëª…ì‹œì ì´ì§€ ì•Šì•„) ì¸¡ì •í•˜ê±°ë‚˜ ê´€ì°°í•  ìˆ˜ ì—†ì§€ë§Œ **latent representations**ì„ í†µí•´ ì¶”ë¡ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

![](https://i.imgur.com/4ZMFGU1.png?1){fig-align="default"}

Inference modelë„ **Recurrent GN-based model** ì…ë‹ˆë‹¤. forward ëª¨ë¸ê³¼ ë‹¤ë¥¸ ì ìœ¼ë¡œëŠ” ì˜¤ì§ trajectoryì˜ `dynamic states`ë“¤ë§Œ inputìœ¼ë¡œ ë°›ìŠµë‹ˆë‹¤. ë”°ë¼ì„œ dynamic state graphì¸ $G_d$ì™€ control inputì„ ë°›ìŠµë‹ˆë‹¤. ì•„ì›ƒí’‹ìœ¼ë¡œëŠ” ì¼ì • time step $T$ì´í›„ì˜ $G^*(T)$ì´ ë˜ë©°, ë³¸ ë…¼ë¬¸ì—ì„œ ì´í›„ ì‹¤í—˜íŒŒíŠ¸ì—ì„œ 20 stepì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.

**inference model í•™ìŠµê³¼ì •**ì˜ pseudo ì•Œê³ ë¦¬ì¦˜ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

![](https://i.imgur.com/0FeskwM.png){fig-align="default"}

## Control algorithm

control algorithmì—ì„œëŠ” ê·¸ë˜í”„ ê¸°ë°˜ì´ ì•„ë‹ˆê³  ì•ì„œ ì„¤ëª…í•œ ê·¸ë˜í”„ ê¸°ë°˜ì˜ forward modelê³¼ inference modelì„ ì˜ í™œìš©í•´ì„œ ì–´ë–»ê²Œ controlí•  ìˆ˜ ìˆì„ì§€ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” í¬ê²Œ 2ê°€ì§€ control algorithmì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤. ê°•í™”í•™ìŠµì„ ì£¼ë¡œ ì—°êµ¬í•˜ëŠ” ì…ì¥ì—ì„œ ë¦¬ë·°í•´ë³´ë©´, ëŒ€ë¶€ë¶„ ê°•í™”í•™ìŠµì€ model-free ê¸°ë°˜ì˜ ì•Œê³ ë¦¬ì¦˜ì´ ë§ì´ ë°œì „í–ˆëŠ”ë° GNê¸°ë°˜ì˜ ë‹¤ìŒ ìƒíƒœë¥¼ ì˜ˆì¸¡í•  ìˆ˜ ìˆëŠ” modelì„ ë§Œë“¦ìœ¼ë¡œì¨ model-based ê¸°ë°˜ì˜ ê°•í™”í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì„ ì ìš©í•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì´ ë§¤ìš° í¥ë¯¸ë¡œì› ìŠµë‹ˆë‹¤.

1. MPC(Model Predictive Control)
    
    GNì€ ë¯¸ë¶„ ê°€ëŠ¥í•˜ê¸° ë•Œë¬¸ì— MPCê°™ì€ **gradient-based trajectory optimization** ë°©ë²•ìœ¼ë¡œ model-based planningì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ëŒ€í‘œì ìœ¼ë¡œ MPCê°€ ìˆê³  í•™ìŠµê¸°ë°˜ì´ ì•„ë‹ˆë¼ ìµœì í™” ì•Œê³ ë¦¬ì¦˜ì´ë©° ì•Œê³ ë¦¬ì¦˜ì˜ íë¦„ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

    ![](https://i.imgur.com/4s443v3.png?1){fig-align="default"}
    
2. [SVG](https://proceedings.neurips.cc/paper/2015/hash/148510031349642de5ca0c544f31b2ef-Abstract.html)(Stochastic Value Gradients)
    
     ê°•í™”í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ ì¤‘ í•˜ë‚˜ì´ë©°, GN-based modelê³¼ SVGì˜ policy functionì„ ë™ì‹œì— í•™ìŠµí•˜ëŠ” agentë¡œ controlì„ í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. SVG(1)ì€ í•œ ìŠ¤í…ì„ ì˜ˆì¸¡í•˜ëŠ” GN modelì„ ê°€ì§€ê³  ê°•í™”í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ controlì„ í•œ ê²ƒì´ë©°(model-based) SVG(0)ì€ ì˜ˆì¸¡í•˜ëŠ” GN model ì—†ì´ model-free ê¸°ë°˜ìœ¼ë¡œ controlí•œ ê²ƒìœ¼ë¡œ ì´í•´í•˜ì‹œë©´ ë©ë‹ˆë‹¤.
    

> ì‚¬ì‹¤ MPCì™€ SVGëŠ” ë§¤ìš° ë¹„ìŠ·í•œ ì¸¡ë©´ì´ ìˆìŠµë‹ˆë‹¤.
> MPCì—ì„œëŠ” control inputsë“¤ì´ í•œ ì—í”¼ì†Œë“œì—ì„œ ì´ˆê¸° ì¡°ê±´ë“¤ì´ ì£¼ì–´ì¡Œì„ ë•Œ ìµœì í™” ë˜ëŠ” ê²ƒì´ë¼ë©´, SVGì—ì„œëŠ” stateì™€ controlì„ ë§¤ì¹­ì‹œí‚¤ëŠ” policy functionì´ í•™ìŠµê³¼ì •ì—ì„œ ê²½í—˜í•œ statesì— ëŒ€í•´ì„œ ìµœì í™” ë˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

# 3. Methods

<span style="color: blue">Environments</span>

- MuJoCo ì‹œë®¬ë ˆì´ì…˜ í™˜ê²½ì„ ì´ìš©í–ˆë‹¤.
    - Pendulum, Cartpole, Acrobot, Swimmer, Cheetah, Walker2d, JACO(robotic arm)
- generated training data for our forward models by applying simulated random controls to the systems, and recording the state transitions
- generalization and system identification ì‹¤í—˜ì„ ìœ„í•´ì„œ
    - created a dataset of versions of several of our systemsâ€”Pendulum, Cartpole, Swimmer, Cheetah and JACOâ€” with procedurally varied parameters and structure.
    - ë³€í™”ì‹œí‚¨ ì†ì„±ë“¤ë¡œëŠ” link lengths, body masses, and motor gears. + varied the number of links in the Swimmerâ€™s structure, from 3-15 (we refer to a swimmer with N links as SwimmerN )

<span style="color: blue">MPC planning</span>

- **N-step trajectory**(N: planning horizon)ì™€ ê·¸ trajectoryë¥¼ ì‹¤í–‰í–ˆì„ ë•Œ ë°›ì„ **total reward**ë¥¼ GN forward ëª¨ë¸ë¡œ ì˜ˆì¸¡í–ˆë‹¤.
- ì´ë•Œì˜ action sequences(=trajectory)ë“¤ì„ total rewardì˜ backpropagating gradientë¥¼ ê°€ì§€ê³  ìµœì í™”í•˜ê²Œ ëœë‹¤.

Model-based reinforcement learning

- GN-based modelì„ ê°•í™”í•™ìŠµì— ì ìš©í•´ë³´ë‹¤
- SVGë¥¼ ì´ìš©í–ˆë‹¤.
- GN forward modelì´ ë¯¸ë¶„ê°€ëŠ¥í•˜ê¸° ë•Œë¬¸ì— GN ëª¨ë¸ë¡œ ìƒì„±ëœ next stateë¥¼ ê°€ì§€ê³  expected return ê°’ì˜ ê·¸ë¼ë””ì–¸íŠ¸ë¥¼ êµ¬í•  ìˆ˜ ìˆë‹¤.
- 1 stepì„ ì˜ˆì¸¡í•˜ëŠ” SVG(1)ê³¼
- model-free RL ë² ì´ìŠ¤ë¼ì¸ê³¼ ë¹„êµí•˜ê¸° ìœ„í•´ SVG(0)ê³¼ deterministic policy ì•Œê³ ë¦¬ì¦˜ì¸ DDPG(Deep Deterministic Policy Gradients)ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í–ˆë‹¤.

<span style="color: blue">Baseline comparisons</span>

1. constant prediction baseline: input stateë¥¼ ê·¸ëŒ€ë¡œ output stateë¡œ ì‚¬ìš©
2. MLP baseline: GN modelì— ì“°ì¸ ë°ì´í„°ë¥¼ ê·¸ëŒ€ë¡œ MLPì— flattened & concatenated í•´ì„œ í•™ìŠµ
3. MPC baseline: ë¬¼ë¦¬ ëª¨ë¸ì„ ê°€ì§€ê³  Differential Dynamic Programming algorithmì„ ì‚¬ìš©í•´ì„œ ground truth ê°’ì„ ê°€ì§
4. SVG(0): model-free RL agents
5. DDPG: model-free RL agents

Prediction performance evaluation

- calculated independent errors for **position, orientation, linear velocity angular velocity**
1. squared one-step dynamic state differences (one-step error)
2. squared trajectory differences (rollout error) between the prediction and the ground truth.

# 4. Results

## Prediction

<span style="color: blue">Learning a **forward** model for a **single** system</span>

í•˜ë‚˜ì˜ ì‹œìŠ¤í…œì„ ê°€ì§€ê³  í•™ìŠµí•œ forward modelì˜ Prediction ì„±ëŠ¥ ì‚´í´ë³´ê¸°

- random controlë¡œ ë§Œë“¤ì–´ì§„ ë°ì´í„°ë“¤ì„ ê°€ì§€ê³  í•™ìŠµëœ GN-based model
    - **[Visually]** Swimmer6ì—ì„œ ê·¸ë¦¼ì—ì„œ ì²˜ëŸ¼ ground truthì™€ ì˜ˆì¸¡ ê²°ê³¼ê°€ êµ¬ë¶„ì´ ì•ˆ ê°ˆ ì •ë„ë¡œ í¡ì‚¬í•˜ë‹¤.([ì˜ìƒ](https://drive.google.com/file/d/1ez6sqCTZmHdSnf86lK6NEsnzyi-O25-B/view)ì—ì„œë„ ê±°ì˜ êµ¬ë¶„ì´ ì•ˆ ê°ˆ ì •ë„ë¡œ ì˜ ì˜ˆì¸¡í•˜ê³  ìˆìŒì„ ì•Œ ìˆ˜ ìˆë‹¤.)
        
        ![](https://i.imgur.com/N6bOymB.png?1){fig-align="default"}
        
    - **[Quantitatively]** 100 stepì—ì„œ 3ì¶• ë°©í–¥ìœ¼ë¡œì˜ ìœ„ì¹˜, ì„ ì†ë„, ê°ì†ë„, ì¿¼í„°ë‹ˆì•ˆ ë°©í–¥ ë¹„êµ
        
        ![](https://i.imgur.com/anOJrxE.png?1){fig-align="default"}
        
- constant prediction baselineì€ ì•„ì›ƒí’‹ìœ¼ë¡œ ì¸í’‹ì„ ê·¸ëŒ€ë¡œ ë³µì‚¬í•´ì„œ ì‚¬ìš©í–ˆê¸° ë•Œë¬¸ì— ì• ëŸ¬ ìµœëŒ€ì¹˜ë¡œ normalization í•˜ê¸° ìœ„í•´ ê²€ì€ìƒ‰ ì ì„ ìœ¼ë¡œ í‘œê¸°
- ìš°ì„  ê²€ì€ ì ì„ ê³¼ ë§‰ëŒ€ê¸°ë“¤ì„ ë­‰ëš±ê·¸ë ¤ì„œ ë³´ë©´,
- 1 stepê³¼ 100 stepì˜ rollout ê²°ê³¼ë¥¼ ë¹„êµí–ˆì„ ë•Œ ê²€ì€ ì ì„ ì— ë¹„í•´ íŒŒë€ìƒ‰ ë§‰ëŒ€ê¸°ë“¤ì˜ error ê°’ì´ ë‚®ìŒì„ ì•Œ ìˆ˜ ìˆë‹¤.
    
    ![](https://i.imgur.com/atKJKme.png?1){fig-align="default"}
    

- GN ëª¨ë¸ì´ MLP-based ë³´ë‹¤ ë” ë‚®ì€ ì• ëŸ¬ë¥¼ ê°€ì§€ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. ì´ëŠ” íŠ¹ë³„íˆ Swimmer6ì²˜ëŸ¼ ì—ì´ì „íŠ¸ì˜ êµ¬ì¡°ê°€ ë°˜ë³µì ì¸ ê²½ìš°ì— ë”ìš± ëˆˆì— ë„ê²Œ ë‚®ìŒì„ ì•Œ ìˆ˜ ìˆì—ˆë‹¤. ì´ë¥¼ í†µí•´ GN-based forward ëª¨ë¸ì´ ë‹¤ì–‘í•œ ë¬¼ë¦¬ ì‹œìŠ¤í…œë“¤ì—ì„œ dynamicsë¥¼ ì˜ ì˜ˆì¸¡í•¨ì„ ì•Œ ìˆ˜ ìˆë‹¤.

![](https://i.imgur.com/u7z0wJP.png?1){fig-align="default"}

- GNì´ MLPë³´ë‹¤ ë” generalizationì´ ì˜ ë¨ì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆëŠ”ë°, Swimmer6ë¥¼ ì§‘ì¤‘ì ìœ¼ë¡œ `train`, `valid`, `test` ë°ì´í„°ì— ëŒ€í•´ 1-step, rollout errorë¥¼ ê°ê° í™•ì¸í•´ë´¤ì„ ë•Œ, Best GNì˜ error ê°’ì´ Best MLPë³´ë‹¤ ë‚®ìŒì„ ì•Œ ìˆ˜ ìˆë‹¤. ë¿ë§Œ ì•„ë‹ˆë¼ test dataì˜ error ì¦ê°€ìœ¨ì„ ë´¤ì„ ë•Œì—ë„ GN ëª¨ë¸ì˜ test dataì˜ errorê°€ ë” ì ê²Œ ì¦ê°€í•¨ì„ ê´€ì°°í•  ìˆ˜ ìˆì—ˆê³  ì´ëŠ” agentì˜ bodiesì™€ jointsë“¤ì— ëŒ€í•œ inductive biasê°€ GNì„ í†µí•´ ì˜ í•™ìŠµë˜ì—ˆìŒì„ ì¦ëª…í•  ìˆ˜ ìˆë‹¤.

![](https://i.imgur.com/bMJJ6Jb.png?1){fig-align="default"}

Learning a forward model for **multiple** systems

í•œ ê°œì˜ ì‹œìŠ¤í…œì—ì„œì˜ forward modelì„ ì‚´í´ë³´ì•˜ìœ¼ë‹ˆ ì´ì œ ì—¬ëŸ¬ ì‹œìŠ¤í…œì—ì„œì˜ forward modelì˜ ì„±ëŠ¥ì„ ì‚´í´ë³´ì. GNì„ ì‚¬ìš©í•˜ë©´ ì—¬ëŸ¬ ì‹œìŠ¤í…œë“¤ì˜ ë‹¤ì–‘í•œ ë³€ìˆ˜ë“¤ë„ ì˜ ë‹¤ë£° ìˆ˜ ìˆë‹¤ëŠ” ê°€ì •ì´ ìˆì—ˆë‹¤. ì´ë¥¼ í™•ì¸í•˜ê¸° ìœ„í•´ ì—°ì†ì ìœ¼ë¡œ static parameterë“¤(ì§ˆëŸ‰, bodyì˜ ê¸¸ì´, jointì˜ ê°ë„ ë“±)ì„ ë°”ê¿”ê°€ë©´ì„œ forward dynamicsë¥¼ ì–´ë–»ê²Œ í•™ìŠµí•´ê°€ëŠ”ì§€ í™•ì¸í–ˆë‹¤.

![](https://i.imgur.com/pM4UKhs.png?1){fig-align="default"}

## Inference

## Control

# 5. Discussion

**Review**

> ë…¼ë¬¸ ë¦¬ë·°í›„ì˜ ì£¼ê´€ì ì¸ ì¥ë‹¨ì ì„ ì •ë¦¬í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.

- Pros ğŸ‘
    - 
    
- Cons ğŸ‘
    - mlp comparison

---

**Reference**

- Original paper [Graph Networks as Learnable Physics Engines for Inference and Control](https://arxiv.org/abs/1806.01242)
- Official code [https://github.com/fxia22/gn.pytorch](https://github.com/fxia22/gn.pytorch)