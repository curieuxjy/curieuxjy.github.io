---
title: "📃AnyTeleop 리뷰"
date: 2025-08-15
categories: [teleoperation, vision]
toc: true
number-sections: true
description: A General Vision-Based Dexterous Robot Arm-Hand Teleoperation System
---

- [Paper Link](https://arxiv.org/abs/2307.04577)
- [Project Link](http://anyteleop.com/)

1.  ✨ AnyTeleop은 다양한 로봇 팔과 손, 현실 환경, 카메라 설정에 사용 가능한 일반적인 비전 기반 로봇 원격 조작 시스템입니다.
2.  🌐 이 시스템은 여러 시뮬레이터와 실제 환경을 지원하며, 원격 및 협업 원격 조작 기능까지 제공하여 데이터 수집의 확장성을 높입니다.
3.  🚀 AnyTeleop은 범용적인 설계에도 불구하고 실제 및 시뮬레이션 실험에서 기존 시스템보다 뛰어난 성능을 달성하여, 모방 학습을 위한 고품질 데이터 수집을 용이하게 합니다.

---

# Brief Review

AnyTeleop는 다양한 로봇 팔, 로봇 손, 현실(시뮬레이터 또는 실제 세계), 카메라 설정 및 다중 운영자 협업을 지원하는 범용적인 비전 기반 로봇 팔-손 원격 조작 시스템입니다. 기존의 비전 기반 원격 조작 시스템은 특정 로봇 모델이나 배포 환경에 맞춰 설계되어 로봇 모델의 다양성이나 운영 환경이 증가함에 따라 확장성이 떨어진다는 문제를 해결합니다. AnyTeleop는 단일 시스템 내에서 이러한 다양한 시나리오를 지원하면서도 우수한 성능을 달성합니다. 실제 환경 실험에서 AnyTeleop는 동일한 로봇을 사용하여 특정 하드웨어에 맞게 설계된 이전 시스템보다 더 높은 성공률을 보였고, 시뮬레이션 원격 조작에서는 해당 시뮬레이터를 위해 특별히 설계된 이전 시스템보다 더 나은 Imitation Learning 성능을 이끌어냈습니다.

시스템은 모듈성, 통신 중심 설계, Containerization이라는 세 가지 핵심 원칙으로 설계되었습니다. 카메라는 Camera Driver를 통해 RGB 또는 RGB-D 스트림을 Teleoperation Server로 전송합니다. Teleoperation Server는 입력 데이터를 처리하여 로봇 제어 명령을 생성하며, 이 명령은 Teleoperation Client를 통해 시뮬레이터나 실제 로봇으로 전달됩니다. Web Visualizer는 로컬 또는 원격에서 원격 조작 과정을 시각적으로 피드백합니다.

Teleoperation Server는 다음 네 가지 주요 모듈로 구성됩니다.
1.  Hand Pose Detection: 카메라 스트림에서 사람 손의 손목(wrist) 및 손가락(finger) 자세를 예측합니다. RGB 또는 RGB-D 카메라, 단일 또는 다중 카메라 등 다양한 카메라 구성을 지원합니다. 손가락 키포인트(keypoint)는 MediaPipe를 사용하여 RGB 데이터로부터 검출하며, 손목 6D 자세는 RGB-D 데이터의 경우 키포인트의 Depth 값을 이용한 PnP 알고리즘으로, RGB 데이터만 있는 경우 FrankMocap에서 영감을 받은 추가 신경망을 사용하여 약한 투영(weak perspective) 변환 스케일을 예측하는 방식으로 추정합니다.
2.  Detection Fusion: 다중 카메라 감지 결과를 통합합니다. 외적 캘리브레이션 없이 사람 손을 자연 마커(marker)로 사용하는 자동 캘리브레이션 과정을 통해 카메라 간의 상대적인 회전(SO(3))을 계산합니다. 각 감지 결과의 신뢰도는 SMPL-X 손 형상 매개변수 예측값의 일관성(초기 참조 값과의 오차)을 기준으로 평가하며, 신뢰도가 가장 높은 카메라의 상대 동작을 선택하여 다음 모듈로 전달합니다.
3.  Hand Pose Retargeting: 사람 손 자세 데이터를 로봇 손 관절 위치로 매핑합니다. 이는 최적화 문제로 공식화됩니다. 사람 손과 로봇 손의 키포인트 벡터 간 차이를 최소화하고 시간적 부드러움을 개선하는 목적 함수를 최소화합니다.
    $$
    \min_{q_t} \sum_{i=0}^N ||\alpha v_i^t - f_i(q_t)||^2 + \beta ||q_t - q_{t-1}||^2 \\
    \text{s.t.} \quad q_l \leq q_t \leq q_u
    $$
    여기서 $q_t$는 시간 $t$에서의 로봇 손 관절 위치, $v_i^t$는 감지된 사람 손 키포인트에서 계산된 $i$번째 키포인트 벡터, $f_i(q_t)$는 로봇 손 관절 위치 $q_t$를 입력받아 $i$번째 로봇 손 키포인트 벡터를 계산하는 순방향 기구학 함수, $q_l$과 $q_u$는 관절 위치의 하한 및 상한, $\alpha$는 손 크기 차이를 고려한 스케일링 계수, $\beta$는 시간적 부드러움에 대한 가중치입니다. 다른 로봇 손 형태에 대해서는 사람과 로봇 손가락 사이의 키포인트 매핑을 수동으로 지정해야 합니다. 이 모듈은 로봇 손만 고려합니다.
4.  Motion Generation: 감지된 손목 및 손 자세(최종 End-effector의 Cartesian 자세)를 기반으로 로봇 팔의 부드럽고 충돌 없는 움직임을 생성합니다. 실시간 모션 생성을 위해 GPU 가속 병렬화 충돌 회피 로봇 모션 생성 라이브러리인 CuRobo를 사용합니다. Motion Generation 모듈은 낮은 주파수(25 Hz)로 End-effector의 Cartesian 자세를 받아 높은 주파수(120 Hz)로 충돌 없는 관절 공간 궤적을 생성합니다. 충돌 회피는 CUDA 기반 기하학적 질의를 사용하여 학습 기반 모델 없이 수행됩니다.

Web-based Teleoperation Viewer는 meshcat 및 Three.js를 기반으로 개발되었으며, 브라우저 기반의 접근성과 원격 및 협업 원격 조작을 위한 동기화된 시각화를 지원합니다. 다중 브라우저 창을 열어 다중 시점(multi-view)을 제공할 수 있습니다.

시스템 평가 결과, Profiling 분석에서 Hand Pose Detection이 가장 시간이 많이 소요되는 모듈이지만 요구 주파수(25Hz)를 충족합니다. 실제 로봇 원격 조작 실험에서는 XArm6 및 Allegro Hand를 사용하여 Robotic Telekinesis [54]의 10가지 조작 작업을 재현하여 비교했습니다. AnyTeleop는 10개 작업 중 8개에서 더 높은 성공률을 보였으며, 특히 컵 쌓기 등 얇은 구조의 객체 조작에서 더 안정적인 성능을 보여, 특정 하드웨어에 맞게 설계된 시스템보다 우수함을 입증했습니다. Imitation Learning 응용에서는 AnyTeleop로 수집된 데이터가 SAPIEN 환경에서 [43]의 데이터보다 더 부드럽고 자체 충돌 없는 궤적을 제공하여 더 나은 Imitation Learning 성능을 이끌어냈습니다. 또한, AnyTeleop는 다중 운영자가 서로 다른 로봇을 제어하여 협업 조작 작업을 수행하는 설정을 지원할 수 있음을 Human-to-robot Handover 작업 시연을 통해 보여주었습니다.

실패 모드로는 빠른 손 움직임 중 추적 손실 및 자체 가림(self-occlusion) 시 불안정한 손 자세가 있습니다. 전자는 운영자가 손 움직임을 늦추도록 지시하고, 후자는 다중 카메라를 사용하여 완화할 수 있습니다.

결론적으로 AnyTeleop는 다양한 로봇, 현실, 카메라 설정 및 운영자 수에 적용 가능한 다목적 원격 조작 시스템입니다. 뛰어난 일반성 및 유연성을 제공하며, 시뮬레이션 및 실제 환경 모두에서 이전 시스템보다 우수한 성능을 보여줍니다. 오픈 소스화를 통해 원격 조작 분야의 추가 연구에 기여할 것입니다.

---

# Detail Review

