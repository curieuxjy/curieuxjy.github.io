---
title: "📃Grasp as You Say 리뷰"
date: 2025-08-14
categories: [llm, retargeting]
toc: true
number-sections: true
description: Language-guided Dexterous Grasp Generation
---

- [Paper Link](https://arxiv.org/abs/2405.19291)
- [Project Link](https://isee-laboratory.github.io/DexGYS/)
- [Code Link](https://github.com/iSEE-Laboratory/Grasp-as-You-Say)

1. 🤖 본 논문은 로봇이 자연어 명령에 따라 정교한 조작(dexterous grasping)을 수행하는 새로운 과제인 DexGYS를 제안하고, 이를 위해 언어 안내가 포함된 대규모 데이터셋 DexGYSNet을 구축했습니다.
2. 📚 DexGYSNet은 인간-객체 상호작용 리타겟팅(HOIR) 및 LLM(Large Language Model) 지원 언어 주석 시스템을 활용하여 비용 효율적으로 구축되었으며, 5만 쌍의 고품질 덱스터러스 그랩 데이터와 해당 언어 지시를 포함합니다.
3. 🧠 또한, 의도 일치, 높은 다양성, 고품질 그랩 생성을 위한 DexGYSGrasp 프레임워크를 제안하며, 이는 복잡한 학습 과정을 두 가지 점진적 목표로 분해하여 기존 최신 방법론 대비 우수한 성능을 달성했습니다.

---

# Brief Review

이 논문은 로봇이 자연어 명령에 기반하여 정교한(dexterous) 그립을 수행할 수 있도록 하는 새로운 태스크인 "언어를 통한 정교한 그립(Dexterous Grasp as You Say, DexGYS)"을 탐구합니다. 이 분야의 발전을 가로막는 주요 장애물은 자연어 안내가 포함된 데이터셋의 부족입니다. 이를 해결하기 위해 저자들은 고품질의 정교한 그립 주석과 유연하고 세밀한 인간 언어 안내를 제공하는 언어 안내 정교한 그립 데이터셋인 DexGYSNet을 제안합니다.

**DexGYSNet 데이터셋 구축:**

DexGYSNet은 비용 효율적인 방식으로 구축됩니다.

1.  **Hand-Object Interaction Retargeting (HOIR)**: 쉽게 얻을 수 있는 인간의 손-객체 상호작용 데이터를 로봇의 정교한 손에 재타겟팅하여 접촉 일관성과 고품질 그립 자세를 유지합니다. HOIR 전략은 세 단계로 구성됩니다:
    *   **자세 초기화(pose initialization)**: 인간 자세의 유사한 구조로부터 정교한 손 파라미터를 복사하여 초기값을 설정합니다.
    *   **손가락 끝 정렬(fingertip alignment)**: 정교한 손 자세를 파라미터 공간에서 최적화하여 손가락 끝 위치를 인간의 손과 정렬시킵니다. 이는 다음의 목적 함수를 통해 달성됩니다:
        $$\min_{G_{dex}=(r,t,q)} \sum_k \|p_{dex,ft_k} - p_{mano,ft_k}\|_2^2$$
        여기서 $p_{dex,ft_k}$는 정교한 손의 $k$번째 손가락 끝 위치를, $p_{mano,ft_k}$는 MANO 모델의 $k$번째 손가락 끝 위치를 나타냅니다.
    *   **상호작용 정제(interaction refinement)**: 물리적 상호작용의 타당성을 높이고 일관성을 유지하기 위해 정교한 손 자세를 추가로 최적화합니다. 이 단계에서는 접촉 영역을 이전 단계의 출력과 일관되게 유지하고 이동(translation)을 고정시킵니다. 최적화 목적 함수는 다음과 같습니다:
        $$\min_{(r,q)} (\lambda_{1pen}L_{pen} + \lambda_{1spen}L_{spen} + \lambda_{1joint}L_{joint} + \lambda_{1cmap}L_{cmap})$$
        여기서 $L_{pen}$은 객체 침투 손실(object penetration loss), $L_{spen}$은 자기-침투 손실(self-penetration loss), $L_{joint}$는 관절 각도 손실(joint angle loss), $L_{cmap}$은 접촉 맵 손실(contact map loss)입니다. 각 손실은 다음과 같이 정의됩니다:
        *   객체 침투 손실 $L_{pen}$: $\sum_i I(dsdf_i > 0) \cdot dsdf_i$, 여기서 $dsdf_i$는 객체 점으로부터 손 메시까지의 부호화된 거리입니다.
        *   자기-침투 손실 $L_{spen}$: $\sum_{i,j}I(i=j) \cdot \max(0, \delta - d(p_{dex,sp_i}, p_{dex,sp_j}))$, 여기서 $p_{dex,sp}$는 손에 미리 정의된 앵커 스피어이며, $\delta$는 임계값입니다. (논문에 제시된 $I(i=j)$ 표기는 통상적인 자기-침투 손실 표현과 다소 상이할 수 있습니다.)
        *   관절 각도 손실 $L_{joint}$: $\sum_i(\max(0, q_i - q_{max_i}) + \max(0, q_{min_i} - q_i))$, 여기서 $q_i$는 관절 각도, $q_{max_i}$와 $q_{min_i}$는 각각 최대 및 최소 관절 각도입니다.
        *   접촉 맵 손실 $L_{cmap}$: $\sum_i\|c_{obj_i} - \hat{c}_{obj_i}\|_2^2$, 여기서 $c_{obj_i}$는 대상 접촉 맵, $\hat{c}_{obj_i}$는 예측된 접촉 맵입니다.
2.  **LLM-assisted Language Guidance Annotation**: 대규모 언어 모델(LLM)의 도움을 받아 유연하고 세밀한 언어 안내 주석을 생성하는 coarse-to-fine 자동 주석 시스템을 개발합니다. 이 시스템은 객체 카테고리와 간략한 인간 의도를 기반으로 간략한 안내를 생성한 다음, 각 손가락의 접촉 정보를 언어 설명자로 구성하고, 최종적으로 이 정보들을 GPT-3.5에 입력하여 자연스러운 주석 안내를 생성합니다.

**DexGYSGrasp 프레임워크:**

DexGYSNet 데이터셋을 기반으로 저자들은 의도 정렬, 고품질, 다양성을 보장하는 DexGYSGrasp 프레임워크를 제안합니다. 이 프레임워크는 복잡한 학습 과정을 두 가지 관리 가능한 점진적 목표로 분해하고 이를 실현하기 위한 두 가지 구성 요소를 도입합니다.

**점진적 그립 목표 (Progressive Grasp Objectives):**

단일 모델이 의도 정렬, 다양성, 고품질이라는 세 가지 요구사항을 동시에 충족하기 어렵다는 문제를 해결하기 위해, 특히 손-객체 침투를 방지하는 데 사용되는 침투 손실($L_{pen}$)이 다양성과 의도 정렬을 저해하는 문제에 주목합니다. 이를 해결하기 위해 학습 목표를 다음과 같이 분해합니다:
1.  **생성적 목표**: 그립 분포 학습에 중점을 둡니다. 이 단계에서는 품질보다는 의도 정렬과 생성 다양성에 초점을 맞추며, 침투 손실의 제약 없이 최적화합니다.
2.  **회귀적 목표**: 초기 거친 그립을 동일한 의도와 다양성을 유지하면서 고품질 그립으로 정제합니다. 이 단계에서는 침투 손실을 활용하여 객체 침투를 방지합니다.

**점진적 그립 구성 요소 (Progressive Grasp Components):**

이러한 점진적 목표를 달성하기 위해 두 가지 구성 요소를 설계합니다:
1.  **의도 및 다양성 그립 구성 요소 (Intention and Diversity Grasp Component, IDGC)**:
    *   그립 분포를 효율적으로 학습하고 의도 정렬 및 다양한 생성을 달성하기 위해 조건부 확산 모델(conditional diffusion model)을 기반으로 합니다.
    *   입력으로 객체 포인트 클라우드($O$)는 PointNet++ [45]로 인코딩되고, 언어 안내($L$)는 사전 학습된 CLIP 모델 [46]로 인코딩되어 조건부 정보로 사용됩니다.
    *   DDPM [47]을 샘플링 프로세스로 사용하며, 이는 다음과 같이 정형화됩니다:
        $$p_{\theta}(G_{dex0} | O, L) = p(G_T) \prod_{t=1}^T p(G_{t-1} | G_t, O, L)$$
        여기서 $G_{dex0}$는 원래의 그립 자세, $G_T$는 노이즈가 추가된 자세, $G_t$는 중간 시간 단계의 자세입니다.
    *   학습 시에는 회귀 손실만을 사용하며, 침투 손실은 의도 일관성과 그립 다양성을 향상시키기 위해 배제됩니다. 손실 함수는 다음과 같습니다:
        $$L_{IDG} = \lambda_{2para}L_{para}(G_{dex0}, \hat{G}_{dex}) + \lambda_{2chamfer}L_{chamfer}(H(G_{dex0}), H(\hat{G}_{dex}))$$
        여기서 $L_{para}$는 자세 파라미터에 대한 MSE 손실이며, $L_{chamfer}$는 손 포인트 클라우드에 대한 Chamfer Distance 손실입니다.
2.  **품질 그립 구성 요소 (Quality Grasp Component, QGC)**:
    *   첫 번째 구성 요소에서 생성된 거친 그립은 의도는 잘 정렬되고 다양하지만, 객체 침투가 심하여 품질이 좋지 않습니다. QGC는 이러한 거친 그립($\hat{G}_{dex}$)을 입력으로 받아 품질을 정제하는 역할을 합니다.
    *   입력으로 거친 자세 $\hat{G}_{dex}$, 거친 손 포인트 클라우드 $H(\hat{G}_{dex})$ 및 객체 포인트 클라우드 $O$를 받으며, $\Delta G_{dex}$를 출력하여 정제된 그립 $\tilde{G}_{dex} = \hat{G}_{dex} + \Delta G_{dex}$를 얻습니다.
    *   학습 쌍은 IDGC가 생성한 거친 그립과 가장 유사한 그라운드-트루스 그립으로 구성되어, 정제된 그립이 의도된 행동과 일관성을 유지하도록 보장합니다.
    *   이 구성 요소는 침투 손실을 포함한 손실 함수를 사용합니다:
        $$L_{QG} = \lambda_{3para}L_{para} + \lambda_{3chamfer}L_{chamfer} + \lambda_{3pen}L_{pen} + \lambda_{3cmap}L_{cmap} + \lambda_{3spen}L_{spen}$$
        여기서 $\lambda$는 각 손실 항의 가중치입니다.

**실험 결과:**

DexGYSNet 데이터셋 및 실제 환경에서의 광범위한 실험을 통해 제안된 방법이 다양한 객체에 대해 의도 일관성, 높은 다양성, 그리고 고품질의 그립 자세를 생성할 수 있음을 입증합니다. 기존 최첨단(SOTA) 방법들과 비교하여 의도 일관성과 그립 다양성 측면에서 훨씬 뛰어난 성능을 보이며, 그립 품질 측면에서도 경쟁력 있는 성능을 달성합니다. 특히, 침투 손실의 영향에 대한 정량적 분석과 점진적 구성 요소 및 손실의 필요성을 검증하는 어블레이션 연구는 제안된 프레임워크의 핵심 통찰력을 뒷받침합니다. 또한, HOIR 전략의 효과성과 다른 SOTA 방법에 대한 플러그-앤-플레이(Plug-and-play) 가능성도 확인되었습니다. 실제 세계 실험에서는 Allegro hand, Flexiv Rizon 4 암, Intel Realsense D415 카메라를 사용하여 제안된 방법의 실용적 적용 가능성을 보여주었습니다.

결론적으로, 이 논문은 로봇이 인간 언어에 맞춰 고품질의 정교한 그립을 수행할 수 있도록 하는 "Dexterous Grasp as You Say"라는 새로운 태스크를 탐구하고, 이를 달성하기 위한 비용 효율적인 데이터셋 DexGYSNet과 점진적 학습 프레임워크 DexGYSGrasp를 제안합니다. 이는 인간-로봇 상호작용을 촉진하고 로봇의 실제 환경 배포를 가속화하는 데 중요한 기여를 합니다.

---

# Detail Review

> Grasp as You Say: 언어로 안내하는 다지 로봇 핸드 그립 생성 – NeurIPS 2024 논문 리뷰

## **핵심 아이디어 및 문제 설정**

다지 로봇 손을 이용한 **섬세한 파지**(dexterous grasping)를 사람의 **자연어 지시**로 수행하는 새로운 과제 **“Dexterous Grasp as You Say (DexGYS)”**를 제안한 논문입니다. 기존의 다지 손 파지 연구들은 주로 **그립 안정성** 확보에 집중했지만, **사람 의도에 맞는 섬세한 파지**에는 미치지 못했습니다. 예를 들어, 이전 작업들은 로봇 손이 물체를 떨어뜨리지 않도록 잡는 데 초점을 맞추었으나, **“손잡이를 검지로 눌러 잡아라”**와 같이 **특정 방식으로 물체를 잡는** 인간의 의도를 반영하지는 못했습니다. 최근 **과업 지향** 또는 **기능 지향** 다지 파지 연구들이 등장했지만, 미리 정해진 한정적 작업들만 대응하여 **유연성과 범용성**이 부족했습니다.

**DexGYS 과제**는 사람이 자연어로 설명하는 **유연하고 세분화된 파지 의도**를 로봇 손이 그대로 구현하는 것을 목표로 합니다. 이 과제 설정의 **핵심 아이디어**는, 로봇에게 **언어로 의도를 전달**하여 인간과 보다 자연스러운 상호작용을 가능케 하고, 로봇 다지 손의 잠재력을 **의도 기반의 인간유사 파지**로 활용하는 것입니다. 하지만 이러한 새로운 과제에는 두 가지 **큰 도전**이 존재합니다.

첫째, **자연어 지시가 포함된 다지 파지 데이터**가 부족합니다. 다지 손의 자세와 그에 대응되는 사람의 언어 지시를 동시에 고품질로 수집하는 것은 비용이 매우 높고 번거롭습니다. 기존에 언어와 결합된 파지 데이터셋이 없기 때문에, **학습을 위한 데이터 기반** 자체가 부족한 상황이었습니다. 둘째, **의도 정합성**, **파지 품질(안정성)**, **다양성**을 모두 만족하는 로봇 손 자세를 **동시에 생성**하는 것이 어렵습니다. 특히, 다지 손이 물체를 관통하지 않도록 하는 **penetration loss**를 학습에 넣으면 파지 품질은 좋아지지만 오히려 **의도에서 벗어나거나 다양성이 감소**하는 현상이 발생합니다. 반대로 관통 페널티를 없애면 손가락이 물체를 뚫고 지나가는 **물리적으로 불가능한 파지**가 생길 수 있습니다. 이러한 **트레이드오프** 때문에 **의도-품질-다양성**을 한꺼번에 달성하기가 까다로운 문제가 제기됩니다.

## **제안한 방법의 기술적 기여 및 기존 연구와의 차별성**

이 논문의 기여는 **데이터셋부터 모델에 이르는 총체적 해결책**을 제시했다는 데 있습니다. 주요 기술적 기여와 기존 작업과의 차별성을 정리하면 다음과 같습니다.

* **세계 최초의 언어 안내 다지 파지 데이터셋 구축:** 저자들은 **DexGYSNet**이라는 **대규모 언어-다지 파지 데이터셋**을 새로 구축했습니다. 이 데이터셋은 **1,800개 일상 물체**에 대해 **50,000쌍**의 로봇 손 자세와 인간 자연어 지시로 이루어져 있습니다. 이전에는 이러한 형태의 데이터가 없어 학습에 어려움이 있었는데, DexGYSNet은 **LLM(대규모 언어 모델)**을 활용한 텍스트 주석 생성과 **손-물체 상호작용 재타깃팅(HOIR)** 기법으로 **비용 효율적**이면서도 **고품질의 데이터**를 확보했다는 점에서 큰 기여를 합니다. HOIR 기법을 통해 **인간 손 모션 캡처 데이터**를 로봇 손 모델로 전이하여 **접촉 지점의 일치**와 **자연스러운 손 자세**를 얻었고, LLM 기반 자동 주석으로 **세밀하고 다양한 표현의 언어 지시**를 생성했습니다. 이는 **기존 작업**들이 소수의 정형화된 지시나 제한된 기능만 다룬 것과 달리, **유연하고 풍부한 언어-행동 쌍 데이터**를 처음 제공한 것입니다.

* **의도 정합성과 품질을 모두 만족하는 **새로운 파지 생성 프레임워크 제안:** 데이터셋을 바탕으로 저자들은 **DexGYSGrasp**라는 **2단계 파지 생성 프레임워크**를 제안했습니다. 이는 **기존**에 하나의 모델로 모든 목표를 달성하려다 **관통 페널티로 인한 성능 저하**를 겪었던 접근들과 달리, 학습 목표를 **두 단계로 분리**하여 문제를 해결합니다. **첫 번째 단계**는 **“의도 및 다양성 파지 생성 (IDGC: Intention & Diversity Grasp Component)”**으로, **언어 의도에 부합하면서 다양한 파지**를 생성하는 **확산 생성 모델**입니다. 이 단계에서는 **관통에 대한 제약을 과감히 제외**하여, 모델이 **의도 정합한 다양한 손 자세 분포**를 자유롭게 학습하도록 합니다. **두 번째 단계**는 **“품질 향상 파지 생성 (QGC: Quality Grasp Component)”**으로, 1단계 출력인 **거친 파지 결과(coarse pose)**를 받아 **미세 조정**함으로써 **안정적이고 물체를 관통하지 않는** 고품질 파지로 개선합니다. 이 단계에서는 **관통 손실과 품질 관련 손실**을 적용하여 손가락들이 물체 표면에 밀착되도록 조정하되, **손바닥의 위치나 전체 의도는 유지**하여 처음 의도에서 벗어나지 않도록 합니다. 이러한 **점진적 학습 전략**은 기존 연구에 없던 발상으로, **복잡한 최적화 문제를 둘로 쪼개어** 각각 해결함으로써 **의도-품질-다양성**을 모두 달성한다는 점에서 차별화됩니다. 저자들은 특히 **관통 손실을 1단계에서 배제**하고 **2단계에서만 적용**하는 **프로그레시브 학습** 아이디어로, 기존 방법들이 직면했던 **학습 상충 문제**를 해결했다는 점을 강조합니다.

* **기존 기법 대비 향상된 성능 입증:** 제안한 DexGYSGrasp 프레임워크는 다양한 **비교 대상(SOTA 기법)**보다 **우수한 성능**을 보였습니다. 예를 들어, **GraspCVAE**(확률적 생성모델), **GraspTTA**(테스트시 최적화 기법), **SceneDiffuser**(확산 모델 기반), **DGTR**(Transformer 기반) 등과 비교했을 때, **의도 정합성 오차가 가장 낮고** 파지 **자세의 다양성은 월등히 높으면서도** 파지 **안정성도 우수**했습니다. 또한 학습 전략의 유효성을 검증하기 위한 **내부 실험(삭제 실험)**에서도, **제안한 2단계 구성과 손실 설계가 없으면 성능이 급격히 악화**됨을 보여주어, 해당 설계가 이 문제에 필수적임을 증명하였습니다. 요약하면, 이 논문은 **새로운 문제 설정**과 함께 이를 해결하기 위한 **데이터셋, 모델, 학습법을 모두 제시**하고, 그 결과로 **사례 연구 분야에서의 새로운 SOTA**를 달성했다는 점에서 큰 기술적 의미를 갖습니다.

## **모델 아키텍처 및 학습 방법의 구체적 분석**

**DexGYSGrasp 프레임워크**는 앞서 언급한 두 가지 컴포넌트(단계)로 구성됩니다. **첫 번째 컴포넌트(IDGC)**는 **조건부 확산 모델**로서, **물체의 점 구름(point cloud)**과 **언어 임베딩**을 입력 받아 **로봇 손의  포즈(자세 파라미터)**를 생성합니다. 이때 물체의 형상 정보는 **PointNet++**로 인코딩하고, 언어 지시는 **사전 학습된 CLIP** 모델로 임베딩하여 조건으로 활용합니다. 확산모델은 **DDPM (Denoising Diffusion Probabilistic Model)** 기법을 사용하여, 노이즈에서부터 점진적으로 손 자세를 생성해냅니다. 한마디로, IDGC는 **“노이즈 → 손 파지 자세”**로의 **분포 생성**을 학습하는 모듈입니다. 학습 시 **손실 함수**는 **L2 회귀 손실**(예측한 관절 각도 등이 실제 값과 가까워지도록)과 **손 모양 챔퍼 손실**(예측 손 모델과 정답 손 모델 간의 Chamfer 거리 최소화)로 구성됩니다. 중요한 점은, **이 단계에서는 물체와 손의 겹침(관통)에 대한 페널티를 넣지 않습니다**. 관통 제약이 없어야 모델이 **다양한 자세**를 자유롭게 시도하며 **언어 의도에 맞는 거친 파지 형태**들을 폭넓게 익힐 수 있기 때문입니다. 이렇게 함으로써 IDGC는 **의도 정합성과 다양성**을 최우선으로 학습합니다.

**두 번째 컴포넌트(QGC)**는 **Transformer 기반의 후처리 모듈**로, 1단계에서 생성된 거친 파지 결과를 **세밀 조정**하여 **물리적으로 실행 가능한 고품질 파지**로 변환합니다. QGC는 **회귀적 접근(regressive manner)**을 취하는데, 거친 손 자세와 해당 상황의 **물체/손 점구름 정보**를 입력으로 받아 **미세 조정된 새로운 손 자세 출력을 예측**합니다. 이때 학습 데이터는 IDGC로 생성한 거친 파지 결과에 대해, **유사한 의도의 인간 시연 정답(grasp)**을 **타겟**으로 짝지어 구성합니다. 예를 들어 언어 지시가 “컵을 옆면에서 집게손가락과 엄지로 집어라”인 경우, IDGC 출력이 컵 옆면을 향하고 있다면, 그와 **의도적으로 비슷한** 데이터셋 내의 실제 그립 자세를 찾아 **목표 값**으로 삼아 QGC를 학습시키는 방식입니다. 이렇게 하면 QGC가 **언어 의도에 부합하는** 결과를 내도록 보장하면서, 동시에 타겟 파지를 모방하며 **품질 향상**을 배우게 됩니다. QGC의 네트워크는 **트랜스포머 인코더-디코더 구조** 등을 사용하여, **물체와 손의 복합 특징을 고려**하면서 관절 각도 등을 조정하는 것으로 보입니다. 특히 학습 시 **손바닥의 위치나 방향(6-자유도 루트 포즈)**는 크게 변경하지 않고 고정하거나 작은 범위에서만 수정하도록 함으로써, **초기 거친 파지의 의도를 유지**한 채 손가락 배치만 최적화하도록 설계되었습니다. QGC 단계의 손실 함수에는 **물체 관통 페널티**가 비로소 포함되며, 그 외에 목표 파지와의 회귀 손실 등이 사용됩니다. 관통 페널티는 손 모델(mesh)과 물체 점구름 간 **최대 관통 깊이(P)**를 줄이는 방향으로 작용하여, 출력 자세에서 **손이 물체를 뚫고 들어가지 않도록** 만듭니다.  이처럼 **QGC는 품질만을 집중적으로 개선**하기 때문에, 1단계와 대비하여 훨씬 **좁은 탐색 공간**(초기 파지 주변의 작은 조정)에서 효율적으로 학습될 수 있습니다.

전체적으로 **두 단계의 분리** 덕분에, 1단계 IDGC는 **의도와 다양성에 특화**되어 학습하고 2단계 QGC는 **물리적 타당성과 안정성 확보**에 주력하게 됩니다. **프로그레시브 학습 전략**으로 각 단계의 **최적화 목표가 단순화**되어, 단일 모델로 한 번에 학습할 때 발생하던 **의도-품질 상충 문제**를 해소할 수 있었습니다. 저자들의 설명에 따르면, **모든 손실을 한 단계에 동시에 최적화하려 하면** 한 쪽을 충족하면 다른 쪽이 나빠지는 문제가 컸지만, **단계를 나누고 적절한 손실을 배치**한 덕분에 **의도 정합성, 그립 품질, 다양성** 모두에서 뛰어난 성능을 얻을 수 있었다고 합니다.

한편, **DexGYSNet 데이터셋** 구축 과정의 **기술적 요소**도 눈여겨볼 만합니다. HOIR(Human-to-robot Hand-Object Interaction Retargeting) 전략을 통해 사람 손 동작을 로봇 손으로 옮길 때 **접촉 지점과 포즈의 일관성**을 유지하도록 했습니다. 이로써 로봇 손이 **사람이 잡은 형태**를 최대한 그대로 모사하는 고품질 파지 데이터를 얻었습니다. 그리고 언어 주석을 달기 위해 GPT 등의 **대규모 언어 모델**을 활용, 각 파지에 대해 **유연하고 상세한 자연어 설명**을 자동 생성했습니다. 예를 들어 한 손 자세에 대해 “검지로 스프레이의 방아쇠를 누르듯이 잡는다”와 같은 문장이 주어지는 식입니다. 이러한 LLM 기반 기법은 사람을 일일이 참여시키지 않고도 **다양한 표현의 지시 문장**을 붙일 수 있게 해, 결과적으로 **풍부한 학습 데이터**를 저비용으로 확보했습니다.

마지막으로 모델의 **학습 파이프라인**을 보면, 1단계 확산 모델(IDGC)은 약 100 epoch 동안 학습하고, 2단계 QGC는 20 epoch 남짓 학습했다고 합니다. 확산 모델의 샘플링 특성상 **여러 샘플을 생성**할 수도 있는데, 실험에서는 하나의 조건에 대해 8개의 샘플을 뽑아 **다양성**을 평가에 활용하기도 했습니다. 학습에는 **SGD** 등의 최적화 방법이 쓰였으며, 구체적인 하이퍼파라미터(예: 관통 손실 가중치는 2단계에서 얼마를 사용 등)는 논문에 기술되어 있습니다. 종합하면, DexGYSGrasp의 아키텍처는 **확산 모델 + 트랜스포머**의 2단 구조, **손실함수의 단계적 적용**, **데이터셋 기반 지도학습**의 조합으로 이루어져 있습니다.

## **실험 결과 분석 – 데이터셋, 비교 대상, 성능 지표 평가**

**DexGYSNet** 데이터셋은 앞서 말한 대로 **총 50,000개의 (언어 지시, 로봇 손 파지 자세) 페어**로 이루어진 대규모 데이터셋입니다. 저자들은 이 데이터셋을 **객체 인스턴스 수준**에서 분리하여 실험했습니다. 즉, **같은 카테고리**의 물체라도 일부는 학습용, 나머지 20%는 평가용으로 하여, 모델이 **보지 못한 새로운 물체**에 대해서도 파지를 생성하도록 설정했습니다. 이는 **일반화 성능**을 보기 위함으로, 특정 물체 모양만 외우지 않고 **새 물체에도 언어 지시 기반 파지 생성**이 가능한지를 평가한 것입니다.

**평가 지표**는 **의도 정합성**, **파지 품질(안정성)**, **파지 다양성**의 세 측면에서 설정되었습니다. **의도 정합성**은 **예측한 로봇 손의 형태가 목표 의도와 얼마나 일치하는가**를 나타내며, **Chamfer 거리**와 **Contact distance** 두 가지를 사용했습니다. Chamfer 거리는 **예측한 손 모델과 데이터셋 정답 손 모델 간 점구름 거리**로, 값이 작을수록 손의 형태가 정답과 비슷함을 의미합니다. Contact distance는 **예측 손과 정답 손이 물체를 접촉한 지점들의 분포 차이**를 L2 거리로 측정한 것으로, 이것 역시 낮을수록 **접촉 패턴**이 유사함을 뜻합니다. 쉽게 말해 Chamfer와 Contact 지표가 작으면, **“로봇 손이 잡은 모양과 위치가 사람이 의도한 그것에 가깝다”**고 볼 수 있습니다. **파지 품질**은 **안정적으로 물체를 잡았는지**를 평가하며, **Q1 지표**와 **관통 깊이(P)**를 사용했습니다. Q1은 DexGraspNet 논문【15†】에서 정의된 지표로서, 일정 기준(충분한 접촉면적, 허용 관통범위 등)을 만족하는 **성공 그립의 비율**을 의미합니다. 값이 높을수록 파지가 성공적이라는 뜻인데, 0\~1 범위가 아닌 **평균 접촉수** 등의 형태로 산출되어 상대 비교에 사용됩니다. **관통 깊이(P)**는 **물체 표면과 손 모델 사이의 최대 겹침 깊이(cm)**로, 값이 클수록 손이 물체를 많이 뚫고 들어갔음을 의미합니다. 이상적인 파지라면 P=0(관통 없음)이겠지만, 시뮬레이션/모델 한계상 약간의 겹침은 발생할 수 있으므로 작을수록 좋다고 봅니다. **파지 다양성**은 **동일 조건에서 생성된 여러 파지 결과의 변동 폭**을 나타냅니다. 하나의 언어 지시와 물체에 대해 모델이 여러 번 파지를 생성해보면 매번 조금씩 다른 자세가 나올 수 있는데, 이 **자세 파라미터들(손의 위치, 회전, 각 관절각)**의 **표준편차**를 계산하여 수치화했습니다. 값이 크면 다양한 자세가 나온다는 뜻이고, 0에 가까우면 매번 비슷한 자세만 생성한다는 의미입니다.

저자들은 **여러 최신 기법(SOTA)**들을 **비교 대상으로 선정**하여, 제안한 방법의 성능을 평가했습니다. 테이블 1에는 대표적인 비교 결과가 정리되어 있습니다. 비교 기법으로는 **GraspCVAE**【48†】(조건부 변분오토인코더 기반 생성), **GraspTTA**【41†】(기 학습된 모델을 테스트시 미세조정하는 기법), **SceneDiffuser**【4†】(3D 장면 확산모델 기반 파지 생성), **DGTR**【7†】(Dexterous Grasping Transformer, 트랜스포머 기반 생성) 등이 포함되었습니다. 공정한 비교를 위해, 이들 기존 기법에도 **언어 조건을 입력**으로 줄 수 있도록 약간의 구조 수정(예: 물체 점구름 특징과 언어 임베딩을 결합)하여 실험했다고 합니다.

**결과를 살펴보면**, **DexGYSGrasp(ours)**가 **전반적으로 가장 우수한 성능**을 달성한 것을 알 수 있습니다. **의도 정합성** 측면에서, Chamfer 거리와 Contact 거리 모두 우리 방법이 **가장 낮았습니다**. 구체적으로 Chamfer 거리의 경우 우리 방법은 **1.198**로, 두 번째로 낮은 SceneDiffuser의 **1.679**보다 훨씬 작고, 다른 방법들(대부분 2.0~~3.1 이상)에 비해 크게 향상되었습니다. Contact 거리도 우리 방법은 **0.036**으로, 다른 방법들(0.045 이상) 대비 뚜렷하게 낮았습니다. 이는 **예측한 손 자세가 정답 대비 매우 정확히 의도를 따라잡고 있음**을 보여줍니다. **파지 품질(안정성)** 측면에서는, 관통 깊이(P)의 경우 우리 방법은 **0.223 cm** 정도로, GraspTTA가 **0.188 cm**로 가장 작긴 했지만 그 외 다수 기법들은 0.25~~0.55 cm 수준이어서, 우리 방법이 **상당히 낮은 관통**을 유지함을 알 수 있습니다. Q1 지표는 값이 높을수록 안정적인데, 우리 방법이 **0.083**으로 가장 높았고, 다른 기법들은 0.05~~0.08 사이였습니다. 특히 GraspTTA는 관통이 적은 대신 Q1이 0.071로 우리보다 낮았고, SceneDiffuser 등은 관통이 약간 더 크면서 Q1은 비슷하거나 더 낮았습니다. 이를 종합하면 **우리 방법은 품질 면에서도 타 기법들과 대등하거나 더 나은 안정성을 확보**하고 있음을 의미합니다. **파지 다양성**은 우리 방법의 두드러진 강점으로 나타났습니다. 우리 방법은 **동일 조건 8회 생성 시 손바닥 위치의 표준편차 약 6.118, 회전 각도 표준편차 55.68, 관절 각도 표준편차 6.118** 등을 기록했는데, 다른 방법들은 회전 각도 변동이 많아야 14 정도(DGTR)이고 대부분 1~~8 범위에 그쳐 현저히 낮았습니다. 이는 **우리 방법이 하나의 지시에도 아주 다양한 손 모양으로 잡을 수 있음**을 뜻하며, **생성의 풍부함** 측면에서 기존 방법들과 차별화되는 결과입니다. 결국 테이블 1의 결과는 **DexGYSGrasp가 의도 일치도와 다양성에서 월등하며, 품질도 희생하지 않는 균형 잡힌 성능**을 보여주는 것을 입증합니다.

논문에서는 이러한 정량 평가 외에도 다양한 **분석 실험**을 수행하여 제안 기법의 동작을 검증하였습니다. **테이블 2**에서는 **프레임워크 구성요소와 학습 전략에 대한 ablation(요소 제거) 실험** 결과를 제시합니다. 여기서는 한 단계 모델로 모든 것을 학습하거나(IDGC만 사용), 1단계 학습 중간에 관통 페널티를 서서히 높이는 등 다양한 변형을 시험했습니다. 그 결과, **두 단계로 나누지 않고 단일 모델로 학습하면 의도-품질-다양성의 균형을 이루지 못하고 한두 측면만 만족**시키는 반쪽짜리 성능을 보였습니다. 또한 **단계를 나누더라도 관통 페널티 사용 방식 등을 우리처럼 하지 않으면 성능이 개선되지 않았고**, 2단계 없이 1단계로만 관통까지 모두 학습시키는 경우 역시 **의도가 크게 어긋나는 문제**가 생겼습니다. 반면 **우리의 프로그레시브 설계(IDGC+QGC 둘 다 적용, 단계별 손실 할당)**만이 **의도 정합성, 품질, 다양성 세 마리 토끼를 동시에 잡는 결과**를 냈습니다. 흥미롭게도, **테스트 타임 적응 기법(TTA)**을 활용해 품질을 높이면 관통은 줄었지만 **의도 일관성이 심각하게 떨어지는** 현상도 관찰되었는데, 이는 **품질만 후처리로 높이는 기존 접근의 한계를 보여주는 예**라 할 수 있습니다. 종합하면 ablation 실험은 **제안한 2단계 구조의 필요성과 설계 선택의 타당성**을 강력하게 뒷받침합니다.

**HOIR 전략의 효과**도 별도로 평가되었습니다. 저자들은 **동일한 파지 데이터를 단순히 로봇 손으로 변경한 경우**와 **HOIR를 통해 접촉 일치시키며 변경한 경우**를 비교하여 데이터 품질을 분석했습니다. 그 결과 HOIR를 사용했을 때 생성된 데이터의 **손-물체 접촉 분포가 실제 사람 파지와 훨씬 유사**해졌고, 모델 학습 시에도 **더 안정적인 수렴과 성능 향상**을 가져왔습니다 (세부 수치는 부록에 제시). 이는 HOIR가 없다면 데이터에 **물체 표면을 스치지 못한 부실한 파지**나 **비현실적 손 모양**이 생길 수 있지만, HOIR로 **자연스러운 파지 예시**들을 제공했기 때문에 모델이 **현실성 높은 파지**를 배울 수 있었음을 의미합니다.

마지막으로, 저자들은 **실물 로봇 실험**을 통해 제안 기법의 **현실 적용 가능성**도 검증했습니다. **알레그로(Allegro) 로봇 핸드**와 **Flexiv Rizon 4** 로봇 팔, 그리고 **Intel RealSense D415 카메라**로 구성된 실제 환경에서, 여러 가지 물체를 놓고 **자연어 지시대로 집어보는 실험**을 수행했습니다. 현실에서는 물체의 **완전한 3D 형태**를 알 수 없으므로, 카메라로 촬영한 물체 영상을 처리하여 **부분 점구름**을 얻은 뒤, **SAM(Segment Anything Model)**을 활용한 시각적 그라운딩으로 물체만 분리하고 **포인트 클라우드 보완 네트워크**로 **완전한 물체 점구름**을 복원하는 파이프라인을 사용했습니다. 이렇게 얻은 추정 물체 형상을 이용해 우리 모델이 파지 자세를 예측하면, 로봇 팔을 해당 위치로 이동시키고 로봇 손의 관절 각도를 예측 값으로 설정하여 **파지를 실행**했습니다. 그 결과 여러 가지 **다양한 모양의 물체**에 대해 **지시한 방식**으로 로봇 손이 물체를 성공적으로 움켜쥐는 모습을 보여주었고 (예: 스프레이 병의 방아쇠 누르기, 머그컵 손잡이 잡기 등), 이는 **본 논문의 기법이 시뮬레이션을 넘어 현실 로봇에서도 효과적**임을 입증했습니다. 실제 동영상 예시는 논문 사이트를 통해 공개되었으며, 전반적으로 **사람의 언어 지시에 따라 로봇이 물체를 잡는 데 성공하는** 장면들을 확인할 수 있습니다. 다만 센서 오차나 점구름 보완의 한계로 인해 **일부 파지에서 아주 미세한 관통이나 불완전 접촉**이 발생하기도 했지만, 이는 추가적인 제어 보정으로 개선 가능할 것으로 보입니다. 저자들은 전반적인 실험을 통해 **제안 기법이 현재까지 보고된 방법들보다 우수하며, 실제 환경에서도 유용**하다는 것을 강조하고 있습니다.

## **강점과 한계, 향후 발전 가능성**

**“Grasp as You Say”** 논문의 강점은 명확합니다. **첫째**, **문제 정의의 참신성**입니다. 로봇 파지에 일반적인 자연어를 적용함으로써 **인간-로봇 상호작용의 새로운 지평**을 열었고, 기존 연구들이 다루지 못한 **유연한 의도 반영 파지**를 가능케 했습니다. **둘째**, 이를 뒷받침하는 **데이터셋과 기법의 완성도**입니다. DexGYSNet 데이터셋은 학계 최초로 **자연어 설명이 포함된 대규모 다지 파지 데이터**를 제공하여 향후 관련 연구의 기반이 될 수 있습니다. **HOIR+LLM**을 통한 데이터 구축은 **효율성과 다양성**을 모두 확보한 뛰어난 방법으로, 이후 다른 로봇 행동 데이터셋 구성에도 응용될 수 있을 것입니다. **셋째**, DexGYSGrasp 프레임워크의 **독창적 설계와 효과성**입니다. 관통 페널티에 기인한 학습 어려움을 **2단계 프로그레시브 학습**으로 풀어낸 것은 로봇 학습 분야에서 **복잡한 다목적 최적화 문제를 해결하는 새로운 방법론**으로 평가할 만합니다. 실험으로 입증되었듯, 이 접근법은 **의도, 품질, 다양성이라는 상충하는 요소들을 모두 달성**하여 이전까지 어려웠던 영역에서 성과를 냈습니다. **넷째**, **시뮬레이션과 실제 실험을 아우르는 검증**을 수행한 점도 강점입니다. 논문은 알고리즘 제안에 그치지 않고, **실제 로봇 팔과 손으로 동작시켜 봄으로써 현실성**을 검증했습니다. 이는 해당 기법이 **이론적 성능뿐 아니라 실용적 가치**도 있음을 보여주며, 연구의 완성도를 높입니다.

그럼에도 불구하고 몇 가지 **한계와 향후 과제**도 존재합니다. 우선, **데이터셋의 범위**에 관한 한계입니다. DexGYSNet은 1,800개의 일상 물체를 포괄하지만, **산업용 복잡한 부품**이나 **비정형 물체** 등은 포함되지 않았을 수 있습니다. 또한 언어 지시도 **파지 동작**에 초점을 맞춘 문장들로 구성되어 있어, **복합적 작업 시나리오**(예: “잡아서 옮겨 놓아라”와 같이 파지 후 다른 행동을 수반하는 지시)에는 대응하지 못합니다. 향후에는 **보다 다양한 객체 및 작업**에 대해 데이터셋을 확장하고, **연속적 조작**까지 포함하는 방향으로 발전시킬 수 있을 것입니다. 둘째, **모델의 복잡도와 실행 시간**도 고려해야 합니다. 확산 모델을 사용한 1단계 생성은 본질적으로 **샘플링에 다수의 확률적 단계**를 거치기 때문에, 실시간 응용에는 속도 제약이 있습니다. 실제 로봇에 적용하려면 **생성 시간 단축**이나 **경량화**가 필요할 수 있습니다. 이를 위해 **디퓨전 모델의 가속화 기법**이나 **단계 축소(예: DDIM)**, 또는 학습된 **픽스드 모션 라이브러리 활용** 등이 연구될 수 있습니다. 셋째, **일반화 능력**에 대한 추가적인 검증이 필요합니다. 본 논문에서는 학습에 사용되지 않은 새 물체에 대해서도 실험했지만, **전혀 보지 않은 새로운 유형의 물체**나 **아주 다른 문장 표현**에 대해서는 성능이 어떻게 되는지 더 살펴봐야 합니다. 예컨대, “이 물체를 아주 느슨하게 쥐어봐”와 같은 **미묘한 힘 조절**이나 추상적인 지시도 처리하려면, 모델을 보완하거나 추가 학습이 필요할 것입니다. 넷째, **물리기반 제한**의 부족입니다. 2단계에서 관통을 줄였다고는 하나, 접촉 마찰이나 동적 안정성 등 **정량화하기 어려운 물리적 요소**는 고려되지 않았습니다. 향후에는 **강화학습(RL)**이나 **물리 시뮬레이터 상의 fine-tuning**으로 진짜 **떨어뜨리지 않고 잡는 안정성**까지 확보하면 더 완벽한 솔루션이 될 것입니다.

그럼에도, 이러한 한계들은 **현재 연구의 범위 밖**의 것들이고, 본 논문의 기여를 폄하하지는 않습니다. 오히려 이 한계들은 **향후 연구 기회**를 제시합니다. **향후 발전 가능성**으로는, **언어-로봇 상호작용**을 더욱 확장하여 **다단계 작업계획**에 언어 지시를 연결하거나, **시각 인지와 언어, 행위**를 통합하는 종합적인 프레임워크로의 발전이 기대됩니다. 예를 들어, **“컵을 집어 식탁 오른쪽 구석에 놓아둬”** 같은 복합 지시를 수행하려면, 파지뿐 아니라 이동, 놓기까지 통합된 계획이 필요하며, 본 연구의 성과는 이러한 방향으로 나아가는 **시발점**이 될 수 있습니다. 또한 **휴먼 피드백 강화학습(RLHF)** 등을 통해 사용자로부터 파지에 대한 피드백을 받아 **더 미세한 조정**을 학습하는 방법도 고려해볼 수 있습니다.

요약하면, *Grasp as You Say* 논문은 **자연어로 로봇 손 파지를 제어하는 혁신적 아이디어**를 제시하고, 이를 구현하기 위한 **데이터셋, 모델, 학습기법의 정교한 조합**을 통해 **새로운 수준의 성능**을 달성한 연구입니다. 로보틱스 전문가에게 본 논문의 접근법은 **다지 로봇 핸드 활용과 인간-로봇 인터랙션** 영역에서 많은 **영감과 시사점**을 줄 것으로 보입니다. 앞으로 이 개념을 바탕으로 한 다양한 응용과 연구의 전개가 기대됩니다.
