---
title: "📃Contact Trust Region 리뷰(feat.Dextreme)"
date: 2025-06-13
categories: [mpc, rl, dexterous, contact, trust-region]
toc: true
number-sections: false
description: Dexterous Contact-Rich Manipulation via the Contact Trust Region
---

> CTR vs DeXtreme: 능숙한 접촉 조작을 향한 두 갈래 길
> 모델 기반 접촉 계획(MPC-CTR)과 강화학습 기반 조작(DeXtreme)의 수학적 원리와 구조를 깊이 분석하고, 두 방법론을 다양한 관점에서 비교

- [Paper Link](https://arxiv.org/pdf/2505.02291)
- [Project Homepage](https://ctr.theaiinstitute.com/)

1.  이 논문은 전통적인 타원형 신뢰 영역의 한계를 극복하기 위해 편측 접촉 역학을 고려하는 Contact Trust Region (CTR)을 제안합니다.
2.  🤖 CTR을 기반으로, 저자들은 효율적인 로컬 Model Predictive Control (MPC) 알고리즘을 개발하고, 이를 초기 추정 휴리스틱 및 빈번한 재계획과 결합하여 복잡한 접촉 조작 작업에 대한 안정화를 가능하게 합니다.
3.  🗺️ 제안된 CTR 기반 로컬 MPC는 로드맵 프레임워크에 통합되어 전역 계획을 수행하며, 기존 방식보다 훨씬 적은 계산 시간으로 양팔 로봇 및 Allegro hand와 같은 복잡한 시스템에서 능숙한 조작을 시연합니다.

# Brief Review

본 논문 "Dexterous Contact-Rich Manipulation via the Contact Trust Region"은 로봇의 능숙하고 접촉이 많은 조작(dexterous contact-rich manipulation)을 위한 효율적인 지역적 동역학 모델과 그 신뢰 영역(trust region)을 정의하는 문제를 다룬다. 기존의 많은 접근 방식은 동역학의 Taylor 근사와 타원형 trust region에 의존하지만, 본 논문은 이러한 방식이 접촉의 비대칭성(unilateral nature)과 근본적으로 일관되지 않다고 주장한다.

이러한 문제점을 해결하기 위해, 본 논문은 접촉의 비대칭성을 포착하면서도 계산 효율성을 유지하는 Contact Trust Region(CTR)을 제안한다. CTR을 기반으로, 먼저 지역적인 접촉이 많은 계획을 합성할 수 있는 Model-Predictive Control(MPC) 알고리즘을 개발한다. 그 후, 이 기능을 확장하여 지역 MPC 계획들을 연결함으로써 전역적으로 계획하고 효율적이며 능숙한 접촉이 많은 조작을 가능하게 한다.

본 논문의 주요 기여는 세 가지이다. 첫째, 접촉 역학을 효율적으로 근사하는 Contact Trust Region(CTR)이다. 둘째, 지역적인 접촉이 많은 조작에 특화된 매우 효율적인 기울기 기반 MPC 컨트롤러이다. 셋째, 지역 궤적들을 연결하는 전역 플래너이다.

**핵심 방법론: Contact Trust Region (CTR)**

본 논문은 접촉 동역학을 Convex Quasidynamic Differentiable Contact(CQDC) 모델로 표현한다. 이는 접촉 시뮬레이션을 다음 형태의 Second-Order Cone Program(SOCP)으로 정식화한다:
$$
\begin{aligned} \min_{q_+} & \quad \frac{1}{2} q_+^\top P(q)q_+ + b(q, u)^\top q_+, \\ \text{subject to} & \quad J_i(q)q_+ + c_i(q) \in K_i, \quad \forall i \in I_c. \end{aligned}
$$
여기서 $q$는 시스템 설정(configuration), $u$는 로봇의 제어 입력(actuated configuration command), $P$, $b$, $J_i$, $c_i$는 $q, u$에 의존하는 행렬/벡터, $I_c$는 접촉 쌍 인덱스 집합, $K_i$는 가능한 속도(velocity)의 feasible cone이다. 이 SOCP의 KKT 조건은 준동적(quasi-dynamic) 운동 방정식, 비관통(non-penetration), 마찰 원뿔(friction cone), 상보성(complementarity) 제약을 만족한다.

이 모델의 직접적인 미분은 접촉 모드 전환으로 인해 기울기가 불연속적이다. 이를 완화하기 위해 본 논문은 로그 배리어(log-barrier) 스무딩을 적용한 완화된 동역학 $f_\kappa(q,u)$를 사용한다. 이 완화된 동역학은 스무딩 파라미터 $\kappa$에 의존하며, 접촉이 없는 객체 사이에도 힘을 발생시킨다. 스무딩된 동역학의 기울기는 민감도 분석(sensitivity analysis)을 통해 얻을 수 있다.

본 논문은 smoothed dynamics의 Taylor 근사를 사용하여 다음 상태 $\hat{q}_+$와 접촉력 $\hat{\lambda}_{+,i}$에 대한 선형 모델을 구축한다:
$$
\begin{aligned} \hat{q}_+ &= A_\kappa \delta q + B_\kappa \delta u + f_\kappa(\bar{q}, \bar{u}), \\ \hat{\lambda}_{+,i} &= C_{\kappa,i} \delta q + D_{\kappa,i} \delta u + \lambda_{\kappa,i}(\bar{q}, \bar{u}). \end{aligned}
$$
여기서 $(\bar{q}, \bar{u})$는 현재 nominal point이고 $(\delta q, \delta u)$는 perturbation이다.

Ellipsoidal Trust Region (ETR)은 $(\delta q, \delta u)$에 대해 $\delta z^\top \Sigma \delta z \leq 1$ 형태의 제약을 가한다. 그러나 이는 접촉의 비대칭성을 포착하지 못한다.

Contact Trust Region (CTR)은 ETR 제약에 더하여, 위 선형 모델로 예측된 다음 상태 $\hat{q}_+$와 접촉력 $\hat{\lambda}_{+,i}$가 *원래 비완화된 SOCP 동역학의* primal 및 dual feasibility constraint를 만족해야 한다는 제약을 추가한다:
$$
\begin{aligned} J_i \hat{q}_+ + c_i &\in K_i, \\ \hat{\lambda}_{+,i} &\in K_i^*. \end{aligned}
$$
이러한 제약은 선형화된 변수에 대해 부과되므로, CTR은 여전히 볼록 집합(convex set)이다 (구체적으로, 여러 개의 second-order cone constraints의 교집합). Example 1과 2를 통해, primal feasibility 제약($J_i \hat{q}_+ + c_i \in K_i$)이 때때로 실제 도달 가능한 영역보다 trust region을 지나치게 보수적으로 제한함을 보여준다.

따라서 본 논문은 primal feasibility 제약을 완화한 Relaxed Contact Trust Region (R-CTR)을 제안한다. R-CTR은 ETR 제약과 dual feasibility 제약($\hat{\lambda}_{+,i} \in K_i^*$)만을 포함한다. Example 3은 R-CTR을 사용한 Motion Set(선형화된 primal solution map에 의한 RA-CTR의 이미지)이 객체 움직임의 지역적 도달 가능성을 더 잘 포착함을 보여준다. 또한, RA-CTR과 그에 따른 Wrench Set, Motion Set 개념은 고전적인 접촉 역학 개념과 연결될 수 있음을 이론적으로 보인다 (Lemma 2).

**지역 계획 및 제어 (Local Planning and Control)**

제안된 R-CTR은 지역 궤적 최적화(trajectory optimization) 및 MPC에 활용된다. Algorithm 1은 R-CTR 제약을 포함하는 SOCP subproblem을 반복적으로 해결하여 nominal trajectory를 개선하는 방식이다. 이 방법은 smoothed dynamics의 선형 근사를 사용하지만, R-CTR을 통해 지역적으로 유효한 영역 내에서 계획이 이루어지도록 한다. 특히, 접촉이 없는 초기 상태에서 시작할 경우, 로봇이 객체에 접촉하도록 유도하는 초기 추측 휴리스틱을 적용하여 계획의 효율성을 높인다. Example 4와 5는 이 방법이 접촉 모드 전환을 탐색하고 계획에 유리한 방향으로 나아가는 과정을 보여준다.

Algorithm 2는 Algorithm 1을 MPC 프레임워크에 적용한 것이다. 현재 상태에서 미래 상태까지의 궤적을 계획하고, 계획된 첫 번째 제어 입력을 실제 시스템에 적용한 후, 다음 상태를 관찰하여 다시 계획을 수행한다 (re-planning).

**실험 결과 (Experiments)**

본 논문은 IiwaBimanual (planar, 29 collision geometries) 및 AllegroHand (3D in-hand, 39 collision geometries) 두 가지 접촉이 많은 로봇 시스템에서 제안된 방법론을 포괄적으로 평가한다.

1.  **CQDC 동역학에서의 지역 MPC 성능 (Section 5):**
    *   R-CTR, CTR, ETR을 사용하는 MPC의 목표 도달 성능(최종 객체 위치/회전 오류) 비교.
    *   생성된 목표는 지역적으로 도달 가능하나 MPC에 도전적인 목표들이다 (Figure 9).
    *   결과(Figure 9, Table 2): R-CTR이 두 시스템 모두에서 평균 오류 및 분산 측면에서 가장 좋은 성능을 보였다. 특히 IiwaBimanual에서 CTR 및 ETR보다 유의미하게 우수했다. AllegroHand에서는 차이가 비교적 작았는데, 이는 시스템 특성상 bilateral contact regime이 더 자주 활성화될 수 있기 때문으로 추측된다.
    *   Trust region radius(r)와 MPC rollout horizon(H)에 대한 실험(Figure 10): 적절한 r과 H에서 성능이 최적화되며, 너무 작은 r은 도달 가능성을 제한하고 너무 큰 r은 선형 근사의 부정확성으로 인해 성능 저하를 야기한다.

2.  **2차 동역학 하에서의 안정화 성능 (Section 6):**
    *   CQDC 동역학 모델과 실제 물리(Drake 시뮬레이션 및 하드웨어) 간의 차이(특히 hydroplaning)를 고려한 안정화 성능 평가.
    *   Algorithm 3을 제안: MPC 계획을 여러 물리 스텝에 걸쳐 실행하고, 재계획 시 현재 로봇 상태에 대해 초기 추측 휴리스틱을 다시 적용하여 접촉 유지를 강화 (MPCProj).
    *   Open-loop, No Heuristics, Closed-loop 세 가지 알고리즘 변형 평가.
    *   결과(Figure 11, Table 4):
        *   Closed-loop MPC는 Open-loop보다 훨씬 우수한 성능을 보이며, 접촉 동역학 모델의 부정확성에도 불구하고 피드백이 중요함을 시사한다.
        *   초기 추측 휴리스틱 적용(Closed-loop vs. No Heuristics): 평균 오류 감소 효과는 작지만, 접촉 손실로 인한 큰 오류 발생 빈도를 유의미하게 줄였다 (Figure 11 histogram). 휴리스틱 적용은 로봇 경로 길이를 단축시키는 효과도 있었다 (Figure 12).
        *   IiwaBimanual과 AllegroHand 비교: AllegroHand 태스크(in-hand manipulation)의 본질적인 어려움(미끄러짐)으로 인해 IiwaBimanual보다 평균 오류가 컸다.
        *   하드웨어 실험: 시뮬레이션 결과와 유사한 성능을 보였다 (Table 4).

**전역 계획 (Global Planning)**

지역 MPC는 비탐욕적 움직임이 필요한 전역 목표 달성에 한계가 있다. 이를 해결하기 위해 본 논문은 지역 MPC의 장점을 활용하는 로드맵(Roadmap) 기반 전역 계획 방법을 제안한다.

1.  **목표 상태 기반 접촉 설정 생성 (Section 7):**
    *   주어진 객체 상태($q_o$)와 목표($q_{og}$)에 대해, 지역 MPC가 효율적으로 목표에 도달하도록 유리한 로봇 설정($q_a$)을 찾는 문제 정의.
    *   최적화 문제의 비용 함수는 지역 MPC의 유한 시간 가치 함수($V$)와 강건성(robustness) regularizer($r$)를 조합한다. $r$은 RA-CTR 기반 wrench set의 최대 내접구 반경으로 정의되며, 이 설정에서 로봇이 객체에 얼마나 큰 외란을 견딜 수 있는지를 나타낸다. 비용 함수는 $C(q_a; q_o, q_{og}) = V(q_a; q_o, q_{og}) - \alpha r(q_a; q_o)^2$ 형태이다.
    *   이 문제는 비볼록하며 기울기 계산이 어렵기 때문에 샘플링 기반 최적화 휴리스틱으로 해결한다. AllegroHand와 같은 고차원 로봇의 경우, reduced-order model (4개의 sphere)을 사용하고 그 해를 역기구학(IK)으로 로봇 설정에 매핑하는 휴리스틱을 도입한다.
    *   결과(Figure 18, Table 6): AllegroHand에서 직관적이고 목표 달성에 효과적인 초기 로봇 설정들을 찾았으며, MPC 롤아웃 결과 10mm 이내의 위치 오류와 30mrad 이내의 회전 오류를 달성했다.

2.  **로드맵 기반 전역 계획 (Section 8):**
    *   오프라인 단계(Algorithm 4): 작업 공간을 충분히 커버하는 안정적인 객체 설정들에 해당하는 접촉 설정들을 로드맵의 정점(vertices)으로 생성한다. 각 정점 쌍에 대해 지역 MPC(객체 목표 도달)와 충돌 회피 계획(로봇 재배치)을 순차적으로 적용하여 전이가 성공하면 에지(edge)를 추가한다 (Figure 19). AllegroHand의 경우 객체의 대칭성을 활용하여 로드맵 구축을 효율화했으며, 표준 노트북 CPU만으로 10분 이내에 로드맵 구축이 가능하다. 하드웨어에서 150회 연속 에지 전이에 성공하며 로드맵의 강건성을 확인했다.
    *   온라인 단계: 임의의 시작 설정에서 임의의 목표 객체 설정까지의 계획은, 시작/목표를 로드맵의 가장 가까운 정점에 연결한 후 그래프 상에서 최단 경로를 탐색하는 방식으로 수행된다 (Figure 20).

**결론 (Conclusion)**

본 논문은 Contact Trust Region(CTR) 개념을 통해 접촉의 비대칭성을 고려한 지역적 동역학 근사를 제공하고, 이를 활용하여 효율적인 MPC 기반 지역 계획 및 제어 방법을 개발한다. 또한, 접촉 설정 생성 및 로드맵 기법을 통해 전역적인 접촉이 많은 조작 계획 능력을 구현했다. 제안된 방법은 시뮬레이션 및 실제 하드웨어 실험을 통해 그 성능과 계산 효율성을 입증했다. 특히 심층 강화 학습(deep RL) 기반 접근 방식에 비해 현저히 낮은 계산 시간으로 목표 달성이 가능함을 보여준다.

하지만 여전히 해결해야 할 과제들이 남아있다. 특정 계획 실패의 원인, IiwaBimanual과 AllegroHand 간 feasibility constraint의 역할 차이에 대한 깊은 이해, 그리고 CQDC의 hydroplaning과 같은 모델-현실 물리 간의 차이를 극복하고 접촉을 강건하게 유지하는 문제 등은 향후 연구가 필요하다. 그럼에도 불구하고 본 논문에서 제시된 CTR, MPC, 접촉 설정 생성, 로드맵 기법은 접촉이 많은 로봇 조작 문제를 해결하기 위한 새로운 강력한 도구들을 제공한다.

---

# Detail Review

## CTR 최적화 프레임워크

**개요:** 접촉 신뢰 영역(Contact Trust Region, CTR)은 기존의 타원형 신뢰영역(Ellipsoidal Trust Region, ETR)을 확장하여, **접촉 동역학의 물리 제약 조건을 명시적으로 포함**하는 새로운 신뢰영역 모델입니다. 핵심 아이디어는 선형화 오차를 제어하는 작은 타원형 영역뿐 아니라, **접촉 가능성 제약 조건(일방향 접촉력, 마찰 원뿔 제약 등)**도 함께 적용하여, 탐색 가능한 지역을 현실적인 물리 범위 내로 제한하는 것입니다.

### 1. 미분 가능한 접촉 동역학 모델

CTR은 **미분 가능한 접촉 시뮬레이터**를 활용합니다. 특히, 이전 연구인 *Convex Quasi-Dynamic Contact (CQDC)* 모델을 기반으로, 접촉 동역학을 **볼록 최적화 문제(SOCP 등)**로 표현합니다. 이 모델을 풀면 다음 상태뿐 아니라 접촉력까지 계산되며, **상태와 제어 입력에 대한 감도(Jacobian)**도 함께 얻을 수 있습니다. 이는 접촉력을 쌍대변수(dual variable)로 간주한 **KKT 조건 민감도 해석**을 통해 가능해집니다.

### 2. 상태 및 접촉력의 선형화

미분 가능한 모델을 기반으로, 다음 상태 \$\hat{q}*+\$와 접촉력 \$\hat{\lambda}*+\$는 다음과 같이 선형 근사됩니다:

* **상태 업데이트:**
  $\hat{q}_+ = A_\kappa \, \delta q + B_\kappa \, \delta u + f_\kappa(\bar{q}, \bar{u})$
* **접촉력 응답:**
  $\hat{\lambda}_{+,i} = C_{\kappa,i} \, \delta q + D_{\kappa,i} \, \delta u + \lambda_{\kappa,i}(\bar{q}, \bar{u})$

이는 표준적인 상태 선형화와 달리, **접촉력 변화**까지 함께 근사하므로, 접촉의 1차 응답을 정밀하게 반영할 수 있습니다.

### 3. 접촉 가능성 제약(Contact Feasibility Constraints)

CTR은 위 선형화 모델에 대해, 다음과 같은 **물리 기반 제약**을 적용합니다:

* **비침투 조건 (Primal feasibility):**
  $\hat{J}_i \, \hat{q}_+ + \hat{c}_i \in K_i$
  → 접촉면에서의 상대 운동이 interpenetration을 유발하지 않도록 제한

* **마찰 원뿔 조건 (Dual feasibility):**
  $\hat{\lambda}_{+,i} \in K_i^*$
  → 마찰 계수 및 일방향 접촉력 조건(정상 마찰력은 0 이상) 보장

이러한 조건은 **2차원 원뿔 제약(SOCP)** 형태로 정식화되며, 신뢰 영역 내의 모든 후보해가 **접촉 가능성 물리 법칙을 만족하도록 보장**합니다.

### 4. 접촉 신뢰 영역의 수학적 정의

CTR은 다음의 조건을 만족하는 \$(\delta q, \delta u)\$의 집합으로 정의됩니다:

1. **타원형 제약:**
   $\delta z^T \Sigma \delta z \leq 1 \quad (\delta z = [\delta q; \delta u])$
2. **선형화된 상태 및 접촉력 식 만족**
3. **비침투 제약:** \$\hat{q}\_+\$가 접촉면을 침투하지 않음
4. **마찰 원뿔 제약:** \$\hat{\lambda}\_{+,i}\$가 원뿔 내부에 위치함

CTR은 이러한 제약들의 교집합이며, 이는 **볼록 집합(convex set)**입니다. 따라서 이후의 최적화 단계도 **볼록 최적화 문제(SOCP)**로 유지됩니다.

### 5. 변형: A-CTR, R-CTR

* **A-CTR (Action-only CTR):** 상태는 고정하고 입력 \$\delta u\$만을 탐색하는 경우. 계산량이 줄어 빠른 추론 가능
* **R-CTR (Relaxed CTR):** 비침투 조건을 제거하고 마찰 제약만 적용하여 **보수성 완화 및 탐색 반경 확대**

실험 결과 R-CTR이 오히려 더 높은 성능을 보이는 경우가 있었으며, 이는 최적화가 **덜 제한적인 방향**으로도 유효한 접촉 조작을 계획할 수 있기 때문입니다.

---

## CTR 기반 모델 예측 제어(MPC) 통합

CTR은 그 자체로는 하나의 제약 조건 집합이지만, 이를 실질적인 조작 제어기로 사용하려면 **MPC(모델 예측 제어)** 프레임워크 내에 통합해야 합니다. 본 섹션에서는 CTR이 어떻게 MPC에 통합되고, 접촉-풍부한 조작을 실시간으로 실행 가능한 최적화 문제로 변환하는지를 설명합니다.

### 1. 접촉 암시적(contact-implicit) MPC

CTR 논문에서는 **접촉-암시적(contact-implicit)** MPC 문제를 구성합니다. 즉, 접촉 모드 전이를 미리 명시하지 않고, **접촉 여부 및 접촉력의 발생을 최적화 과정에서 자동으로 결정**합니다.

* 각 시점에서 CQDC 기반 선형화를 통해 상태 및 접촉력에 대한 선형 모델을 생성
* CTR 제약(접촉 가능성, 마찰 등)을 적용한 SOCP 문제를 구성
* 일정 시간 지평(horizon) 내에서 최적화한 후, 첫 번째 제어 입력만 적용하고 다시 반복 (Receding Horizon Planning)

CTR의 구조 덕분에 이 MPC 문제는 **전 구간에서 볼록 최적화(SOCP)**로 유지됩니다.

### 2. 반복 최적화 및 피드백

CTR-MPC는 일반적인 MPC와 마찬가지로 매 타임스텝마다 **새로운 상태를 관측하고, 선형화를 새로 수행한 후 최적화**합니다. 이러한 반복 피드백 구조는 다음과 같은 이점을 제공합니다:

* 모델링 오류나 외란에 대한 **강건성 확보**
* 접촉 변화나 미세한 환경 조건 변화에 대한 실시간 적응

### 3. 모드 전이 없이 접촉 처리

CTR-MPC는 **접촉 모드 전이(mode scheduling)**를 명시적으로 기술할 필요가 없습니다. 다음의 수식 조건을 통해 **접촉의 생성과 소멸을 자연스럽게 포함**합니다:

* \$\hat{\lambda}*{+,i} \in K\_i^\*\$ 조건은 \$\hat{\lambda}*{+,i} = 0\$ (접촉 없음)도 허용
* \$\hat{J}*i \hat{q}*+ + \hat{c}\_i \in K\_i\$는 물체와 손가락이 떨어져 있을 때도 비침투 조건을 만족하도록 허용

이러한 설계는 **접촉 모드를 명시적으로 분기시키는 기존 방법들보다 훨씬 유연하고 계산 효율적**입니다.

### 4. 계산 효율성

CTR-MPC의 각 최적화는 **볼록 문제(SOCP)**로 구성되며, 논문에서는 다음과 같은 실험 결과를 보고합니다:

* Allegro 핸드로 큐브를 조작하는 작업에서, **온라인 최적화는 수 초 이내에 실행 가능**
* 전체 조작을 위한 **조작 동작 그래프(로드맵)를 구축하는 데 10분 미만 소요**

이는 일반적인 강화학습 기반 접근보다 훨씬 **낮은 계산 자원**으로 유사한 성능을 달성할 수 있음을 의미합니다.

### 5. 예시 작업 및 결과

CTR-MPC는 두 가지 실제 예시에서 검증되었습니다:

* **양팔 조작 (Bimanual Manipulation):** 두 개의 KUKA iiwa 팔로 큰 원통형 물체를 이동시키는 작업. 복잡한 접촉 협응이 필요하지만, CTR-MPC는 시뮬레이션과 실제 로봇 모두에서 성공적으로 수행.

* **손 안 큐브 회전 (In-Hand Manipulation):** Allegro 핸드로 큐브를 다양한 방향으로 회전시키는 작업. **Relaxed CTR (R-CTR)**을 사용한 경우가 가장 높은 성능을 보였으며, **로드맵 기반 전략**으로 장거리 목표 회전도 달성 가능했음.

### 6. 전역 계획과의 통합

CTR-MPC는 본질적으로 로컬 최적화 기반이므로, 전체 상태 공간에서의 경로 계획은 어려울 수 있습니다. 이를 보완하기 위해 논문에서는 **전역 로드맵 기반 계획(global roadmap planning)**을 제안합니다:

* 큐브의 다양한 **안정된 포즈를 노드로 구성**
* CTR-MPC를 이용해 이들 노드 간 **단거리 조작 궤적(edge)**를 생성
* 전체 그래프를 탐색하여 **멀리 떨어진 목표도 순차적 조작으로 도달 가능**

이 방식은 전통적인 샘플링 기반 계획과 유사하지만, **MPC 기반 동작 원시(primitive)**를 사용하여 접촉-풍부한 경로 생성을 가능케 합니다.

---

## DeXtreme: 강화학습 기반 큐브 회전 제어

**DeXtreme**(NVIDIA Research, 2022)은 심층 강화학습 기반으로 학습된 정책(policy)을 통해, **저비용 로봇 핸드**에서도 정밀한 큐브 회전을 수행한 시스템입니다. 이 접근법은 CTR이 다룬 Allegro 핸드의 조작 문제와 동일한 문제 설정에서, 전혀 다른 방식으로 해결책을 제시합니다.

### 1. 시뮬레이션 기반 학습

* **Isaac Gym**이라는 GPU 가속 물리 시뮬레이터를 사용해 정책을 학습
* 무려 **10만 개 이상의 병렬 환경**을 GPU에서 동시 실행
* 이로 인해 로봇은 **초인적인 속도로 시행착오 학습** 가능

### 2. 정책 구조

* 정책은 심층 신경망으로 구성되며, 입력은 로봇 상태 및 물체 자세 정보
* **비전 기반 정책**도 학습됨: RGB 카메라 3대를 사용해 물체 자세 추정 후 입력으로 활용
* 별도의 **포즈 추정 신경망**을 함께 학습시켜, 시각 정보에서 3D 물체 자세를 복원

### 3. 도메인 랜덤화(Domain Randomization)

* 시뮬레이션-현실 간 격차(Sim2Real gap)를 극복하기 위해 **물리 속성 및 시각 조건을 광범위하게 랜덤화**

  * 질량, 마찰계수, 표면 텍스처, 조명 조건, 카메라 위치 등
* 이로 인해 정책은 **넓은 조건 분포에 대해 강건한 행동 전략**을 학습함

### 4. 학습 비용 및 계산 자원

* 약 **32시간 동안 고성능 GPU 서버에서 학습**
* 이 동안 정책은 약 **42년치에 해당하는 시뮬레이션 경험을 축적**
* 이는 강화학습의 대표적인 단점인 **샘플 비효율성**을 보여주는 지표

### 5. 실행 및 실제 로봇 적용

* 학습 완료 후, 정책은 **고속 실시간 제어 가능** (신경망 전방 연산만 수행)
* Allegro 핸드에서 목표 방향으로 큐브를 안정적으로 회전시킴
* OpenAI의 Shadow Hand와 달리, **관절 수가 적고 비용도 낮은** Allegro 핸드에서 성공한 점이 인상적임

### 6. 일반화 및 강건성

* 도메인 랜덤화를 통해, **하드웨어 손상에도 견디는 강건성** 확보

  * 예: 엄지 관절이 느슨한 상태에서도 정책이 보상하며 동작 성공
* 시각 네트워크는 **가림(occlusion)** 및 **모션 블러**에도 견딜 수 있도록 학습됨

### 7. 정책의 한계

DeXtreme은 놀라운 성능을 보여줬지만, CTR 접근과 달리 **접촉 물리 법칙을 명시적으로 반영하지는 않음**:

* 마찰 원뿔, 비침투 조건 등은 **학습을 통해 암묵적으로 습득**
* 행동은 시뮬레이터의 물리 엔진과 보상 함수 설계를 통해 유도됨
* 따라서 정책은 **왜 해당 동작을 수행하는지 해석하기 어렵고**, **제약 조건 위반 여부도 명시적으로 판단하기 어려움**

---

## CTR vs DeXtreme: 두 접근 방식의 비교 분석

CTR-MPC와 DeXtreme은 모두 **손 안의 큐브 회전과 같은 고난도 접촉 조작**을 목표로 하지만, **모델 기반 최적화**와 **데이터 기반 학습**이라는 정반대의 철학을 가지고 접근합니다. 아래는 두 방법론을 주요 관점에서 비교한 내용입니다.

### 1. 접촉 처리 방식

| 항목            | CTR-MPC                                     | DeXtreme (RL)                                      |
| ------------- | ------------------------------------------- | -------------------------------------------------- |
| **접촉 모델링**    | 마찰 원뿔, 비침투 조건 등을 **명시적 수식으로 모델링**하고 최적화에 통합 | 시뮬레이션과 보상을 통해 **암묵적으로 접촉 전략을 학습**                  |
| **접촉력 추론**    | 접촉력은 최적화 변수로 직접 계산되며, 계획 과정에서 사용됨           | 신경망 내부에서 암묵적으로 형성됨 (관측 불가)                         |
| **물리 위반 가능성** | 수식 제약으로 인해 **물리 법칙 위반 불가능**                 | 학습된 정책이 **물리 제약을 위반할 수 있음** (ex. interpenetration) |

### 2. 샘플 효율성과 계산 자원

| 항목             | CTR-MPC          | DeXtreme (RL)         |
| -------------- | ---------------- | --------------------- |
| **사전 학습 필요성**  | 없음 – 매 실행마다 최적화  | 필요 – 수십억 스텝의 시뮬레이션 필요 |
| **실행 시 계산 비용** | 중간 – SOCP 최적화 수행 | 매우 낮음 – 신경망 전방 연산만 수행 |
| **샘플 효율성**     | 매우 높음 – 모델 기반 추론 | 낮음 – 방대한 시행착오 필요      |

### 3. 일반화와 적응성

| 항목           | CTR-MPC              | DeXtreme (RL)              |
| ------------ | -------------------- | -------------------------- |
| **환경 변화 대응** | 모델만 수정하면 즉시 대응 가능    | 사전 학습된 분포 외에는 **재학습 필요**   |
| **목표 변화 적응** | 즉시 가능 (목표 상태만 바꾸면 됨) | 가능하나, 정해진 목표 형식 내에서만 일반화됨  |
| **외란 대응성**   | 고 – 재계획 기반           | 중 – 일부 외란에는 강건하나 계획 능력은 없음 |

### 4. 정책 구조와 해석 가능성

| 항목               | CTR-MPC                 | DeXtreme (RL)       |
| ---------------- | ----------------------- | ------------------- |
| **정책 형태**        | 최적화 기반 – 현재 상태에서 계획을 계산 | 신경망 기반 – 관측 → 행동 매핑 |
| **해석 가능성**       | 높음 – 접촉력, 제약 조건 등 확인 가능 | 낮음 – 블랙박스 정책        |
| **제약 조건 추가 용이성** | 용이 – 수식 삽입만으로 반영 가능     | 어려움 – 네트워크 재학습 필요   |

### 요약

| 항목             | CTR-MPC     | DeXtreme (RL) |
| -------------- | ----------- | ------------- |
| **접촉 처리**      | 명시적, 해석 가능  | 암묵적, 해석 불가    |
| **학습 필요성**     | 없음          | 큼 (수십억 스텝)    |
| **실행 속도**      | 느리지만 정확     | 매우 빠름         |
| **일반화**        | 모델 기반 적응    | 제한된 목표 내 일반화  |
| **확장성 및 유지보수** | 제약 추가/변경 쉬움 | 재학습 필요        |

---

## 결론 및 향후 연구 방향

CTR과 DeXtreme은 각각 **정확하고 물리적으로 해석 가능한 모델 기반 계획**과 **빠르고 강건한 데이터 기반 제어**라는 상반된 강점을 보여줍니다. 이러한 성격의 차이는 오히려 **상호보완적인 통합 가능성**을 시사합니다.

### 1. 하이브리드 전략의 가능성

앞으로의 연구는 다음과 같은 하이브리드 모델을 탐색할 수 있습니다:

* **CTR으로 생성된 궤적을 imitation learning의 teacher로 활용**

  * RL의 초기 정책을 빠르게 수렴시킬 수 있음
* **DeXtreme 정책을 warm-start로 사용하여 CTR 최적화를 가속**

  * 최적화 초기화를 RL 정책 기반으로 설정해 연산량 감소
* **접촉 모델의 일부를 학습된 근사 모델로 대체**

  * 예: 마찰계수 추정, 감쇠 계수 추정 등 실제 환경 파라미터 보정

이처럼 양측의 장점을 조합하는 방식은, **물리 기반 정확성과 학습 기반 유연성**을 동시에 확보할 수 있는 유망한 방향입니다.

### 2. 실시간성 향상

CTR-MPC의 경우, 최적화의 실시간성은 여전히 제한적입니다. 이를 해결하기 위해 다음과 같은 접근이 제안될 수 있습니다:

* **CTR 기반 정책을 사전 학습해 신경망으로 근사 (Policy Distillation)**
* **CTR 해를 데이터셋으로 수집 후, offline RL이나 trajectory matching으로 정책 학습**

이러한 방식은 **제약 조건을 만족하는 정책을 빠르게 실행**할 수 있게 해줄 뿐 아니라, **정책의 해석 가능성**도 부분적으로 유지할 수 있습니다.

### 3. 보다 복잡한 조작 작업 확장

향후 연구는 다음과 같은 더 복잡한 작업으로의 확장을 목표로 할 수 있습니다:

* **비정형 물체 조작** (불규칙한 형상, 연성 물체 등)
* **시각 기반 입력 통합** (CTR과 카메라 인식 결합)
* **사람과의 협업 조작** (공동 운반, 안전 제약 등 포함)

특히 CTR 기반 접근은 **제약 조건 기반의 신뢰성과 안전성**을 활용해, 사람과 함께하는 환경에서도 활용 가능성을 보여줍니다.

---

## 마무리

"Dexterous Contact-Rich Manipulation via the Contact Trust Region" 논문은 고난도 조작에서 접촉 제약을 어떻게 명시적으로 다루고, 이를 모델 기반 제어 프레임워크에 통합할 수 있는지를 수학적으로 우아하게 풀어낸 작업입니다. 그에 비해 DeXtreme은 대규모 계산 자원을 활용한 전통적인 심층강화학습 방식이지만, 실제 적용성에 있어 매우 강력한 접근임을 보여줍니다.

이 두 흐름은 서로 경쟁적이라기보다, **다음 세대의 조작 시스템에서 병렬적으로 사용될 수 있는 기술 스펙트럼의 양극단**으로 이해될 수 있습니다.

앞으로의 연구는, 이들 방법론을 상황에 따라 선택하거나 조합함으로써, **보다 유연하고 안전하며 일반화 가능한 로봇 조작 시스템**을 구축하는 데 기여할 수 있을 것입니다.
