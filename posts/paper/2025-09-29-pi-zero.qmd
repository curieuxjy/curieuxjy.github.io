---
title: "📃π0 리뷰"
date: 2025-09-29
categories: [vla, flow, cross-embodiment]
toc: true
number-sections: False
description: A Vision-Language-Action Flow Model for General Robot Control
---

- [Paper Link](https://www.physicalintelligence.company/download/pi0.pdf)
- [Homepage](https://www.physicalintelligence.company/blog/pi0)
- [Code Link](https://github.com/Physical-Intelligence/openpi)

1. π0는 사전 학습된 Vision-Language Model(VLM) 백본과 플로우 매칭(flow matching) 아키텍처를 기반으로 로봇 제어의 일반성과 정밀성을 향상시킨 새로운 로봇 파운데이션 모델입니다.
2. 이 모델은 인터넷 규모의 시맨틱 지식을 활용하며, 7가지 로봇 구성과 68개 작업에 걸친 10,000시간 이상의 방대한 교차-embodiment 데이터셋으로 사전 학습 및 미세 조정을 거칩니다.
3. 실험 결과, π0는 빨래 개기, 상자 조립 등 복잡하고 섬세한 조작 작업에서 기존 모델들을 능가하는 강력한 성능을 보여주며, VLM 사전 학습이 언어 지시 이해 능력을 크게 향상시킴을 입증했습니다.

---

# Brief Review

이 논문은 유연하고 일반적이며 정교한 로봇 시스템을 위한 범용 로봇 제어 정책인 π0를 제안합니다. 이 모델은 Vision-Language Model (VLM)을 백본으로 활용하고, 인터넷 규모의 방대한 데이터에서 학습된 의미론적 지식을 로봇 제어로 확장하는 것을 목표로 합니다.

π0의 핵심 방법론은 다음과 같습니다:

1.  **VLM 백본 활용**: PaliGemma [5]와 같은 사전 학습된 VLM을 기반으로 하여, 이미지와 텍스트로부터 학습된 광범위한 지식, 의미론적 추론 및 문제 해결 능력을 계승합니다. 이는 인터넷 규모의 데이터에서 얻은 경험을 로봇 제어에 통합하는 역할을 합니다.
2.  **Flow Matching을 통한 연속적인 액션 생성**: 기존의 VLA 모델들이 주로 autoregressive discretization 방식을 사용하여 액션을 텍스트 토큰처럼 처리하는 것과 달리, π0는 `conditional flow matching` [28, 32]을 도입하여 연속적인 액션 분포를 모델링합니다. Flow matching은 `diffusion` [20, 46]의 한 변형으로, 고주파수 (최대 50 Hz)의 액션 청크(action chunk) [57]를 정밀하게 모델링하고 복잡한 연속 액션 분포를 표현할 수 있어 세밀한 조작(dexterous manipulation)이 요구되는 작업에 특히 적합합니다. 액션 청크 $A_t = [a_t, a_{t+1},..., a_{t+H-1}]$는 미래 H 스텝의 액션을 나타내며, H는 50으로 설정됩니다.
    학습 시 손실 함수는 다음과 같습니다:
    $$L_\tau (\theta) = \mathbb{E}_{p(A_t|o_t), q(A_t^\tau|A_t)}[\|v_\theta (A_t^\tau, o_t) - u(A_t^\tau|A_t)\|^2]$$
    여기서 $o_t$는 관측값 (다중 RGB 이미지, 언어 명령어, 로봇의 고유수용성 상태), $A_t^\tau$는 노이즈가 추가된 액션 청크, $v_\theta$는 학습된 벡터 필드, $u$는 디노이징 벡터 필드입니다. 확률 경로(probability path)는 $q(A_t^\tau|A_t) = \mathcal{N}(\tau A_t, (1-\tau)\mathbf{I})$로 정의되며, 디노이징 벡터 필드 $u(A_t^\tau|A_t) = \epsilon - A_t$는 무작위 노이즈 $\epsilon \sim \mathcal{N}(0, \mathbf{I})$와 실제 액션 $A_t$로 구성됩니다. 추론 시에는 학습된 벡터 필드를 $\tau = 0$에서 $\tau = 1$까지 `forward Euler integration` 규칙을 사용하여 통합하여 액션을 생성합니다:
    $$A_t^{\tau+\delta} = A_t^\tau + \delta v_\theta (A_t^\tau, o_t)$$
    이때 $\delta$는 통합 스텝 크기이며, 실험에서는 10개의 통합 스텝을 사용합니다 ($\delta=0.1$).
3.  **액션 전문가 (Action Expert) 아키텍처**: VLM 백본에 로봇 고유의 입력 (고유수용성 상태 $q_t$) 및 출력 (액션 $A_t$)을 처리하기 위한 별도의 가중치 세트("액션 전문가")를 추가합니다. 이는 이미지 및 텍스트 입력을 처리하는 VLM 백본과 로봇 관련 입출력을 처리하는 액션 전문가로 구성된 `mixture of experts` [45] 디자인과 유사합니다. PaliGemma (30억 파라미터)와 액션 전문가 (3억 파라미터)를 결합하여 총 33억 파라미터의 모델을 구성합니다.
4.  **크로스-엔바디먼트 (Cross-Embodiment) 학습**: 다양한 로봇 플랫폼 (단일 팔 로봇, 이중 팔 로봇, 모바일 매니퓰레이터 등)에서 수집된 데이터를 단일 모델에 결합하여 학습합니다. 이는 다양한 구성 공간과 액션 표현을 가진 로봇 시스템에 대한 일반화를 가능하게 합니다.

**학습 레시피**:

논문은 `pre-training` 및 `post-training` (미세 조정) 단계를 따르는 다단계 학습 절차를 제안합니다.

*   **Pre-training**: Physical Intelligence에서 수집한 7가지 로봇 구성, 68가지 태스크에 대한 정교한 조작 데이터셋 (약 9억 3천만 스텝)과 공개된 OXE [10] 데이터셋 (22개 로봇 포함)을 포함한 대규모의 다양한 데이터 혼합 (총 10,000시간 이상의 로봇 데이터)으로 모델을 사전 학습합니다. 이 단계는 광범위한 기능과 일반화 능력을 부여하는 것을 목표로 합니다.
*   **Post-training**: 사전 학습된 모델을 더 적고 엄선된 고품질의 태스크별 데이터셋으로 미세 조정하여 특정 다운스트림 태스크에 대한 숙련되고 유창한 실행 능력을 부여합니다. 이는 LLM의 "정렬(alignment)" 과정과 유사합니다.

**실험 및 결과**:

π0는 다양한 실험을 통해 그 성능을 입증합니다.

*   **Out-of-box 평가**: 사전 학습만으로도 셔츠 접기, 테이블 정리, 식료품 포장 등의 다양한 태스크에서 기존의 OpenVLA [24] 및 Octo [50]와 같은 로봇 파운데이션 모델들을 크게 능가하는 성능을 보였습니다. 특히, VLM 사전 학습이 없는 π0-small 버전보다 월등한 성능을 보이며 VLM 사전 학습의 중요성을 강조합니다.
*   **언어 명령어 추종**: π0는 언어 명령어 추종 능력에서 π0-small보다 현저히 우수한 성능을 보여, VLM 사전 학습이 모델의 언어 이해 능력 향상에 크게 기여함을 시사합니다. 인간 전문가 또는 `high-level VLM policy`가 제공하는 중간 언어 명령어를 통해 복잡한 태스크를 더 잘 수행할 수 있습니다.
*   **새로운 정교한 태스크 학습**: 사전 학습 데이터와는 다른 새로운 태스크(예: 그릇 쌓기, 수건 접기, 전자레인지에 용기 넣기, 종이 타월 교체, 서랍에 물건 넣기)에 대한 미세 조정 평가에서, π0는 기존의 ACT [57] 및 Diffusion Policy [9]를 포함한 다른 방법들보다 우수한 성능을 보였습니다. 사전 학습은 특히 적은 미세 조정 데이터로도 성능 향상에 기여합니다.
*   **복합 다단계 태스크 숙달**: 세탁물 접기 (정지형/이동형 로봇), 식탁 정리, 상자 조립, 달걀 포장, 도시락 포장 등 복잡하고 시간적으로 확장된 다단계 태스크에서, π0는 사전 학습 및 미세 조정 조합을 통해 높은 성공률을 달성했습니다. 이러한 태스크는 수십 개의 개별 행동과 다양한 물체 구성, 그리고 변형 가능한 물체와 같은 복잡한 물리적 특성을 다루는 능력을 요구합니다. 논문은 이러한 수준의 자율 성능이 정교한 로봇 조작 분야에서 새로운 `state-of-the-art`를 제시한다고 주장합니다.

**결론**:

π0는 VLM 사전 학습과 flow matching 기반 액션 생성, 그리고 대규모의 다각적인 데이터셋을 활용하는 사전 학습-미세 조정 레시피를 통해 범용적이고 정교한 로봇 제어 능력을 달성할 수 있음을 보여줍니다. 이 연구는 로봇 파운데이션 모델의 현실화를 위한 중요한 발걸음으로 평가되며, 미래 연구를 위한 데이터 구성 및 전이 학습 범위 확장 등의 과제를 제시합니다.

---

# Detail Review

> π0: 범용 로봇 제어를 위한 비전-언어-액션 플로우 모델

## 논문의 주요 기여 요약

이 논문에서는 사전학습된 비전-언어 모델(VLM)과 연속 행동 생성용 플로우 매칭(flow matching) 구조를 결합한 새로운 범용 로봇 제어 정책 π0를 제안한다. π0는 인터넷 규모의 시각·언어 정보를 학습한 VLM(예: 3B 파라미터 규모의 PaliGemma)을 백본으로 사용하며, 별도의 액션 전문가(action expert) 모듈을 추가하여 연속적이고 고주파의 로봇 행동을 생성할 수 있다. 학습 방식은 대규모 사전학습(Pre-training) – 파인튜닝(Post-training) 레시피를 따른다. 먼저 7가지 로봇 구성에서 수집된 68개 과제로 이루어진 총 10,000시간 이상의 복잡한 조작 데이터(자사 데이터 + 공개 OXE 데이터셋)를 사용해 모델을 사전학습한다. 그런 다음 고품질 데이터로 파인튜닝하여 세탁물 접기, 상자 조립 같은 복합 다단계 작업을 수행한다. **주요 기여점**은 (1) VLM 기반의 신경망과 플로우 매칭 기반 행동 생성을 통합한 새로운 모델 아키텍처, (2) 다양한 로봇과 작업을 포함하는 대규모 데이터셋 구성 및 사전학습/파인튜닝 레시피, (3) 실험을 통한 일반화 성능 검증이다.

<center>
<img src="../../images/2025-09-29-pi-zero/00.png" width="100%" />
</center>

## 기술적 설명

- 비전-언어-액션 통합: π0의 입력 관찰(observation)은 여러 카메라의 RGB 이미지, 텍스트 명령어, 그리고 로봇 관절 상태(프로프리오셉티브 정보)로 구성된다. 이때 이미지와 텍스트 토큰은 사전학습된 VLM 백본(예: PaliGemma)으로 처리되고, 관절 상태와 예측할 액션 토큰은 별도의 액션 전문가(action expert) 모듈로 분리된다. 즉, 하나의 트랜스포머 모델 안에 두 개의 전문가(experts)를 두어, 이미지·언어 입력은 VLM 전문가로, 로봇 상태 및 행동 토큰은 액션 전문가로 각각 라우팅된다. 이때 블록 단위 인과적(attention mask) 주의 메커니즘을 사용하여, 이미지/언어 정보 블록과 행동 토큰 블록이 서로 영향을 주고받도록 설계되었다.
- Flow Matching을 통한 행동 예측: π0는 플로우 매칭(flow matching)이라는 확산(diffusion) 기법 변형을 사용해 연속 행동 분포를 모델링한다. 학습 시에는 실제 행동에 가우시안 노이즈를 더한 후, 네트워크가 노이즈 추가된 행동( $A^τ$ )에서 원래 행동으로 되돌아가는 노이즈 속도 벡터장을 예측하도록 한다. 이로써 행동 생성이 다중 모드의 연속 분포로 표현되고 높은 정밀도를 유지한다. 추론 시에는 무작위 노이즈로부터 시작하여, 학습한 벡터장을 이용해 여러 단계(논문에서는 10단계, δ=0.1)의 오일러 적분으로 점진적으로 행동 청크(action chunk)를 생성한다. 이 과정에서 모든 행동 토큰은 서로 완전 양방향(attend)이 가능하도록 설계되었으며, 이전에 계산된 키/값은 캐싱하여 효율성을 높였다.
- 액션 청킹(Action Chunking): π0는 H=50 타임스텝에 해당하는 액션 청크를 한꺼번에 예측한다. 즉, 50프레임 분량의 연속 행동 시퀀스를 한 번에 생성하여 고주파(최대 50Hz)의 세밀한 동작이 가능하다. 이는 단일 스텝씩 디코딩하는 기존의 텍스트 토큰 기반 VLA(vision-language-action) 모델이 어려워했던 복잡한 조작 작업에서 유리하게 작용한다.
- 크로스 엠바디드먼트 학습: π0는 서로 다른 로봇 플랫폼들의 데이터를 하나의 모델로 통합 학습한다. 실험에 사용된 로봇은 단일/듀얼 암 로봇(UR5e, Franka 등)과 이동형 로봇(모바일 ALOHA 기반) 등 총 7가지 구성이다. 논문에서는 이들 7개 로봇 구성에서 수집된 68개 작업 데이터와 공개 OXE 데이터셋을 결합해 사전학습했으며 , 이를 통해 서로 다른 로봇 간 경험 공유와 범용 제어 능력을 확보하였다.

## 실험 및 결과 분석
- Out-of-Box 평가: 사전학습된 π0(파인튜닝 없이) 모델은 다양한 조작 작업에 대해 언어 명령만으로도 높은 성능을 보였다. 예를 들어, “티셔츠 접기”, “식탁 치우기(쉬운/어려운 버전)”, “식료품 봉지 담기”, “토스터에서 토스트 꺼내기” 등의 테스트에서 π0는 기존의 대형 비전-언어-액션 모델(OpenVLA 7B)이나 Octo(93M)보다 월등한 성능을 기록했다. 그림 7에 따르면, 연산량(학습 스텝) 동등 조건(160k 스텝)에서도 π0는 모든 작업에서 기존 모델을 앞섰으며, 풀 학습(700k 스텝)을 거친 π0-full은 모든 과제에서 최상의 성능을 보였다. 성능 지표는 작업별 성공률 및 진행도(예: 정답 물체 배치 개수)로 측정되었다.
- 언어 명령 수행: π0는 언어 지시에 따라 물체를 집어놓는 작업에서도 좋은 결과를 보였다. “테이블 비우기”나 “식탁 차리기” 등 일련의 객체 옮기기 작업에서, 단순한 “전체 작업만 명령(π0-flat)” 대신 중간 단계별 명령(π0-human)이나 상위 정책(π0-HL)으로 안내할 때 성공률이 크게 올랐다. 특히 π0는 작은 크기(VLM 비적용)의 비교모델(π0-small)에 비해 언어 이해 능력이 월등하여, 사람이 제공한 단계별 지시를 잘 따랐고, 상위 VLM 정책의 지시를 받았을 때에도 성능 향상이 뚜렷했다. 이는 VLM 사전학습이 언어 명령 수행 능력을 크게 향상시킴을 보여준다.
- 파인튜닝 과제: 파인튜닝을 통해 π0는 새로운 단일 단계 조작 과제도 학습했다. 예를 들어, 쌓아 올린 그릇 정리(stack bowls), 수건 접기(towel folding), 전자레인지 조작 등에서 π0는 비교적 적은 양의 데이터로도 높은 완성도를 달성했다. 그림 11에 따르면, 사전학습된 π0는 무작위 초기화 모델에 비해 적은 학습 데이터(1~10시간)로도 빠르게 성능을 향상시켰으며, 특히 쉬운 과제에서는 소량의 데이터만으로도 50% 이상의 성능을 달성했다. 이는 사전학습이 파인튜닝 데이터 효율성과 일반화에 기여함을 의미한다.
- 복합 다단계 과제: π0는 세탁물 접기, 이동식 세탁물 처리, 건조기 옮기기, 실물 점심 테이블 청소, 박스 조립, 포장 계란 등 매우 복잡한 다단계 작업에서도 성능을 보였다. 그림 12, 13에 나타난 바와 같이, 사전학습+파인튜닝된 π0-full은 모든 과제에서 10회 평균 50% 이상의 점수를 기록했으며, 사전학습 없는 scratch 모델이나 사전학습만(out-of-box) 모델보다 월등히 높은 성능을 보였다. 특히 빨랫감 접기나 박스 조립처럼 난이도가 높은 작업에서는 사전학습 효과가 크게 나타났는데, π0-full은 과제별 최고 점수의 절반 이상을 꾸준히 달성하며 새로운 SOTA 수준의 제어 능력을 입증했다. 이러한 평가는 객관적 채점 기준(1.0 완벽 수행)으로 10회 반복 평균을 사용했다.

## 장점과 한계 분석

- **장점**: π0의 강점은 범용성과 데이터 효율성에 있다. 사전학습된 VLM을 활용함으로써 인터넷 규모의 시각-언어 지식을 계승하여, 각 작업별로 특화된 모델보다 광범위한 상황에 대응할 수 있다. 다양한 로봇 플랫폼의 데이터를 단일 모델로 통합 학습하였기에, 서로 다른 로봇 간 전이 학습이 가능하다. 또한 액션 청킹과 플로우 매칭 덕분에 최대 50Hz의 고주파 연속 제어가 가능하여 세밀한 조작 수행이 가능하다. 실험 결과, 사전학습 π0는 적은 파인튜닝 데이터만으로도 빠르게 성능을 높였는데, 예를 들어 일부 쉬운 과제에서는 1시간 미만의 데이터만으로도 기본 성능에 도달했다.

- **한계**: π0는 현재의 대규모 데이터 요구량과 계산 비용 때문에 현실적 한계도 존재한다. 사전학습에는 10,000시간 이상의 행동 데이터가 필요했고 , 전체 모델 크기는 33억 파라미터에 달한다. 따라서 모델 학습 및 추론 시 고성능 하드웨어와 긴 시간이 필요하다. 실시간 제어 측면에서도, 플로우 매칭은 다중 적분 단계를 요구하므로(논문에서는 10스텝) 응답 지연이 있을 수 있다. 또한 모든 과제에서 완벽한 성공률을 보장하지는 못했다. 논문에서도 일부 과제는 신뢰성에 한계가 있었음을 언급하며, 사전학습 데이터 구성(어떤 작업, 어떤 비율이 중요한지)과 추가 데이터의 효과는 아직 연구 과제로 남아있다. 마지막으로, 실제 로봇에 적용할 때 발생할 수 있는 안전성 문제(예: 예기치 않은 행동, 환경과의 충돌)도 고려되어야 한다.

## 향후 연구 방향

논문 저자들은 데이터 구성과 범용성 등에 대해 추가 연구의 여지를 제시했다. 실제 로봇 시스템으로 확장하려면 실시간 제어와 안전성 보장이 중요하다. 예를 들어, 추론 속도를 높이거나 안전 필터를 추가하는 연구가 필요할 것이다. 모델이 적응성을 갖추도록 온라인 학습이나 도메인 적응 방법도 유망하다. 또한 고수준 계획(Low-level 제어와 상위 레벨 계획 통합)을 위해 언어 기반 플래너나 강화학습 기법과의 연동도 고려할 수 있다. 마지막으로, 논문에서는 자동차 자율주행이나 보행 로봇 등 매우 다른 도메인으로의 확장 가능성도 언급한다. 예를 들어 주행 네비게이션, 보행 제어 같은 분야에 π0 같은 로봇 파운데이션 모델 개념을 적용할 수 있는지 탐구하는 것이 향후 과제다.
