---
title: "ğŸ“ƒIPO"
description: Interior-point Policy Optimization under Constraints
date: "2024-11-02"
categories: [paper, rl, cmdp]
draft: true
toc: true
number-sections: true
image: ../../images/2024-03-17-vcgs/2.png
---

# Introduction

<!--
rlì—ì„œ rewardì—ë§Œ ì´ˆì ì´ ë§ì¶°ì ¸ ìˆì§€ë§Œ constraint ê´€ì ì—ì„œ cmdpì˜ ê°œë…ì„ ì†Œê°œ

- constraint ì˜ ì¢…ë¥˜
- -->

## Constrained Markov Decision Process(CMDP)

## Policy Gradient Methods



ì• ë¶€ë¶„ì—ì„œ ì‚´í´ë³¸ ê²ƒê³¼ ê°™ì´ CMDP Goalì€ Reward ê°’ì„ ìµœëŒ€í™”í•˜ë©´ì„œ ì œì•½ì‹ì„ ë§Œì¡±í•˜ëŠ” ìµœì ì˜ policyë¥¼ ì°¾ëŠ” ê²ƒì´ë¼ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

![7]()

ë¨¼ì € ì œì•½ì¡°ê±´ì„ ì ì‹œ ë’¤ë¡œ ë‘ê³ , ë³¸ë˜ ê¸°ë³¸ì ì¸ ê°•í™”í•™ìŠµì˜ ëª©ì ì‹ì¸ Reward Maximizationì€ ì–´ë–»ê²Œ í• ê¹Œìš”? Policy GradientëŠ” ê°•í™”í•™ìŠµì˜ í•œ ê³„ì—´ë¡œ ìµœì ì˜ policy, ì¦‰ ê°€ì¥ Rewardë¥¼ ë§ì´ ë°›ì„ ìˆ˜ ìˆëŠ” policyë¥¼ ì°¾ê¸° ìœ„í•´ ì•„ë˜ì™€ ê°™ì€ ëª©ì ì‹ì˜ gradientë¥¼ ê³„ì‚°í•˜ê²Œ ë©ë‹ˆë‹¤. ì´ë•Œ ìµœì ì˜ policyë¥¼ ì°¾ê¸° ìœ„í•´ì„œ $\theta$ëŠ” ìœ„ì—ì„œ êµ¬í•œ gradient ê°’ì„ ê¸°ë°˜ìœ¼ë¡œ ì•„ë˜ì™€ ê°™ì´ ì—…ë°ì´íŠ¸í•˜ê²Œ ë©ë‹ˆë‹¤.

![8]()

**Trust Region Policy Optimization(TRPO)**ë¼ëŠ” ì•Œê³ ë¦¬ì¦˜ì´ PGê³„ì—´ì—ì„œ ëŒ€í‘œì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì´ë©°, ìµœì ì´ policyë¥¼ ì°¾ê¸° ìœ„í•´ surrogate functionì„ ì´ìš©í•˜ê³  policyê°€ ì—…ë°ì´íŠ¸ ë˜ëŠ” step sizeë¥¼ ì œí•œí•˜ê¸° ìœ„í•´ KL divergenceë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. TRPOì˜ ìµœì í™” ì‹ì€ ì•„ë˜ì™€ ê°™ì´ í‘œí˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

![9]()

í•˜ì§€ë§Œ TRPOëŠ” [conjugate gradient optimization](https://en.wikipedia.org/wiki/Conjugate_gradient_method)ìœ¼ë¡œ í’€ë¦¬ëŠ” 2ì°¨ ë¯¸ë¶„ ìµœì í™”ë¥¼ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— ê³„ì‚° costê°€ í½ë‹ˆë‹¤. ë”°ë¼ì„œ TRPOë¥¼ ì‹¤ìš©ì ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œí•œ **Proximal Policy Optimization (PPO)** ì•Œê³ ë¦¬ì¦˜ì´ ì œì•ˆë˜ì—ˆìŠµë‹ˆë‹¤. PPOì˜ ìµœì í™” ì‹ì€ TRPOì—ì„œ ë¬¸ì œì˜€ë˜ 2ì°¨ë¯¸ë¶„ì„ 1ì°¨ ë¯¸ë¶„ surrogate functionìœ¼ë¡œ ëŒ€ì²´í•  ìˆ˜ ìˆì—ˆìœ¼ë©° ê³„ì‚°ë³µì¡ì„±ì„ ì¤„ì¼ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. 

IPOëŠ” ì´ëŸ¬í•œ íë¦„ëŒ€ë¡œ ë°œì „í•´ì˜¨ PPO ì•Œê³ ë¦¬ì¦˜ì˜ ìµœì í™” ì‹ì—ì„œ ì œì•½ì‹ì„ ì¶”ê°€í•˜ë©´ì„œ ë°œì „í•˜ê²Œ ë©ë‹ˆë‹¤.




# Method

## Interior-point Policy Optimization

## logarithmic barrier function

# Experiment

## 


# Reference

- [Original Paper: IPO](https://arxiv.org/abs/1910.09615)
- [Presentation Video](https://youtu.be/kTZD6cxTtv8?si=-WMLnODehN9f3rXR)
- [Lagrangian relaxation method Diagram](https://www.researchgate.net/publication/259246799_A_Near-Optimal_Distributed_QoS_Constrained_Routing_Algorithm_for_Multichannel_Wireless_Sensor_Networks)