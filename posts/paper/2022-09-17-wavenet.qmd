---
title: "ğŸ“ƒWaveNet"
description: A Generative Model for Raw Audio
date: "2022-09-17"
categories: [autoregressive, generative, paper]
toc: true
---

![](https://i.imgur.com/s1pIkp9.jpg){fig-align="default"}

ì´ë²ˆ í¬ìŠ¤íŒ…ì€ Google DeepMindì—ì„œ ë°œí‘œí•œ WaveNetì´ë¼ëŠ” ë…¼ë¬¸ì— ëŒ€í•´ ë¦¬ë·°ë¥¼ í•˜ë ¤ê³  í•©ë‹ˆë‹¤. WaveNetì€ Autoregressiveí•œ Generative modelë¡œì¨ [Googleì˜ ìŠ¤í”¼ì»¤ ì„œë¹„ìŠ¤ì— ì‚¬ìš©ë˜ì—ˆë‹¤](https://towardsdatascience.com/wavenet-google-assistants-voice-synthesizer-a168e9af13b1)ê³  ë§ì´ ì•Œë ¤ì§„ ëª¨ë¸ì…ë‹ˆë‹¤. 

> ë¦¬ë·°ì— ì•ì„œì„œ ê°€ì¥ ë„ì›€ì„ ë§ì´ ë°›ê³  ì•„ë˜ í¬ìŠ¤íŒ…ì˜ ìƒë‹¹í•œ ì´ë¯¸ì§€ë“¤ì´ ê¹€ì •í¬ ë‹˜ì˜ [[ë…¼ë¬¸ë¦¬ë·°]WaveNet](https://joungheekim.github.io/2020/09/17/paper-review/) í¬ìŠ¤íŒ…ì—ì„œ ê°€ì ¸ì˜¨ ê²ƒì„ì„ ë°íˆë©° ê°ì‚¬ì˜ ë§ì”€ì„ ì „í•´ë“œë¦¬ê³  ì‹¶ìŠµë‹ˆë‹¤. ê° ì´ë¯¸ì§€ì˜ ì¶œì²˜ëŠ” ìœ—ì²¨ìë¡œ Reference numberingì„ í‘œì‹œí•˜ì˜€ìŠµë‹ˆë‹¤.

# Background

<center>

<img src="https://i.imgur.com/spzO8yA.gif" />

</center>

<div style="text-align:center">
  Raw waveform of the audio<sup>2</sup>
</div>

<p>

</p>

WaveNetì€ ìŒì„± ìƒì„± ëª¨ë¸ë¡œ ë³¸ê²©ì ìœ¼ë¡œ ëª¨ë¸ì— ëŒ€í•´ ì•Œì•„ë³´ê¸° ì „ì— `ì†Œë¦¬`ë¼ëŠ” ê²ƒì´ ì–´ë–»ê²Œ `ì‹ í˜¸`ê°€ ë˜ëŠ”ê°€ë¥¼ ì‚´í´ë³¼ í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤. ì†Œë¦¬ëŠ” ê³µê¸° ì…ìë“¤ì˜ ë–¨ë¦¼ì´ë©° ì¢…íŒŒì˜ íŒŒí˜•ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ `ì†Œë¦¬`ë¼ëŠ” í˜„ìƒì„ íŒŒë™ìœ¼ë¡œ í‘œí˜„í•´ë³´ìë©´, ì•„ë˜ì˜ ê·¸ë¦¼ê³¼ ê°™ì´ ê³µê¸° ì…ìë“¤ì´ ë§ì´ ë°€ì§‘ë˜ì–´ ìˆëŠ” ë¶€ë¶„ì„ íŒŒë™ì˜ ì§„í­ì„ í¬ê²Œ, ìƒëŒ€ì ìœ¼ë¡œ ì…ìë“¤ì˜ ìˆ˜ê°€ ì ì€ ê³³ì€ ì§„í­ì„ ì‘ê²Œí•˜ì—¬ í‘œí˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

![](https://ds055uzetaobb.cloudfront.net/uploads/BA0A3V9ODx-p4g2-1.gif){fig-align="default"}

<div style="text-align:center">
  Sound waveform<sup>3</sup>
</div>

<p>

</p>

ì´ë ‡ê²Œ íŒŒë™ ëª¨í˜•ìœ¼ë¡œ ë‚˜íƒ€ë‚´ì–´ì§„ ì†Œë¦¬ëŠ” **Continutous(ì—°ì†ì ì¸)** ì‹ í˜¸ ì…ë‹ˆë‹¤. ì´ëŸ¬í•œ ì‹ í˜¸ë¥¼ ì»´í“¨í„°ì—ì„œ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ì„œëŠ” ì»´í“¨í„°ê°€ ì´í•´í•  ìˆ˜ ìˆë„ë¡ **Discrete(ë¶ˆì—°ì†ì ì¸)** ê°’ìœ¼ë¡œ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆì–´ì•¼ í•˜ë©° `Continuousí•œ ì‹ í˜¸ â†’ Discreteí•œ ì‹ í˜¸`ë¡œ ë°”ê¾¸ëŠ” ê³¼ì •ì„ **Sampling**ì´ë¼ê³  í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œ ëì´ ì•„ë‹Œ ì»´í“¨í„°ëŠ” ë¬´í•œí•œ (ì´ì§„í™”ëœ)ì •ìˆ˜ í‘œí˜„ì„ ê°€ì§ˆ ìˆ˜ ìˆëŠ”ê²ƒì´ ì•„ë‹ˆê³  ë” íš¨ìœ¨ì ìœ¼ë¡œ ì‹ í˜¸ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ **Quantization(ì–‘ìí™”)**ê³¼ì •ì„ ê±°ì¹˜ê²Œ ë©ë‹ˆë‹¤. ì´ëŠ” ìƒ˜í”Œë§ë˜ì–´ ì´ì‚°í™” ë˜ì–´ ìˆëŠ” ì‹ í˜¸ ê°’ì„ Sectionì„ ë‚˜ëˆ„ì–´ ì¼ì • êµ¬ê°„ ë‚´ì— ìˆëŠ” ê°’ë“¤ì€ í•˜ë‚˜ì˜ ì–‘ìí™”ëœ ê°’ìœ¼ë¡œ ë§¤ì¹­í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. ì´ë ‡ê²Œ ì´ì§„ìˆ˜ë¡œ ì •ìˆ˜í™”ëœ ì†Œë¦¬ëŠ” ì•„ë˜ì˜ ì˜¤ë¥¸ìª½ ê·¸ë¦¼ì—ì„œì™€ ê°™ì´ ì‹œê°„ì¶•(x)ì— ë”°ë¼ ë¹¨ê°„ ì ìœ¼ë¡œ ë‚˜íƒ€ë‚´ì–´ì§€ëŠ” ì‹ í˜¸ë¡œ ë³€í™˜ë˜ê²Œ ë©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì‹ í˜¸ì²˜ë¦¬ ê³¼ì •ì„ **Pulse-Code Modulation(PCM)**ì´ë¼ê³  í•©ë‹ˆë‹¤.

![](https://i.imgur.com/oOWn7U7.png){fig-align="default"}

<div style="text-align:center">
  PCM<sup>6, 8</sup>
</div>

<p>

</p>

ë³´í†µ ì†Œë¦¬ì˜ ì‹ í˜¸ì²˜ë¦¬ëŠ” 16-bitì˜ ì •ìˆ˜í‘œí˜„(-255 ~ 256)ìœ¼ë¡œ ë‚˜íƒ€ë‚´ì§€ë§Œ WaveNetì—ì„œëŠ” Nonlinearityë¥¼ ì¦ê°€ì‹œí‚¤ê³  ë” íš¨ìœ¨ì ì´ì—ˆë˜ **8-bit** ì •ìˆ˜ í‘œí˜„ ë””ì§€í„¸ ì‹ í˜¸ë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤. ì´ë•Œ ì‚¬ìš©í•œ ë°©ë²•ì€ `Âµ-law Companding Transformation(Î¼-law algorithm)`ìœ¼ë¡œ ì‚¬ëŒì´ ì†Œë¦¬ë¥¼ ì¸ì‹í•˜ëŠ” ë°©ë²•ì„ ëª¨ë°©í•œ ë°©ì‹ì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤. ì‚¬ëŒì€ ì‘ì€ ì†Œë¦¬ì˜ ë³€í™”ì—ëŠ” ë¯¼ê°í•˜ì§€ë§Œ í° ì†Œë¦¬ì˜ ë³€í™”ì—ëŠ” ë‘”ê°í•˜ë¯€ë¡œ [Î¼-law algorithm](https://en.wikipedia.org/wiki/%CE%9C-law_algorithm)ì—ì„œë„ ì‘ì€ ì†Œë¦¬ì˜ êµ¬ê°„(ì•„ë˜ ê·¸ë˜í”„ì—ì„œ ì¤‘ì•™ ë¶€ë¶„)ì€ ì„¸ë°€í•˜ê²Œ ë‚˜ëˆ„ê³  í° ì†Œë¦¬ êµ¬ê°„(ì•„ë˜ ê·¸ë˜í”„ì—ì„œ ì¢Œìš° ë ë¶€ë¶„)ì€ ê¸°ìš¸ê¸°ë¥¼ ì™„ë§Œí•˜ê²Œ í•˜ì—¬ ë¹„êµì  ë“¬ì„±í•˜ê²Œ ë‚˜ëˆ„ì—ˆìŠµë‹ˆë‹¤. 

![](https://i.imgur.com/ZI5lIyp.png){fig-align="default"}

<div style="text-align:center">
  Î¼-law algorithm<sup>9</sup>
</div>

<p>

</p>

WaveNetì—ì„œ 16-bitê°€ ì•„ë‹Œ 8-bitë¥¼ ì‚¬ìš©í•œ ì´ìœ ëŠ” ì•„ë˜ ê·¸ë¦¼ì˜ ì˜¤ë¥¸ìª½ì—ì„œ WaveNetì˜ ì „ì²´ íë¦„ì—ì„œ ë³¼ ë•Œ ì–‘ìí™”ëœ ê° êµ¬ê°„ì˜ softmaxë¡œ í•´ë‹¹ ê°’ì˜ í™•ë¥ ì„ êµ¬í•˜ê²Œ ë˜ëŠ”ë°, 16-bitë¼ë©´ softmax layerì—ì„œ ì´ 65,536(= $-2^{15}$ ~ $2^{15}-1$ )ê°œì˜ í™•ë¥ ì„ êµ¬í•´ì•¼ í•˜ë¯€ë¡œ ê³„ì‚°ì´ ë§¤ìš° ë§ì´ í•„ìš”í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

![](https://i.imgur.com/DWwuKRO.png){fig-align="default"}

<div style="text-align:center">
  WaveNet Structure<sup>6</sup>
</div>

<p>

</p>


**TTS(Text-to-Speech)ë€**

ì•ì„œ ì´ì•¼ê¸°í•œëŒ€ë¡œ êµ¬ê¸€ì˜ ìŠ¤í”¼ì»¤ ì„œë¹„ìŠ¤ì— WaveNetì´ ì“°ì¸ ê²ƒìœ¼ë¡œ í° í™”ì œì˜€ëŠ”ë° ì´ëŠ” ë°”ë¡œ TTS ì„œë¹„ìŠ¤ì— WaveNetì´ ì“°ì¸ ê²ƒ ì´ì—ˆìŠµë‹ˆë‹¤. TTS taskëŠ” íŠ¹ì • textê°€ ì£¼ì–´ì§€ë©´ ì´ë¥¼ ìŒì„± ì‹ í˜¸ë¡œ ë°”ê¿”ì£¼ëŠ”(ìŒì„±ì„ ìƒì„±í•˜ëŠ”) taskì´ë©° Text analysisì™€ Speech synthesisê°€ ê°™ì´ ì´ë£¨ì–´ì§€ëŠ” task ì…ë‹ˆë‹¤.


![](https://i.imgur.com/SJIIZSd.png){fig-align="default"}

<div style="text-align:center">
  TTS Process <sup>19</sup>
</div>

<p>

</p>


ê¸°ì¡´ì˜ TTS ê¸°ìˆ ì€ í¬ê²Œ 2ê°€ì§€ê°€ ìˆì—ˆìŠµë‹ˆë‹¤. ì²«ë²ˆì§¸ë¡œ `Concatenative`ëŠ” ë‹¤ëŸ‰ì˜ ìŒì„± ë°ì´í„°ë¥¼ ìŒì†Œ ë‹¨ìœ„ë¡œ ìª¼ê°œì–´ ì‹ í˜¸ë¥¼ ì €ì¥í•œ ê²ƒì„ ì¡°í•©í•˜ì—¬ ìƒˆë¡œìš´ ìŒì„±ì„ ìƒì„±í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ, ë§ˆì¹˜ í€¼íŠ¸ë¡œ ì˜·ê°ì˜ íŒ¨í„´ì„ ë§Œë“¤ì–´ë‚´ë“¯ì´ ìŒì„± ë‹¨ìœ„ë“¤ì„ ì´ì–´ë¶™ì´ëŠ” ë°©ì‹ì…ë‹ˆë‹¤. ì´ ë°©ë²•ì€ ì‹¤ì œ ìŒì„± ë°ì´í„°ë¥¼ ìª¼ê°  ê²ƒì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ë¯€ë¡œ ìŒì„± ë°ì´í„° í•˜ë‚˜ í•˜ë‚˜ì˜ í€„ë¦¬í‹°ëŠ” ì¢‹ì§€ë§Œ ë‹¨ì ìœ¼ë¡œëŠ” ìŒì„±ì„ ì¡°ì ˆí•  ìˆ˜ ìˆëŠ” ììœ ë„ê°€ ë–¨ì–´ì§„ë‹¤ëŠ” ì ê³¼ ìŒì„± ë°ì´í„°ê°€ ë§¤ìš° ë§ì•„ì•¼ í•œë‹¤ëŠ” ì ì´ ìˆìŠµë‹ˆë‹¤.

ë‘ë²ˆì§¸ë¡œ `Parametric`ì€ í†µê³„ì  ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìŒì„±ì„ í•©ì„±í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ WaveNetì˜ ë¶€ë¡ì— ìì„¸íˆ ì„¤ëª…ì´ ë˜ì–´ ìˆë“¯ì´ Acoustic modelì„ ë§Œë“¤ì–´ì„œ ìŒì„±ì„ ë§Œë“¤ì–´ ëƒ…ë‹ˆë‹¤. Concatenativeì™€ ë‹¤ë¥´ê²Œ ìƒˆë¡œìš´ ìŒì„± ë°ì´í„°ë¥¼ ë§Œë“¤ì–´ë‚¸ë‹¤ëŠ” ì ì—ì„œ ìŒì„± ì‹ í˜¸ë¥¼ ì¡°ì‘í•  ìˆ˜ ìˆëŠ” ììœ ë„ê°€ ì»¤ì§€ê³  ë°ì´í„° ì…‹ì´ ë§ì´ í•„ìš” ì—†ìœ¼ë‚˜ ìŒì„±ì„ ìƒì„±í•´ë‚´ëŠ” í€„ë¦¬í‹°ê°€ ë‹¤ì†Œ ë–¨ì–´ì§€ëŠ” ë‹¨ì ì´ ìˆìŠµë‹ˆë‹¤. ê¸°ì¡´ì˜ 2ê°€ì§€ ë°©ì‹ê³¼ ë‹¤ë¥´ê²Œ WaveNetì€ explicití•œ acoustic featureë¥¼ ëª¨ë¸ë§ í•˜ì§€ ì•Šê³  ë°”ë¡œ raw waveformì„ ìƒì„±í•˜ëŠ” ê²ƒì´ ê°€ì¥ í° ì°¨ì´ë¼ê³  ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

![](https://i.imgur.com/Kx9VZi3.png){fig-align="default"}

<div style="text-align:center">
  Concatenative and Parametric methods<sup>10</sup>
</div>

<p>

</p>

![](https://i.imgur.com/P54R1zi.png){fig-align="default"}

<div style="text-align:center">
  NN-based GM for TTS<sup>19</sup>
</div>

<p>

</p>

WaveNetì„ vocoderë¡œ ì´ìš©í•˜ì—¬ Tacotron2ì™€ ê°™ì€ í…ìŠ¤íŠ¸ì—ì„œ ì§ì ‘ ìŒì„± í•©ì„±ì„ ìœ„í•œ ì‹ ê²½ë§ ì•„í‚¤í…ì²˜ì—ì„œ ì“°ê²Œ ë©ë‹ˆë‹¤. ì•„ë˜ëŠ” Tacotron2ì˜ êµ¬ì¡°ì´ë©° ì˜¤ë¥¸ìª½ ìƒë‹¨ì—ì„œ WaveNet MoL(mixture of logistic distributions)ì„ ì°¾ì•„ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

![](https://i.imgur.com/nrRdYjy.png){fig-align="default"}

<div style="text-align:center">
  Tacotron 2 system architecture<sup>20</sup>
</div>

<p>

</p>

# WaveNet

WaveNetì˜ ì „ì²´ì ì¸ êµ¬ì¡°ëŠ” ì•„ë˜ì˜ ê·¸ë¦¼ê³¼ ê°™ì´ í¬ê²Œ 4ê°€ì§€ ë¶€ë¶„ìœ¼ë¡œ ë‚˜ëˆ„ì–´ì„œ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.

![](https://i.imgur.com/42guttz.png){fig-align="default"}

<div style="text-align:center">
  WaveNet 4 Main components <sup>6</sup>
</div>

<p>

</p>

1. **Dilated Casual Convolution**

2. **Residual Connection & Gated Activation Units**

3. **Skip Connection**

4. **Conditional WaveNets**

WaveNet êµ¬í˜„ì€ ë‚´ìš© ì´í•´ë¥¼ ìš°ì„ ìœ¼ë¡œ í•˜ê¸° ìœ„í•´ ë¹„êµì  êµ¬í˜„ì´ ê°„ë‹¨ ëª…ë£Œí•˜ê²Œ ë˜ì–´ìˆëŠ” Reference[17]ì„ ì°¸ê³ í•˜ì˜€ìŠµë‹ˆë‹¤.([Youtube ê°•ì˜](https://youtu.be/KCk1i5xRxLA)) ìš°ì„  WaveNetì˜ ì „ì²´ ì½”ë“œëŠ” ë‹¤ìŒê³¼ ê°™ê³  class ë‚´ë¶€ì— ìˆëŠ” ë‹¤ë¥¸ module classì— ëŒ€í•œ ìì„¸í•œ ì½”ë“œëŠ” ì•„ë˜ ë‚´ìš©ì—ì„œ ì„¤ëª…ê³¼ í•¨ê»˜ ë‚˜ì˜¬ ì˜ˆì •ì…ë‹ˆë‹¤.

```python
class WaveNet(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, stack_size, layer_size):
        super().__init__()
        self.stack_size = stack_size
        self.layer_size = layer_size
        self.kernel_size = kernel_size
        self.casualConv1D = CasualDilatedConv1D(in_channels, in_channels, kernel_size, dilation=1)
        self.stackResBlock = StackOfResBlocks(self.stack_size, self.layer_size, in_channels, out_channels, kernel_size)
        self.denseLayer = DenseLayer(out_channels)


    def calculateReceptiveField(self):
        return np.sum([(self.kernel_size - 1) * (2 ** l) for l in range(self.layer_size)] * self.stack_size)

    def calculateOutputSize(self, x):
        return int(x.size(2)) - self.calculateReceptiveField()

    def forward(self, x):
        # x: b c t -> input data size
        x = self.casualConv1D(x)
        skipSize = self.calculateOutputSize(x)
        _, skipConnections = self.stackResBlock(x, skipSize)
        dense=self.denseLayer(skipConnections)
        return dense
```

---

## 1. Dilated Casual Convolution

ë¨¼ì € `Dilated Casual Convolution`ì€ `Âµ-law Companding Transformation` ì²˜ë¦¬ë¥¼ ê±°ì¹œ ìŒì„± ì‹ í˜¸ë¥¼ ë°›ì•„ì˜¤ëŠ” ì²«ë²ˆì§¸ ë¶€ë¶„ì…ë‹ˆë‹¤.

![](https://i.imgur.com/WwYFZBr.png){fig-align="default"}

<div style="text-align:center">
  Casual Convolution <sup>2</sup>
</div>

<p>

</p>

ìš°ì„  **Casual** ì´ë¼ëŠ” ê²ƒì€ Time-seriesì¸ ìŒì„± ì‹ í˜¸ì˜ ì‹œê°„ ìˆœì„œë¥¼ ê³ ë ¤í•˜ì—¬ í˜„ì¬ ì‹œì  $t$ë¥¼ ê¸°ì¤€ìœ¼ë¡œ **ë¯¸ë˜ ì •ë³´ëŠ” ì‚¬ìš©í•  ìˆ˜ ì—†ê³ ** í˜„ì¬ê¹Œì§€ì˜(ê³¼ê±°~í˜„ì¬ $t$) ì •ë³´`ë§Œ` ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤. ì™¼ìª½ Causal Convolution ê·¸ë¦¼ì—ì„œ Receptive FieldëŠ” `(ë ˆì´ì–´ ìˆ˜) + (í•„í„°ì˜ length) -1`ë¡œ ê³„ì‚°ë˜ì–´ ì´ ë ˆì´ì–´ ìˆ˜ëŠ” 4ê°œì´ê³  í•„í„° lengthëŠ” ì´ì „ ë ˆì´ì–´ì—ì„œ 2ê°œì˜ ì •ë³´ê°€ ëª¨ì•„ì ¸ì„œ ë‹¤ìŒ ë ˆì´ì–´ì˜ í•˜ë‚˜ì˜ ë°ì´í„°ë¡œ ì‚°ì¶œë˜ë¯€ë¡œ í•„í„° lengthëŠ” 2ë¼ê³  ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ 4+2-1ë¡œ Receptive FieldëŠ” 5ê°€ ë˜ë©° ì´ë¥¼ ê·¸ë¦¼ì—ì„œ ì‚´í´ë³´ë©´ ì²˜ìŒ `input`ì—ì„œ 5ê°œì˜ ìŒì„± ì •ë³´ê°€ `output`ì˜ 1ê°œì˜ ì •ë³´ë¡œ ë‚˜ì˜¤ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ° Receptive FieldëŠ” ë§¤ìš° ì§§ì€ ì‹œê°„ì— ë§ì€ ìŒì„±ì‹ í˜¸ê°€ ë§¤ì¹­ë˜ëŠ” ìƒí™©ì—ì„œ ë§¤ìš° ì¢ìœ¼ë©° RFë¥¼ ëŠ˜ë¦¬ê¸° ìœ„í•´ì„œëŠ” ë ˆì´ì–´ ìˆ˜ë¥¼ ëŠ˜ë¦¬ê±°ë‚˜ í•„í„°ì˜ lengthë¥¼ ëŠ˜ë ¤ì•¼ í•˜ëŠ”ë° ì´ëŠ” ëª¨ë¸ì„ ë§¤ìš° í¬ê²Œ ë§Œë“¤ê²Œ ë˜ê³  ê³„ì‚°ë„ ë§ì´ ìš”êµ¬ë©ë‹ˆë‹¤.


![](https://i.imgur.com/k9Nhtsz.png){fig-align="default"}

<div style="text-align:center">
  Dilated Casual Convolution <sup>2</sup>
</div>

<p>

</p>

ê·¸ë˜ì„œ ì œì•ˆì´ ëœ ë°©ë²•ì´ ë°”ë¡œ **Dilated Convolution**ì…ë‹ˆë‹¤. ì´ëŠ” convolution with **holes**ë¡œ í•´ì„í•  ìˆ˜ ìˆëŠ”ë° ìœ„ì˜ ê·¸ë¦¼ì—ì„œ ë³¼ ìˆ˜ ìˆë“¯ì´ ì´ì „ ë ˆì´ì–´ì—ì„œ ë°ì´í„°ê°€ Dilatedë˜ì–´ ë°ì´í„°ê°€ ë“¬ì„±ë“¬ì„±í•˜ê²Œ ëª¨ì•„ì ¸ì„œ ë‹¤ìŒ ë ˆì´ì–´ë¡œ ë„˜ì–´ê°€ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” skipì´ë‚˜ poolingê³¼ ìœ ì‚¬í•´ë³´ì´ì§€ë§Œ inputê³¼ outputì˜ ì°¨ì›ì´ ìœ ì§€ëœë‹¤ëŠ” ì ì—ì„œ ì°¨ì´ê°€ ìˆìŠµë‹ˆë‹¤. ì´ë•Œì˜ RFëŠ” ê° ë ˆì´ì–´ì˜ Dilation ê°’ì„ ëª¨ë‘ ë”í•˜ê³  ë§ˆì§€ë§‰ì— í˜„ì¬ ì‹œì ì˜ ë°ì´í„° 1ì„ ë”í•˜ë©° RFê°€ ê³„ì‚°ë©ë‹ˆë‹¤. WaveNetì—ì„œëŠ” Dilationì„ ì´ 30ê°œì˜ ë ˆì´ì–´ì— ì ìš©í–ˆê³  Dilation ê°’ì˜ íŒ¨í„´ì€ inputì—ì„œ ë¶€í„° 1, 2, ..., 512 ë¡œ 2ë°°ì”© ëŠ˜ë¦° 10ê°œì˜ ë ˆì´ì–´ë¥¼ ì´ 3ë²ˆ ë°˜ë³µí–ˆìŠµë‹ˆë‹¤. ì´ë•Œ, 1 ~ 512 Dilation ê°’ì„ ê°€ì§„ 10ê°œ ë ˆì´ì–´ì˜ RFëŠ” 1024ë¡œ ê³„ì‚°ë©ë‹ˆë‹¤. 

![](https://i.imgur.com/K4NH1nL.gif){fig-align="default"}

<div style="text-align:center">
  Dilated Casual Convolution Process<sup>2</sup>
</div>

<p>

</p>

![](https://i.imgur.com/61Ph7uJ.png){fig-align="default"}

<div style="text-align:center">
  Dilated Convolution Pattern<sup>6</sup>
</div>

<p>

</p>

Code êµ¬í˜„ìœ¼ë¡œ ì‚´í´ë³´ë©´ ì•„ë˜ì™€ ê°™ì´ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Casual íŠ¹ì„±ì„ ë°˜ì˜í•˜ê¸° ìœ„í•´ `self.ignoreOutIndex` ì„ ë§Œë“¤ì–´ì„œ dilation ê°’ì„ ê³ ë ¤í•˜ì—¬ `(kernel_size - 1) * dilation`ìœ¼ë¡œ ê³„ì‚°í•œ í›„ì— ì˜ë¼ë‚´ì£¼ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
class CasualDilatedConv1D(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, dilation, padding=1):
        super().__init__()
        self.conv1D = nn.Conv1d(in_channels, out_channels, kernel_size, dilation=dilation, bias=False, padding='same')
        self.ignoreOutIndex = (kernel_size - 1) * dilation # casual

    def forward(self, x):
        return self.conv1D(x)[..., :-self.ignoreOutIndex] # casual
```


## 2. Residual Connection & Gated Activation Units

ë‹¤ìŒìœ¼ë¡œ Dilated Causal Convolutionì„ ê±°ì¹œ í›„ í†µê³¼í•˜ê²Œ ë˜ëŠ” `Residual Connection & Gated Activation Units` ë¶€ë¶„ì— ëŒ€í•´ì„œ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.

![](https://i.imgur.com/qJqN9JK.png){fig-align="default"}

WaveNetì—ì„œ ì‚¬ìš©ëœ **Gated Activation Units**ëŠ” [PixelCNN](https://arxiv.org/abs/1606.05328)ì—ì„œ ì‚¬ìš©ëœ ë§¤ì»¤ë‹ˆì¦˜ì„ ì°¨ìš©í–ˆìŠµë‹ˆë‹¤. ì•„ë˜ì˜ ê·¸ë¦¼ì—ì„œ ë³´ì´ëŠ” ë³´ë¼ìƒ‰ Dilated Convê°€ ì•ì—ì„œ ì„¤ëª…í•œ DCCì´ë©° ì´ë¥¼ ê±°ì¹œ í›„ Convoltion layerì™€ ê°ê° tanh, sigmoid activationì„ í†µê³¼í•˜ì—¬ **Filter**, **Gate**ê°€ ë©ë‹ˆë‹¤. ì´ 2ê°€ì§€ ê²½ë¡œë¡œ ê³„ì‚°ëœ ê°’ì€ elementwise productë¥¼ í†µí•´ í•˜ë‚˜ì˜ ë²¡í„°ë¡œ ë³€í™˜ë©ë‹ˆë‹¤. ì´ë–„ Dilatedë¥¼ í†µê³¼í•˜ê¸° ì „ ê°’ì„ **Residual Connection**ì„ í†µí•´ ì—°ê²°í•¨ìœ¼ë¡œì¨ ë”¥ëŸ¬ë‹ ëª¨ë¸ì´ ë ˆì´ì–´ë¥¼ ë” ê¹Šê²Œ ìŒ“ì„ ìˆ˜ ìˆë„ë¡ ë•ê³  ë” ë¹ ë¥´ê²Œ í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ í•  ìˆ˜ ìˆì—ˆë‹¤ê³  í•©ë‹ˆë‹¤.

![](https://i.imgur.com/7Q5PiqX.png){fig-align="default"}

<div style="text-align:center">
  Residual Connection & Gated Activation Units<sup>6</sup>
</div>

<p>

</p>


## 3. Skip Connection

![](https://i.imgur.com/kw4enrQ.png){fig-align="default"}


**Skip Connection**ì€ Dilated Convolutionì„ í†µí•´ ë‹¤ì–‘í•œ Receptive Fieldë¥¼ ê°€ì§„ ê° ë ˆì´ì–´ë“¤ì˜ ê°’ì„ í™œìš©í•˜ì—¬ outputì„ ë§Œë“¤ì–´ë‚¼ ìˆ˜ ìˆë„ë¡ í–ˆìŠµë‹ˆë‹¤. ì•ì„œ ì„¤ëª…í–ˆë˜ ëŒ€ë¡œ ê° Residual Blockì˜ Dilation ê°’ì´ ë‹¤ ë‹¤ë¥´ê¸° ë•Œë¬¸ì— ê° Residual Blockì˜ outputì€ **ì„œë¡œ ë‹¤ë¥¸ Receptive Field**ë¥¼ ê°€ì§€ê²Œ ë©ë‹ˆë‹¤.

![](https://i.imgur.com/1YWCpC3.png){fig-align="default"}

<div style="text-align:center">
  Skip Connection<sup>6</sup>
</div>

<p>

</p>

Residual Connectionê³¼ Skip Connectionì„ Codeë¡œ êµ¬í˜„í•˜ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. ìœ„ì—ì„œ ì„¤ëª…í–ˆë˜ Gated Activation Unitsì˜ tanh, sigmoid activationì„ ê°ê°ì˜ activation functionì„ ê±°ì¹œí›„ `self.resConv1D`ì„ í†µê³¼í•˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ Skip Connectionì„ êµ¬í˜„í•˜ëŠ” ë¶€ë¶„ì€ `self.skipConv1D`ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ returnì—ì„œ `resOutput`, `skipOutput`ìœ¼ë¡œ 2ê°œì˜ outputì´ ë‚˜ì˜¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
class ResBlock(nn.Module):
    def __init__(self, res_channels, skip_channels, kernel_size, dilation):
        super().__init__()
        self.casualDilatedConv1D = CasualDilatedConv1D(res_channels, res_channels, kernel_size, dilation=dilation)
        self.resConv1D = nn.Conv1d(res_channels, res_channels, kernel_size=1)
        self.skipConv1D = nn.Conv1d(res_channels, skip_channels, kernel_size=1)
        self.tanh = nn.Tanh()
        self.sigmoid = nn.Sigmoid()

    def forward(self, inputX, skipSize):
        x = self.casualDilatedConv1D(inputX)
        x1 = self.tanh(x)
        x2 = self.sigmoid(x)
        x = x1 * x2
        resOutput = self.resConv1D(x)
        resOutput = resOutput + inputX[..., -resOutput.size(2):]
        skipOutput = self.skipConv1D(x)
        skipOutput = skipOutput[..., -skipSize:]
        return resOutput, skipOutput
```

ìœ„ì™€ ê°™ì€ `ResBlock`ì€ ì „ì²´ êµ¬ì¡°ì—ì„œ ë³´ì‹œë‹¤ì‹œí”¼ ì—¬ëŸ¬ê°œê°€ stacked ë˜ì–´ ìˆìœ¼ë¯€ë¡œ `StackOfResBlocks` classë¡œ êµ¬í˜„í•˜ì—¬ WaveNetì— ë„£ì–´ì£¼ê²Œ ë©ë‹ˆë‹¤. 

```python
class StackOfResBlocks(nn.Module):

    def __init__(self, stack_size, layer_size, res_channels, skip_channels, kernel_size):
        super().__init__()
        buildDilationFunc = np.vectorize(self.buildDilation)
        dilations = buildDilationFunc(stack_size, layer_size)
        self.resBlocks = []
        for s,dilationPerStack in enumerate(dilations):
            for l,dilation in enumerate(dilationPerStack):
                resBlock=ResBlock(res_channels, skip_channels, kernel_size, dilation)
                self.add_module(f'resBlock_{s}_{l}', resBlock) # Add modules manually
                self.resBlocks.append(resBlock)

    def buildDilation(self, stack_size, layer_size):
        # stack1=[1,2,4,8,16,...512]
        dilationsForAllStacks = []
        for stack in range(stack_size):
            dilations = []
            for layer in range(layer_size):
                dilations.append(2 ** layer)
            dilationsForAllStacks.append(dilations)
        return dilationsForAllStacks

    def forward(self, x, skipSize):
        resOutput = x
        skipOutputs = []
        for resBlock in self.resBlocks:
            resOutput, skipOutput = resBlock(resOutput, skipSize)
            skipOutputs.append(skipOutput)
        return resOutput, torch.stack(skipOutputs)
```


## 4. Conditional WaveNets

![](https://i.imgur.com/lAbHdjt.png){fig-align="default"}

![](https://i.imgur.com/dqoNwPB.png){fig-align="default"}

<div style="text-align:center">
  Conditional modeling <sup>6</sup>
</div>

<p>

</p>


**Conditional Modeling**ì€ Autoregressive modelì¸ WaveNetì— ì ìš©í•˜ê¸° ì‰½ê³  ì´ ë˜í•œ PixelCNNì—ì„œì˜ ì•„ì´ë””ì–´ì™€ ìœ ì‚¬í•©ë‹ˆë‹¤. Feature $h$ ë²¡í„°ë¥¼ ì¡°ê±´ ë¶€ë¶„ì— ì¶”ê°€í•˜ì—¬ ìŒì„± ë°ì´í„°ì— ì¡°ê±´ì„ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

$$
p(\mathbf{x} \mid \mathbf{h})=\prod_{t=1}^T p\left(x_t \mid x_1, \ldots, x_{t-1}, \mathbf{h}\right)
$$

Conditionì—ëŠ” í¬ê²Œ 2ê°€ì§€ë¡œ **Global**ê³¼ **Local**ì´ ìˆìŠµë‹ˆë‹¤. ë¨¼ì € **Global**ì€ Time-invariantí•œ ì¡°ê±´ìœ¼ë¡œ ì‹œì ì— ë”°ë¼ ë³€í•˜ì§€ ì•ŠëŠ” ì¡°ê±´ ì •ë³´ë¥¼ ì¶”ê°€í•˜ëŠ” ê²ƒì„ ë§í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ í•œ ë°œí™”ìì˜ ìŒì„±ì€ í•´ë‹¹ ìŒì„± íŒŒì¼ì˜ ì–´ë–¤ ì‹œì ì—ì„œë‚˜ ë˜‘ê°™ì€ conditionì´ê¸° ë•Œë¬¸ì— Global conditionì´ë¼ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë•Œì˜ Feature vector $h$ëŠ” linear projectionì„ ê±°ì¹œ í›„ data $x$ì™€ ë”í•˜ê²Œ ë©ë‹ˆë‹¤.

![](https://i.imgur.com/xnfhnfa.png){fig-align="default"}

ë‹¤ìŒìœ¼ë¡œ Time-variantí•œ **Local** conditionì€ ì‹œì ì— ë”°ë¼ ë³€í•˜ëŠ” ì¡°ê±´ ì •ë³´ë¥¼ ì¶”ê°€í•˜ëŠ” ê²ƒì„ ë§í•˜ëŠ”ë° ìŒì„± ë°ì´í„°ë³´ë‹¤ ê¸¸ì´ê°€ ì§§ì§€ë§Œ ìˆœì„œê°€ ìˆëŠ” ì¼ì • ê¸¸ì´ì˜ Sequence vectorë¼ê³  ìƒê°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê°™ì€ ë°œí™”ìì—¬ë„ ì–´ë–¤ ë‹¨ì–´ë¥¼ ë§í•˜ëŠëƒì— ë”°ë¼ ìŒì„±í•™ì ì¸ íŠ¹ì§•(linguistic feature)ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆê¸° ë–„ë¬¸ì— localí•œ ì¡°ê±´ì€ í•œ ìŒì„± íŒŒì¼ì— ì—¬ëŸ¬ê°œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë•Œ Feature vector $h$ëŠ” ìŒì„± íŒŒì¼ê³¼ ê¸¸ì´ê°€ ë‹¤ë¥´ê¸° ë•Œë¬¸ì— Upsamplingì„ ê±°ì¹œí›„ 1x1 convolutionì„ ê±°ì³ì„œ data $x$ì™€ ë”í•´ì§‘ë‹ˆë‹¤.

![](https://i.imgur.com/6P2OFif.png){fig-align="default"}

# Experiments

ì‹¤í—˜ì€ ì´ 4ê°€ì§€ **Free-form Speech Generation, TTS, Music Audio Modelling, Speech Recognition**ì„ ì§„í–‰í–ˆì§€ë§Œ ì£¼ëœ ì‹¤í—˜ì€ **TTS**ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì´ë£¨ì–´ì¡Œìœ¼ë©° Evaluationì€ 2ê°€ì§€ë¡œ `Paired Comparison Test`, `Mean Opinion Score`ìœ¼ë¡œ ì§„í–‰í–ˆìŠµë‹ˆë‹¤. `Paired Comparison Test`ì€ í”¼ì‹¤í—˜ìì—ê²Œ 2ê°œì˜ ì‹¤í—˜ ëª¨ë¸ë¡œë¶€í„° ìƒì„±ëœ ìŒì„± íŒŒì¼ì„ ë“¤ë ¤ì£¼ê³  ë‘˜ ì¤‘ **ë” ìì—°ìŠ¤ëŸ½ë‹¤ê³ ** ìƒê°ë˜ëŠ” ìŒì„± íŒŒì¼ì„ ì„ íƒí•˜ê²Œ í•©ë‹ˆë‹¤. ì´ë•Œ ë‘ ê°œì˜ ìŒì„±ë“¤ì—ì„œ ë”±íˆ ì„ í˜¸ë„ê°€ ì—†ì„ ê²½ìš°ì—ëŠ” `No preference`ë¡œ ì‘ë‹µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. `Mean Opinion Score` ì‹¤í—˜ì—ì„œëŠ” í”¼ì‹¤í—˜ìì—ê²Œ ìƒì„±ëœ ìŒì„± 1ê°œë¥¼ ë“¤ë ¤ì£¼ê³  1~5ì  ì‚¬ì´ì˜ í’ˆì§ˆ ì ìˆ˜ë¥¼ ë°›ê²Œ ë©ë‹ˆë‹¤. (1: Bad, 2: Poor, 3: Fair, 4: Good, 5: Excellent)

![](https://i.imgur.com/BJDXKwa.png){fig-align="default"}

TTS ì‹¤í—˜ì—ì„œ **Paired Comparison Test**ë¥¼ ì§„í–‰í•˜ê¸° ìœ„í•´ ì…ë ¥ textì—ì„œ ì¶”ì¶œëœ linguistic feature[L]ì™€ ìŒì„±ì˜ íŠ¹ì§• ì¤‘ í•˜ë‚˜ì¸ logarithmic fundamental frequency($F_o$)[F]ë¥¼ local conditionìœ¼ë¡œ ë„£ì–´ì£¼ì—ˆìŠµë‹ˆë‹¤. ì´ë•Œ Receptive FieldëŠ” 240 ë°€ë¦¬ì„¸ì»¨ë“œì˜€ìœ¼ë©° ë¹„êµëª¨ë¸ë¡œëŠ” `concatenative ê³„ì—´`ì˜ HMM-driven unit selectionê³¼ `parametric ê³„ì—´`ì˜ LSTM-RNN-based ëª¨ë¸ì„ ê°€ì§€ê³  ë¹„êµí–ˆìŠµë‹ˆë‹¤.

Preference scoreì„ ë¹„êµí•´ë´¤ì„ ë•Œ, ìš°ì„  ê¸°ì¡´ì˜ ë°©ë²•ë¡ ì´ì—ˆë˜ LSTMì™€ Concatì„ ë¹„êµí•´ë³´ë©´(ê°€ì¥ ì™¼ìª½ bar graph) ì˜ì–´ì—ì„œëŠ” `Concat`ì´ ì¤‘êµ­ì–´ì—ì„œëŠ” `LSTM`ì´ ë” ë†’ì€ ì ìˆ˜ë¥¼ ë°›ì€ ê²ƒì„ ë³´ì•„ ë°ì´í„°ê°€ ë§ì€ ì˜ì–´ì—ì„œëŠ” Concat ë°©ë²•ë¡ ì´ ë” ì¢‹ì€ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ìŒìœ¼ë¡œ WaveNetì˜ local conditionì„ `Lë§Œ ì£¼ì—ˆì„ ë•Œ`ì™€ `L+Fë¥¼ ì£¼ì—ˆì„ ë•Œ`ë¥¼ ë¹„êµí•´ë³´ë©´(ê°€ìš´ë° bar graph) local condition ì¡°ê±´ì´ ë§ì„ìˆ˜ë¡, ì¦‰ L+Fë¥¼ local conditionìœ¼ë¡œ ì£¼ì—ˆì„ ë•Œ ì„ í˜¸ë„ê°€ ë†’ìŒì„ ì•Œ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ ë¹„êµêµ°ì´ì—ˆë˜ ê¸°ì¡´ì˜ ëª¨ë¸ë“¤ ì¤‘ ê°€ì¥ ì„ í˜¸ë„ê°€ ë†’ì€ ëª¨ë¸ê³¼ WaveNetì— ëª¨ë“  local conditionì„ ì£¼ì—ˆì„ ë•Œë¥¼ ë¹„êµí•´ë³´ë©´(ê°€ì¥ ì˜¤ë¥¸ìª½ bar graph) ì˜ì–´ì™€ ì¤‘êµ­ì–´ ëª¨ë‘ì—ì„œ WaveNetì˜ ì„ í˜¸ë„ê°€ ë†’ì€ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

![](https://i.imgur.com/khalgQ7.png){fig-align="default"}

<div style="text-align:center">
  Paired Comparison Test Result and Logarithmic fundamental frequency<sup>12</sup>
</div>

<p>

</p>

ë‘ë²ˆì§¸ ì‹¤í—˜ì¸ **Mean Opinion Score**ì—ì„œëŠ” WaveNetì´ 4ì  Goodì„ ì˜ì–´ì™€ ì¤‘êµ­ì–´ì—ì„œ ëª¨ë‘ ë„˜ì€ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆìœ¼ë©° ì‹¤ì œ ìŒì„±(ground truth)ì—ì„œ 8-bit í˜¹ì€ 16-bitë¡œ ë³€í™˜í•œ ê²ƒê³¼ ê¸°ì¡´ ëª¨ë¸ë“¤(LSTM, HMM)ì‚¬ì´ì˜ ì°¨ì´ë¥¼ ë” ì¤„ì—¬ì¤€ ê²ƒì„ í™•ì¸í•¨ìœ¼ë¡œì¨ ìŒì„± ìƒì„± ëª¨ë¸ì˜ í¼í¬ë¨¼ìŠ¤ê°€ í–¥ìƒëœ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

![](https://i.imgur.com/4hjl1VL.png){fig-align="default"}

<div style="text-align:center">
  Mean Opinion Score Result 
</div>

<p>

</p>

# Conclusion

WaveNet ë…¼ë¬¸ì—ì„œëŠ” **ìŒì„± ìƒì„±ì„ raw dataë¡œ** ë°”ë¡œ í•  ìˆ˜ ìˆì—ˆë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤€ ê²ƒì— í° Contributionì´ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ Dilated Causal Convolution / Skip / Residual ê¸°ë²•ì„ ì´ìš©í•˜ì—¬ **Receptive Fieldë¥¼ ëŠ˜ë ¤ì„œ ê¸´ ìŒì„± íŒŒí˜•ì„ í•™ìŠµ**í•  ìˆ˜ ìˆë„ë¡ í–ˆìŠµë‹ˆë‹¤. ë˜í•œ ìŒì„± íŒŒí˜• ë°ì´í„°ì—ë‹¤ê°€ **conditioning model**ì„ ë”í•¨ìœ¼ë¡œì¨ ë” íŠ¹ì§•ì ì´ê³  ìì—°ìŠ¤ëŸ¬ìš´ ìŒì„±ì„ ìƒì„± í•  ìˆ˜ ìˆë„ë¡ í–ˆìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ TTSë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì—°êµ¬ê°€ ë˜ê¸´í–ˆì§€ë§Œ ìŒì•…ê³¼ ê°™ì€ ì‚¬ëŒì˜ ìŒì„±ì´ ì•„ë‹Œ ìŒì„± ë°ì´í„° ìƒì„±ì—ë„ potentialí•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì£¼ì–´ ê·¸ **í™•ì¥ì„±ì´ ì¢‹ë‹¤**ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

![](https://i.imgur.com/3H5u77X.png){fig-align="default"}

# Improved Works

WaveNetì˜ auto-regressiveí•œ íŠ¹ì„±ìœ¼ë¡œ ì¸í•´ ê³„ì‚°ëŸ‰ì´ ë§ê³  ëŠë¦° ìƒì„±ì„ ë³´ì™„í•œ [Fast Wavenet Generation Algorithm](https://arxiv.org/abs/1611.09482) ì—°êµ¬ê°€ ìˆì—ˆìŠµë‹ˆë‹¤. ë„¤íŠ¸ì›Œí¬ì˜ ë ˆì´ì–´ ìˆ˜ë¥¼ $L$ì´ë¼ê³  í–ˆì„ ë•Œ ê¸°ì¡´ì˜ naive WaveNetì´ $O(2^L)$ ë³µì¡ë„ê°€ ìˆì—ˆì§€ë§Œ ì¤‘ë³µë˜ëŠ” convolution ì—°ì‚°ì„ cachingí•¨ìœ¼ë¡œì¨ $O(L)$ ë³µì¡ë„ë¡œ ì¤„ì¼ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.

![](https://i.imgur.com/vKlD7a1.png){fig-align="default"}

<div style="text-align:center">
  Fast Wavenet <sup>21</sup>
</div>

<p>

</p>

---

**Reference**

[1] Original paper - [WaveNet: A Generative Model for Raw Audio](https://arxiv.org/abs/1609.03499)

[2] Project page - [https://www.deepmind.com/blog/wavenet-a-generative-model-for-raw-audio](https://www.deepmind.com/blog/wavenet-a-generative-model-for-raw-audio)

[3] [https://brilliant.org/practice/wave-anatomy-2/](https://brilliant.org/practice/wave-anatomy-2/)

[4] [https://m.blog.naver.com/sbkim24/10084099777](https://m.blog.naver.com/sbkim24/10084099777)

[5] [https://blog.naver.com/sorionclinic/221184537689](https://blog.naver.com/sorionclinic/221184537689)

[6] [https://joungheekim.github.io/2020/09/17/paper-review/](https://joungheekim.github.io/2020/09/17/paper-review/)

[7] [https://tech.kakaoenterprise.com/66](https://tech.kakaoenterprise.com/66)

[8] [https://www.researchgate.net/publication/269935208_Psychophysics_of_musical_elements_in_the_discrete-time_representation_of_sound](https://www.researchgate.net/publication/269935208_Psychophysics_of_musical_elements_in_the_discrete-time_representation_of_sound)

[9] [https://en.wikipedia.org/wiki/%CE%9C-law_algorithm](https://en.wikipedia.org/wiki/%CE%9C-law_algorithm)

[10] [https://youtu.be/m2A9g6Xu91I](https://youtu.be/m2A9g6Xu91I)

[11] [https://youtu.be/GyQnex_DK2k](https://youtu.be/GyQnex_DK2k)

[12] [https://wiki.aalto.fi/pages/viewpage.action?pageId=149890776](https://wiki.aalto.fi/pages/viewpage.action?pageId=149890776)

[13] [https://youtu.be/MNZepE1m-kI](https://youtu.be/MNZepE1m-kI)

[14] [https://medium.com/@satyam.kumar.iiitv/understanding-wavenet-architecture-361cc4c2d623](https://medium.com/@satyam.kumar.iiitv/understanding-wavenet-architecture-361cc4c2d623)

[15] [https://www.deepmind.com/blog/wavenet-a-generative-model-for-raw-audio](https://www.deepmind.com/blog/wavenet-a-generative-model-for-raw-audio)

[16] [https://towardsdatascience.com/wavenet-google-assistants-voice-synthesizer-a168e9af13b1](https://towardsdatascience.com/wavenet-google-assistants-voice-synthesizer-a168e9af13b1)

[17] [https://github.com/antecessor/Wavenet](https://github.com/antecessor/Wavenet)

[18] [https://youtu.be/nsrSrYtKkT8](https://youtu.be/nsrSrYtKkT8)

[19] [https://research.google/pubs/pub45882/](https://research.google/pubs/pub45882/)

[20] [https://arxiv.org/abs/1712.05884](https://arxiv.org/abs/1712.05884)

[21] [https://arxiv.org/abs/1611.09482](https://arxiv.org/abs/1611.09482)