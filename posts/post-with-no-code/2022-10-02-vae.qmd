---
title: "ğŸ“ƒVAE"
description: Auto-Encoding Variational Bayes
date: "2022-10-02"
categories: [generative model, vae, variational inference, paper review]
toc: true
---

![](https://i.imgur.com/xTJRmKC.jpg)

ì´ë²ˆ í¬ìŠ¤íŠ¸ëŠ” ìƒì„±ëª¨ë¸ì—ì„œ ìœ ëª…í•œ Variational Auto-Encoder(VAE)ë¥¼ ë‹¤ë£¨ê³  ìˆëŠ” `Auto-Encoding Variational Bayes`ë¼ëŠ” ë…¼ë¬¸ ë¦¬ë·°ì…ë‹ˆë‹¤. ì´ë²ˆ í¬ìŠ¤íŠ¸ë¥¼ ì •ë¦¬í•˜ë©´ì„œ ê°€ì¥ ë§ì´ ì¸ìš©í•˜ê³  ë„ì›€ì„ ë°›ì€ [ì˜¤í†  ì¸ì½”ë”ì˜ ëª¨ë“  ê²ƒ](https://youtu.be/o_peo6U7IRM)ë¥¼ ë³´ì‹œë©´ í›¨ì”¬ ë” ìì„¸í•˜ê³  ê¹Šì€ ì´í•´ë¥¼ í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í¬ìŠ¤íŠ¸ì˜ ìˆœì„œëŠ” ì•„ë˜ì™€ ê°™ì´ ì§„í–‰ë©ë‹ˆë‹¤.

![](https://i.imgur.com/wXPuTek.jpg)

# Introduction

VAEëŠ” ìƒì„±ëª¨ë¸(Generative Model)ì—ì„œ ìœ ëª…í•œ ëª¨ë¸ì…ë‹ˆë‹¤. ê·¸ë ‡ë‹¤ë©´ ìƒì„± ëª¨ë¸ì´ë€ ë¬´ì—‡ì„ ë§í•˜ëŠ” ê±¸ê¹Œìš”? ì˜ˆë¥¼ ë“¤ì–´ ìš°ë¦¬ê°€ ì°ì€ ì ì´ ì—†ëŠ” ê°•ì•„ì§€ ì‚¬ì§„ì„ `ë§Œë“¤ì–´ë‚´ê³  ì‹¶ë‹¤`ê³  í•´ë´…ì‹œë‹¤. ê·¸ë ‡ì§€ë§Œ ê°•ì•„ì§€ ì‚¬ì§„ì´ ì‹¤ì œ ê°•ì•„ì§€ë“¤ì„ ì°ì€ ì‚¬ì§„ë“¤ê³¼ ë„ˆë¬´ ë™ë–¨ì–´ì ¸ì„œ ì´ì§ˆê°ì„ ëŠë¼ì§€ ì•Šì•„ì•¼ í•©ë‹ˆë‹¤. ì´ëŸ° ë§¥ë½ì—ì„œ ìš°ë¦¬ê°€ ì›í•˜ëŠ” ê²ƒì€ train databaseì— ìˆëŠ” ì‚¬ì§„ë“¤, ì¦‰ ì‹¤ì œë¡œ ê°•ì•„ì§€ë“¤ì„ ì°ì€ ì‚¬ì§„ë“¤ì˜ **ë¶„í¬**ë¥¼ ì•Œê³  ì‹¶ìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œ **ë¶„í¬**ë¥¼ ì•Œê³  ì‹¶ì€ ì´ìœ ëŠ” ìš°ë¦¬ê°€ ë¶„í¬(distribution)ì„ ì•Œì•„ì•¼ ë¶„í¬ì—ì„œ dataë¥¼ ìƒ˜í”Œë§í•´ì„œ **ìƒì„±**í•  ìˆ˜ ìˆê¸° ë–„ë¬¸ì…ë‹ˆë‹¤. ë‹¤ì‹œ ì •ë¦¬í•˜ìë©´, í˜„ì¬ ë°ì´í„°ë“¤ê³¼ **ë¹„ìŠ·í•œ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ìƒì„± í•˜ê¸° ìœ„í•´** í˜„ì¬ train DBì˜ ë°ì´í„°ë“¤ì˜ ë¶„í¬ **$p(x)$** ë¥¼ ì•Œê³  ì‹¶ìŠµë‹ˆë‹¤. 

![](https://i.imgur.com/v5JMB4O.jpg)

ë°ì´í„° $x$ë¥¼ ìƒì„±í•˜ëŠ” **Generator**ë¥¼ ì‘ë™ì‹œí‚¬ **controller**ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì–´ë–¤ ë°ì´í„°ë¥¼ ìƒì„±í•˜ë„ë¡ Generatorë¥¼ trigger í•´ì£¼ëŠ” ë¶€ë¶„ì´ê¸° ë•Œë¬¸ì— ìš°ë¦¬ê°€ ë‹¤ë£¨ê¸° ì‰½ê²Œ ë§Œë“¤ì–´ ì¤˜ì•¼ ì´í›„ ìƒì„±ëª¨ë¸ì„ ì‚¬ìš©í•  ë•Œ í¸ë¦¬í•  ê²ƒ ì…ë‹ˆë‹¤. controller ì—­í• ì„ í•˜ëŠ” latent variable $z$ëŠ” ìœ„ì˜ ê·¸ë¦¼ì—ì„œ ë³¼ ìˆ˜ ìˆë‘£ì´ ë°ì´í„° xë³´ë‹¤ ì°¨ì›ì´ ì‘ê²Œ ë§Œë“¤ê³  $p(z)$ì—ì„œ ìƒ˜í”Œë§ ë©ë‹ˆë‹¤. 

ë‹¤ì‹œ ëª©í‘œì˜€ë˜ $p(x)$ë¥¼ ìƒê°í•´ë³´ë©´, `prior probability` $p(z)$ì™€ conditional probababilityì˜ ê³± ì ë¶„ìœ¼ë¡œ ìƒê°í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì ë¶„ ì´ë•Œ ì ë¶„ì„ ë‹¨ìˆœíˆ samplingí•œ ì—¬ëŸ¬ ë°ì´í„°ë“¤ì„ summationí•´ì„œ maximum likelihood estimationì„ ë°”ë¡œ í•  ìˆ˜ ìˆì§€ ì•Šì„ê¹Œ? ìƒê°í•  ìˆ˜ë„ ìˆì§€ë§Œ ì´ëŠ” ìƒ˜í”Œë§í•˜ëŠ” ê³¼ì •ì—ì„œ ìš°ë¦¬ê°€ ì›í•˜ì§€ ì•ŠëŠ” ìƒ˜í”Œë“¤ì´ ë” ë§ì´ ë½‘í ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ì´ ë°©ë²•ì„ ì“¸ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

**ìš°ë¦¬ê°€ ì›í•˜ì§€ ì•ŠëŠ” ìƒ˜í”Œë“¤ì´ ë” ë§ì´ ë½‘íˆëŠ” í˜„ìƒ**ì„ ì˜ˆì‹œë¥¼ ë“¤ì–´ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤. MINST ë°ì´í„° ì¤‘ 2ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì´ë¯¸ì§€ (a)ê°€ ìˆê³ , (a)ë¥¼ ì¼ë¶€ ì§€ìš´ (b)ì™€ (a)ë¥¼ ì˜¤ë¥¸ìª½ìœ¼ë¡œ 1 pixel ë§Œí¼ ì˜®ê¸´ (c)ê°€ ìˆìŠµë‹ˆë‹¤. ì´ë•Œ ìš°ë¦¬ëŠ” (a)ì™€ ìœ ì‚¬í•œ ë°ì´í„°ë¥¼ ë” ë§ì´ ë½‘ê³  ì‹¶ê³ , (b)ë³´ë‹¤ëŠ” (c)ê°€ (a)ì™€ ë” ê°€ê¹ë‹¤ê³  ìƒê°í•˜ë¯€ë¡œ (c)ì™€ ê°™ì€ ë°ì´í„°ë“¤ì´ ë” ë§ì´ ë½‘íˆê¸°ë¦¬ ì›í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ ë³´í†µ Generatorê°€ Normal distributionìœ¼ë¡œ ë””ìì¸ ë˜ê³  MSE ê±°ë¦¬ ê³„ì‚°ì„ í†µí•´ (a)ì™€ ë” ê°€ê¹Œìš´ ë°ì´í„° ìƒ˜í”Œë¡œ Normal distributionì˜ í‰ê· ì„ ì˜®ê²¨ê°„ë‹¤ê³  í–ˆì„ ë•Œ, (c)ë³´ë‹¤ (b)ê°€ (a)ì™€ì˜ MSEê°€ ì ê¸° ë•Œë¬¸ì— (b)ì™€ ë¹„ìŠ·í•œ ê°’ì´ ì •ê·œë¶„í¬ì˜ í‰ê· ì´ ë˜ê³  (b)ì™€ ë¹„ìŠ·í•œ ìƒ˜í”Œë“¤ì´ ë” ë§ì´ ë‚˜ì˜¤ê²Œ ë©ë‹ˆë‹¤. í•˜ì§€ë§Œ ê²°ê³¼ì ìœ¼ë¡œ (c)ê°€ (a)ì™€ ë¹„ìŠ·í•œ ê²ƒì´ ë” ì¢‹ì€ ìƒ˜í”Œë§ì´ ë˜ëŠ” ê²ƒì´ë¼ê³  ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì¢‹ì€ sampling functionì´ë€, ì•ì„  ì˜ˆì‹œì—ì„œ ë³¼ ìˆ˜ ìˆì—ˆë“¯ì´ train DBì— ìˆëŠ” data $x$ì™€ ìœ ì‚¬í•œ ìƒ˜í”Œì´ ë‚˜ì˜¬ ìˆ˜ ìˆëŠ” í™•ë¥ ë¶„í¬ë¼ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ê·¸ëƒ¥ ìƒ˜í”Œë§ í•¨ìˆ˜ë¥¼ ë§Œë“¤ê¸° ë³´ë‹¤ evidenceë¡œ xë¥¼ given(ì¡°ê±´)ìœ¼ë¡œ í•˜ì—¬ zë¥¼ ë½‘ì•„ë‚´ëŠ” í™•ë¥ ë¶„í¬ $p(z\|x)$ë¥¼ ë§Œë“¤ì–´ë‚´ëŠ” ê²ƒì´ ëª©ì ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ ì—¬ê¸°ì„œ ë˜ ë¬¸ì œì¸ ì ì€ true distridutionì¸ í•´ë‹¹ ë¶„í¬ë¥¼ ë§Œë“¤ì–´ë‚´ê¸°ìœ„í•´ Variational Inference ë°©ë²•ì„ ì´ìš©í•©ë‹ˆë‹¤. ë¶„í¬ ì¶”ì •ì„ ìœ„í•œ family, ì˜ˆë¥¼ ë“¤ë©´ guassian ë¶„í¬ë“¤ì„ Approximation Classë¡œ ë‘ê³  true distributionì„ ì¶”ì •í•©ë‹ˆë‹¤. ì´ë•Œ gaussian ë¶„í¬ì˜ íŒŒë¼ë¯¸í„°ì¸ $\phi$ëŠ” meanê³¼ std ê°’ì´ ë  ê²ƒ ì´ê³  ì´ëŸ° ì—¬ëŸ¬ gaussian ë¶„í¬ë“¤ê³¼ true posterior ê°„ì˜ KL divergenceë¥¼ êµ¬í•˜ì—¬ ì¶”ì •í•´ê°‘ë‹ˆë‹¤.

![](https://i.imgur.com/UzRI0bp.jpg)

ë”°ë¼ì„œ ì •ë¦¬í•´ë³´ë©´ ì•„ë˜ ê·¸ë¦¼ê³¼ ê°™ì´ ìƒì„±ëª¨ë¸ì¸ Generatorë¥¼ í•™ìŠµí•˜ê¸° ìœ„í•´ Variational Inference ë°©ë²•ì„ ì‚¬ìš©í•˜ê²Œ ë˜ì—ˆê³  ê·¸ëŸ¬ë‹¤ ë³´ë‹ˆ AutoEncoderì™€ ë¹„ìŠ·í•œ ëª¨ë¸ êµ¬ì¡°ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ `ë°ì´í„° ì••ì¶•`ì´ ëª©í‘œì¸ AutoEncoderì™€ `ë°ì´í„° ìƒì„±`ì´ ëª©í‘œì¸ VAEëŠ” ê°ìì˜ ëª©í‘œì— ë§ì¶° í•„ìš”í•œ ë°©ë²•ë¡ ì„ ë”í•˜ê²Œ ë˜ë©´ì„œ ê·¸ ëª¨ë¸ êµ¬ì¡°ê°€ ë¹„ìŠ·í•´ë³´ì´ê²Œ ëœ ê²ƒì´ì§€ ê°™ì§€ì•ŠìŠµë‹ˆë‹¤.

![](https://i.imgur.com/uMHIQnA.jpg)

VAEì˜ ì „ì²´ êµ¬ì¡°ëŠ” **[1] Decoder, Generator, Generation Network** ë¼ê³  ë¶€ë¥´ëŠ” ë¶€ë¶„ê³¼ **[2] Encoder, Posterior, Inference Network**ë¼ê³  ë¶€ë¥´ëŠ” ë¶€ë¶„, í¬ê²Œ 2ê°€ì§€ íŒŒíŠ¸ë¡œ ì´ë£¨ì–´ì ¸ ìˆìŠµë‹ˆë‹¤.

![](https://i.imgur.com/4rrcmgH.jpg)

# Variational Bound

ìœ„ì˜ íë¦„ì„ ì´ì–´ê°€ë³´ë©´, ì²˜ìŒì— ì•Œê³  ì‹¶ì—ˆë˜ ê²ƒì€ **(1) $p(x)$**ì˜€ìœ¼ë‚˜ ìš°ë¦¬ê°€ ì›í•˜ëŠ” ë°ì´í„°ë“¤ë¡œ ìƒ˜í”Œë§(ì»¨íŠ¸ë¡¤)í•˜ê¸° ìœ„í•´ **(2) $p(z\|x)$**(true posterior)ê°€ í•„ìš”í•´ì¡Œê³ , true posteriorë¥¼ ì•Œ ìˆ˜ ì—†ìœ¼ë‹ˆ ì´ë¥¼ ì¶”ì •(Variational Inference)í•˜ê¸° ìœ„í•´ì„œ **(3) $q_{\phi}(z\|x)$**ê°€ í•„ìš”í–ˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ìš°ë¦¬ëŠ” ì´ 3ê°œì˜ ë¶„í¬ë“¤ì˜ ê´€ê³„ë¥¼ ì¢€ ë” ì‚´í´ë³´ê³  ì–´ë–»ê²Œ ìƒì„±ëª¨ë¸ì„ í•™ìŠµí•´ë‚˜ê°ˆ ê²ƒì¸ì§€ ê³ ë¯¼í•´ë´ì•¼ í•©ë‹ˆë‹¤. 

ì²˜ìŒì˜ ëª©í‘œì˜€ë˜ $p(x)$ì— logë¥¼ ì”Œì›Œì„œ ì•„ë˜ì™€ ê°™ì€ ì‹ ë³€í˜•ì„ ì§„í–‰í•˜ë©´ 2ê°œì˜ termìœ¼ë¡œ ë‚˜ëˆ ì§‘ë‹ˆë‹¤. ì²«ë²ˆì§¸ termì€ ì´ë²ˆ ì¥ì˜ ì£¼ì¸ê³µì¸ Evidence LowerBOundë¼ëŠ” ELBOì´ê³  ë‘ë²ˆì§¸ termì€ Variational Inferenceì—ì„œ ë´¤ì—ˆë˜ true posteriorì™€ approximator ì‚¬ì´ì˜ ê±°ë¦¬ë¥¼ ë‚˜íƒ€ë‚´ëŠ” KL ê°’ì…ë‹ˆë‹¤. ì—¬ê¸°ì„œ $log(p(x))$ê°€ ì¼ì •í•  ë•Œ KL ê°’ì„ ì¤„ì´ëŠ” ê²ƒì´ ëª©í‘œ(=true posteriorë¥¼ ì˜ approximationí•˜ëŠ” ê²ƒ)ì´ê³  KLì€ í•­ìƒ ì–‘ìˆ˜ì´ê¸° ë•Œë¬¸ì—, ì—­ìœ¼ë¡œ ìƒê°í•´ë³´ë©´ ì²«ë²ˆì§¸ termì´ì—ˆë˜ ELBO ê°’ì„ ìµœëŒ€í™”í•˜ëŠ” ê²ƒì´ë¼ê³  ìƒê°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ ê°„ë‹¨íˆ ê·¸ë˜í”„ë¡œ ë‚˜íƒ€ë‚´ë³´ë©´ ì˜¤ë¥¸ìª½ ê·¸ë¦¼ì—ì„œ ë³¼ ìˆ˜ ìˆë“¯ì´ ìš°ë¦¬ê°€ ì›í•˜ëŠ” ê²ƒì€ ELBOê°’ì´ ì»¤ì§ˆ ìˆ˜ ìˆëŠ” $\phi$ë¥¼ ì°¾ì•„ê°€ëŠ” ê³¼ì •ì´ë¼ê³  ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

![](https://i.imgur.com/B5gwqlT.jpg)

ë”°ë¼ì„œ ELBOê°’ì´ ì»¤ì§ˆ ìˆ˜ ìˆëŠ” $\phi$ë¥¼ ì°¾ì•„ê°€ëŠ” ìµœì í™”ë¥¼ ìˆ˜ì‹ì„ ë³€í˜•í•˜ì—¬ ë˜ ë‹¤ì‹œ 2ê°œì˜ termìœ¼ë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆëŠ”ë° (1) `Reconstructino Error`ì™€ (2) `Regularization` ìœ¼ë¡œ ë³¼ ìˆ˜ ìˆê³  ê° termì€ ë‹¤ìŒê³¼ ê°™ì´ í•´ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

![](https://i.imgur.com/J0uo8qQ.jpg)

![](https://i.imgur.com/vjQJAWt.jpg)

## Regularization term

ELBO termì„ ë‚˜ëˆ„ì—ˆì„ ë•Œ ë‚˜ì™”ë˜ ì²«ë²ˆì§¸ Regularization termì— ëŒ€í•´ ë³´ê² ìŠµë‹ˆë‹¤. True posteriorë¥¼ ì¶”ì •í•˜ê¸° ìœ„í•œ $q_{\phi}(z\|x)$ì€ KL ê°’ì„ ê³„ì‚°í•˜ê¸° ì‰½ë„ë¡ í•˜ê¸° ìœ„í•´ Multivariate gaussian distributionìœ¼ë¡œ ì„¤ê³„í•©ë‹ˆë‹¤. ë˜í•œ ì•ì„œ ì´ì•¼ê¸°í–ˆë˜ ê²ƒ ì²˜ëŸ¼ controller ë¶€ë¶„ì¸ $p(z)$ëŠ” ë‹¤ë£¨ê¸° ì‰¬ìš´ ë¶„í¬ì´ì–´ì•¼ í•˜ê¸° ë•Œë¬¸ì— ì •ê·œë¶„í¬ë¡œ ë§Œë“¤ì–´ ì¤ë‹ˆë‹¤. ê·¸ëŸ¬ë©´ ë…¼ë¬¸ì˜ Appendix F.1ì—ì„œ ë³¼ ìˆ˜ ìˆë“¯ì´ ê°€ìš°ì‹œì•ˆ ë¶„í¬ë“¤ ì‚¬ì´ì˜ KL ê°’ì€ ë‹¤ìŒê³¼ ê°™ì´ ì‰½ê²Œ ê³„ì‚°ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

![](https://i.imgur.com/NXEFibn.jpg)

## Reconstruction error term

ELBOì˜ ë‘ë²ˆì§¸ termì¸ Reconstruction errorì— ëŒ€í•´ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤. Reconstruction errorì˜ expectation í‘œí˜„ì„ integralë¡œ í‘œí˜„í•˜ë©´ ë‹¤ìŒê³¼ ê°™ê³  ì´ëŠ” ëª¬í…Œì¹´ë¥¼ë¡œ ìƒ˜í”Œë§ì„ í†µí•´ $L$ê°œì˜ $z^{i, l}$ë¥¼ ê°€ì§€ê³  í‰ê· ì„ ë‚´ì„œ êµ¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—¬ê¸°ì—ì„œ index $i$ëŠ” ë°ì´í„° $x$ì˜ ë„˜ë²„ë§ì´ê³  index $l$ì€ generatorì˜ distributionì—ì„œ ìƒ˜í”Œë§í•˜ëŠ” íšŸìˆ˜ì— ëŒ€í•œ ë„˜ë²„ë§ì…ë‹ˆë‹¤.

![](https://i.imgur.com/xuJwkVJ.jpg)

### Reparametrization Trick

ìœ„ì—ì„œ Reconstruction errorë¥¼ êµ¬í•˜ê¸° ìœ„í•´ ìƒ˜í”Œë§í•˜ëŠ” ê³¼ì •ì—ì„œ backpropationì„ í•˜ê¸° ìœ„í•´ **Reparametrization trick**ì„ ì‚¬ìš©í•˜ê²Œ ë©ë‹ˆë‹¤. ë‹¨ìˆœíˆ ì •ê·œë¶„í¬ì—ì„œ ìƒ˜í”Œë§ í•˜ë©´ random nodeì¸ $z$ì— ëŒ€í•´ì„œ gradientë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ê¸° ë•Œë¬¸ì— randomì„±ì„ ì •ê·œë¶„í¬ì—ì„œ ìƒ˜í”Œë§ ë˜ëŠ” $\epsilon$ìœ¼ë¡œ ë§Œë“¤ì–´ì£¼ê³  ì´ë¥¼ reparametrizationì„ í•´ì£¼ì–´ì„œ deterministic nodeê°€ ëœ $z$ë¥¼ backpropagation í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤. 

![](https://i.imgur.com/9b1CPni.jpg)

$z$ë¥¼ ìƒ˜í”Œë§í•˜ëŠ” generatorì˜ distributionì€ Bernoullië¡œ ë””ìì¸í•  ê²½ìš° NLLì´ Cross Entropyê°€ ë˜ë©° Gaussian ë¶„í¬ë¡œ ë””ìì¸í•  ê²½ìš° MSEê°€ ë˜ì–´ì„œ ë³´í†µ ê³„ì‚°í•˜ê¸° ìš©ì´í•œ 2ê°œì˜ ë¶„í¬ ì¤‘ í•˜ë‚˜ë¥¼ ì‚¬ìš©í•˜ê²Œ ë©ë‹ˆë‹¤.

![](https://i.imgur.com/lCMjRUO.jpg)

# VAE Structure

ì§€ê¸ˆê¹Œì§€ ì‚´í´ë³¸ VAE êµ¬ì¡°ëŠ” Encoderì™€ Decoderë¥¼ ê°ê° ì–´ë–¤ ë¶„í¬ë¡œ ë””ìì¸í•´ì£¼ëŠ” ëƒì— ë”°ë¼ Reconstruction errorì™€ Regularizationì„ ê³„ì‚°í•˜ëŠ” ì‹ë§Œ ì¡°ê¸ˆì”© ë‹¬ë¼ì§€ê²Œ ë©ë‹ˆë‹¤. Encoder ë¶€ë¶„ì€ Reconstruction errorì˜ ê³„ì‚°ì˜ ìš©ì´ì„± ë•Œë¬¸ì— ê±°ì˜ ê°€ìš°ì‹œì•ˆ ë¶„í¬ë¥¼ ì‚¬ìš©í•˜ê²Œ ë˜ê³  Decoder ë¶€ë¶„ë§Œ ë³€í˜•í•˜ì—¬ ì•„ë˜ì˜ ì—¬ëŸ¬ ìœ í˜•ë“¤ì´ ë‚˜íƒ€ë‚˜ê²Œ ë©ë‹ˆë‹¤.

![](https://i.imgur.com/JPOVTlK.jpg)

![](https://i.imgur.com/fNma1fZ.jpg)

![](https://i.imgur.com/fNma1fZ.jpg)

![](https://i.imgur.com/Si4xjNg.jpg)

MNISTë¥¼ ì˜ˆì‹œë¡œ ë“¤ì–´ì„œ VAE êµ¬ì¡°ë¥¼ ë‚˜íƒ€ë‚´ë³´ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

![](https://i.imgur.com/FqjKwdF.jpg)

# Experiment

í•´ë‹¹ ë…¼ë¬¸ì—ì„œ ì‹¤í—˜ì€ ì´ 2ê°€ì§€ë¥¼ ì§„í–‰í–ˆëŠ”ë° ì•ì—ì„œëŠ” ê³„ì† VAEë¡œ ë‚˜íƒ€ëƒˆì§€ë§Œ ë…¼ë¬¸ì—ì„œëŠ” í•´ë‹¹ ì•Œê³ ë¦¬ì¦˜ì„ AEVBë¡œ ì§€ì¹­í•˜ê¸° ë•Œë¬¸ì— ì´ë¥¼ VAE ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ìƒê°í•˜ê³  ì‹¤í—˜ ê²°ê³¼ë“¤ì„ ë³´ë©´ ë©ë‹ˆë‹¤. ìš°ì„  ì²«ë²ˆì§¸ëŠ” MNIST ë°ì´í„°ì…‹ê³¼ Frey Face ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ ë² ì´ìŠ¤ë¼ì¸ìœ¼ë¡œ wake-sleep ì•Œê³ ë¦¬ì¦˜ê³¼ ì„±ëŠ¥ì„ ë¹„êµí–ˆìŠµë‹ˆë‹¤. ELBOê°’ì„ ìµœëŒ€í™”í•˜ëŠ” ê²ƒì´ ëª©í‘œì´ë¯€ë¡œ ê°’ì´ í´ìˆ˜ë¡ ì¢‹ì€ ê²ƒìœ¼ë¡œ í•´ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì•„ë˜ì˜ ê·¸ë˜í”„ë“¤ì—ì„œ ì‹¤ì„ ê³¼ ì ì„ ì€ ê°ê° trainê³¼ test ë°ì´í„°ì…‹ì— ëŒ€í•´ ELBO ê°’ì„ plottingí•œ ê²ƒìœ¼ë¡œ latent variableì¸ $z$ì˜ ì°¨ì›ì˜ í¬ê¸°ì— ë”°ë¼ ELBO ê°’ì´ ì–´ë–¤ ì–‘ìƒì„ ë‚˜íƒ€ë‚´ëŠ”ì§€ ë³´ì—¬ì¤ë‹ˆë‹¤.  

![](https://i.imgur.com/1vllCMk.jpg)

ë‘ë²ˆì§¸ë¡œëŠ” MNIST ë°ì´í„°ì…‹ì— ëŒ€í•´ì„œ $z$ì˜ ì°¨ì›ì´ 1000, 50000ì¼ë•Œì˜ ê° ì•Œê³ ë¦¬ì¦˜ë“¤ì˜ ì„±ëŠ¥ì„ í•™ìŠµ ìƒ˜í”Œìˆ˜ì— ë”°ë¼ Marginal log-likelihoodë¥¼ plottingí•˜ì—¬ ë‚˜íƒ€ëƒˆìŠµë‹ˆë‹¤. ì´ ì‹¤í—˜ì—ì„œëŠ” ë² ì´ìŠ¤ë¼ì¸ìœ¼ë¡œ Wake-Sleepê³¼ MCEMì„ ì‚¬ìš©í–ˆìœ¼ë©° ì—¬ê¸°ì„œë„ AEVB(=VAE)ê°€ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤.

![](https://i.imgur.com/cPEO4wa.jpg)

# Conclusion

![](https://i.imgur.com/VwtJ70W.jpg)

> ì•„ë˜ëŠ” ì¶”ê°€ì ìœ¼ë¡œ VAEë¥¼ ë°œí‘œí•œ í›„ì— ë°›ì•˜ë˜ in-class ì§ˆë¬¸ë“¤ì— ëŒ€í•´ ë‹µë³€í•´ë³¸ ë¶€ë¶„ë“¤ ì…ë‹ˆë‹¤. ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì€ solutionì´ ì•„ë‹Œ discussionìœ¼ë¡œë§Œ ì°¸ê³ í•´ì£¼ì„¸ìš”.

<details>
<summary><b>Questions in class</b></summary>
    <p>
    <a href="https://imgur.com/RHarOED"><img src="https://i.imgur.com/RHarOED.jpg" title = "Question 1"/></a>
    </p>
    <p>
    <a href="https://imgur.com/cRj4GHK"><img src="https://i.imgur.com/cRj4GHK.jpg" title = "Question 2"/></a>
    </p>
    <p>
    <a href="https://imgur.com/PxPm5Pf"><img src="https://i.imgur.com/PxPm5Pf.jpg" title = "Question 3"/></a>
    </p>
    <p>
    <a href="https://imgur.com/dT1dXfc"><img src="https://i.imgur.com/dT1dXfc.jpg" title = "Question 4" /></a>
    </p>
    <p>
    <a href="https://imgur.com/ajgw7p8"><img src="https://i.imgur.com/ajgw7p8.jpg" title = "Question 5" /></a>
    </p>
    <p>
    <a href="https://imgur.com/mIxVuO4"><img src="https://i.imgur.com/mIxVuO4.jpg" title = "Question 6" /></a>
    </p>
    <p>
    <a href="https://imgur.com/N2fIvvh"><img src="https://i.imgur.com/N2fIvvh.jpg" title = "Question 7" /></a>
    </p>
    <p>
    <a href="https://imgur.com/0OZrZOE"><img src="https://i.imgur.com/0OZrZOE.jpg" title = "Question 8" /></a>
    </p>
    <p>
    <a href="https://imgur.com/czPUc72"><img src="https://i.imgur.com/czPUc72.jpg" title = "Question 9" /></a>
    </p>
    <p>
    <a href="https://imgur.com/qsRONAE"><img src="https://i.imgur.com/qsRONAE.jpg" title = "Question 10" /></a>
    </p>
    <p>
    <a href="https://imgur.com/zsjDlrB"><img src="https://i.imgur.com/zsjDlrB.jpg" title = "Question 11" /></a>
    </p>
</details>

**Reference**

- original paper: [https://arxiv.org/abs/1312.6114](https://arxiv.org/abs/1312.6114)

[1] [https://di-bigdata-study.tistory.com/5](https://di-bigdata-study.tistory.com/5)

[2] [https://di-bigdata-study.tistory.com/4?category=848869](https://di-bigdata-study.tistory.com/4?category=848869)

[3] [https://ratsgo.github.io/generative%20model/2017/12/19/vi/](https://ratsgo.github.io/generative%20model/2017/12/19/vi/)

[4] [https://taeu.github.io/paper/deeplearning-paper-vae/](https://taeu.github.io/paper/deeplearning-paper-vae/)

[5] [https://medium.com/humanscape-tech/paper-review-vae-ac918509a9ba](https://medium.com/humanscape-tech/paper-review-vae-ac918509a9ba
)

[6] [https://www.youtube.com/watch?v=o_peo6U7IRM](https://www.youtube.com/watch?v=o_peo6U7IRM)

[7] [https://youtu.be/SAfJz_uzaa8](https://youtu.be/SAfJz_uzaa8)

[8] [https://youtu.be/GbCAwVVKaHY](https://youtu.be/GbCAwVVKaHY)

[9] [https://youtu.be/7t_3dNs4QK4](https://youtu.be/7t_3dNs4QK4)