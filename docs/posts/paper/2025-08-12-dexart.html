<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.33">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2025-08-12">
<meta name="description" content="Benchmarking Generalizable Dexterous Manipulation with Articulated Objects">

<title>📃DexArt 리뷰 – Curieux.JY</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../profile.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-ea385d0e468b0dd5ea5bf0780b1290d9.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark-bc185b5c5bdbcb35c2eb49d8a876ef70.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-ea385d0e468b0dd5ea5bf0780b1290d9.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-23aef1c2a45953e85f3378e7ccfb1407.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark-5a614c35f1f90bfd0a5b2992298a8538.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-23aef1c2a45953e85f3378e7ccfb1407.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-2NVZN2MJZT"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-2NVZN2MJZT', { 'anonymize_ip': true});
</script>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-fixed quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Curieux.JY</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../post.html"> 
<span class="menu-text">Post</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../note.html"> 
<span class="menu-text">Note</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">Jung Yeon Lee</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/curieuxjy"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#brief-review" id="toc-brief-review" class="nav-link active" data-scroll-target="#brief-review">Brief Review</a></li>
  <li><a href="#detail-review" id="toc-detail-review" class="nav-link" data-scroll-target="#detail-review">Detail Review</a>
  <ul class="collapse">
  <li><a href="#배경-로봇-섬세-조작과-관절-객체의-도전" id="toc-배경-로봇-섬세-조작과-관절-객체의-도전" class="nav-link" data-scroll-target="#배경-로봇-섬세-조작과-관절-객체의-도전">배경: 로봇 섬세 조작과 관절 객체의 도전</a></li>
  <li><a href="#기존-벤치마크의-한계" id="toc-기존-벤치마크의-한계" class="nav-link" data-scroll-target="#기존-벤치마크의-한계">기존 벤치마크의 한계</a></li>
  <li><a href="#dexart-벤치마크-구성과-특징" id="toc-dexart-벤치마크-구성과-특징" class="nav-link" data-scroll-target="#dexart-벤치마크-구성과-특징">DexArt 벤치마크: 구성과 특징</a></li>
  <li><a href="#성능-평가와-실험-설정" id="toc-성능-평가와-실험-설정" class="nav-link" data-scroll-target="#성능-평가와-실험-설정">성능 평가와 실험 설정</a></li>
  <li><a href="#주요-결과와-통찰" id="toc-주요-결과와-통찰" class="nav-link" data-scroll-target="#주요-결과와-통찰">주요 결과와 통찰</a></li>
  <li><a href="#한계점-및-향후-과제" id="toc-한계점-및-향후-과제" class="nav-link" data-scroll-target="#한계점-및-향후-과제">한계점 및 향후 과제</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-page-left" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">📃DexArt 리뷰</h1>
  <div class="quarto-categories">
    <div class="quarto-category">benchmark</div>
    <div class="quarto-category">rl</div>
    <div class="quarto-category">survey</div>
  </div>
  </div>

<div>
  <div class="description">
    Benchmarking Generalizable Dexterous Manipulation with Articulated Objects
  </div>
</div>


<div class="quarto-title-meta column-page-left">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">August 12, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<ul>
<li><a href="https://arxiv.org/abs/2305.05706">Paper Link</a></li>
</ul>
<ol type="1">
<li>🕹️ 이 논문은 다지(multi-finger) 로봇 손을 사용하여 다양한 다관절 객체를 조작하는 능력을 벤치마킹하는 새로운 데이터셋 및 태스크 스위트인 DexArt를 제안합니다.</li>
<li>🤖 DexArt 벤치마크는 3D Point Cloud 관측값을 기반으로 RL(Reinforcement Learning) 정책을 학습하며, 특히 학습되지 않은 객체에 대한 일반화 성능과 시각적 표현 학습의 영향을 평가합니다.</li>
<li>💡 연구 결과, 더 많은 객체로 훈련할수록 일반화 성능이 향상되고, 더 작은 PointNet 인코더가 효율적이며, 객체 부분 분할(part segmentation) 사전 학습이 조작 성능 및 카메라 시점 변화에 대한 강건성을 크게 개선함을 밝혀냈습니다.</li>
</ol>
<hr>
<section id="brief-review" class="level1">
<h1>Brief Review</h1>
<p>이 논문은 로봇이 일상생활에서 인간처럼 다양한 가동형(articulated) 물체를 조작할 수 있도록 하기 위한 새로운 벤치마크인 DexArt를 제안합니다. 현재 로봇 조작은 주로 병렬 그리퍼에 의존하고 있어 제한된 물체에만 적용 가능합니다. 반면, 다중 손가락 로봇 손(multi-finger robot hand)은 인간의 행동에 더 가깝게 모방하고 다양한 가동형 물체 조작을 가능하게 합니다. 본 벤치마크는 물리 시뮬레이터에서 가동형 물체를 이용한 정교한(dexterous) 조작을 다루며, 여러 복잡한 조작 작업을 정의하고 각 작업 내에서 다양한 가동형 물체를 조작해야 합니다. 주요 목표는 학습된 정책의 미등록(unseen) 가동형 물체에 대한 일반화 능력(generalizability)을 평가하는 것입니다. 이는 로봇 손과 물체 모두의 높은 자유도(Degrees of Freedom, DoF) 때문에 매우 어려운 문제입니다.</p>
<p>이 연구는 일반화를 달성하기 위해 3D 표현 학습(3D representation learning)과 Reinforcement Learning (RL)을 통합합니다. 3D 점군(point cloud)을 관측으로 사용하고 PointNet 인코더를 통해 시각적 표현을 추출하여 의사 결정을 수행합니다. 이 연구는 광범위한 실험을 통해 3D 표현 학습이 3D 점군 입력을 사용하는 RL의 의사 결정에 어떤 영향을 미치는지에 대한 새로운 통찰력을 제공합니다.</p>
<p><strong>핵심 방법론 (Core Methodology)</strong></p>
<ol type="1">
<li><strong>DexArt 벤치마크 구성:</strong>
<ul>
<li><strong>작업(Task) 정의:</strong> Faucet (수도꼭지 돌리기), Bucket (양동이 들기), Laptop (노트북 열기), Toilet (변기 뚜껑 열기)의 네 가지 작업을 제시합니다. 각 작업은 로봇 손이 물체의 특정 가동 부분과 상호작용하도록 요구합니다. 예를 들어, Faucet 작업은 수도꼭지 손잡이를 잡고 약 90도 회전시키는 것을 목표로 하며, 이는 다중 손가락 손의 미세한 조작 능력을 평가합니다. Bucket 작업은 양동이 손잡이 아래로 손을 넣어 안정적인 형태 폐쇄(form closure)를 구성하여 들어 올리는 것을 목표로 합니다.</li>
<li><strong>환경 설정:</strong> SAPIEN 물리 시뮬레이터에서 6자유도(DoF) XArm6 로봇 팔과 16자유도 Allegro Hand를 사용합니다.
<ul>
<li><strong>관측 공간(Observation Space):</strong> 두 부분으로 구성됩니다.
<ul>
<li><strong>고유 수용 데이터(Proprioceptive Data) <span class="math inline">S_r</span>:</strong> 로봇 전체의 현재 관절 위치, 선형 및 각속도, 그리고 말단 작업기(end-effector) 손바닥의 위치 및 자세를 포함합니다.</li>
<li><strong>부분 점군(Partial Point Cloud) <span class="math inline">P_o</span>:</strong> 깊이 카메라로 촬영된 가동형 물체와 로봇의 점군을 포함합니다. 이 점군은 로봇 작업 공간 내에서 잘리고 균일하게 다운샘플링됩니다. 또한, 로봇 모델을 사용하여 생성된 가상 로봇 점군(imagined robot point cloud) <span class="math inline">P_i</span>를 <span class="math inline">P_o</span>에 연결하여 손가락과 같은 로봇의 세부 정보를 보완합니다.</li>
</ul></li>
<li><strong>행동 공간(Action Space):</strong> 22차원 벡터로 구성됩니다. 로봇 팔에는 목표 선형 및 각속도에 대한 6자유도 작동 공간 제어(operational space control)를 사용하고, Allegro Hand에는 16개 관절의 목표 위치를 제어하는 관절 위치 제어기(PD control)를 사용합니다.</li>
</ul></li>
<li><strong>보상 설계(Reward Design):</strong> 세 가지 원칙을 따릅니다: (i) 합리적인 시간 내 해결을 위한 밀집 보상(dense reward), (ii) 자연스럽고 안전한 행동 유도, (iii) 일반적이고 표준화된 구조. 작업은 기능적 부분에 도달, 손과 물체 간 접촉 형성, 작업별 행동 실행의 세 단계로 나뉩니다.
<ul>
<li><strong>도달 및 잡기 단계:</strong>
<ul>
<li>도달 보상: <span class="math inline">r_{\text{reach}} = \mathbf{1}(\text{stage} == 1) \min(-\|x_{\text{palm}} - x_{\text{object}}\|, \lambda)</span> 여기서 <span class="math inline">\mathbf{1}()</span>는 지시 함수(indicator function), <span class="math inline">x_{\text{palm}}</span>과 <span class="math inline">x_{\text{object}}</span>는 손바닥과 물체의 3D 위치, <span class="math inline">\lambda</span>는 보상 급증 방지를 위한 정규화 항입니다.</li>
<li>접촉 보상: <span class="math inline">r_{\text{contact}} = \mathbf{1}(\text{stage} \geq 2) \text{IsContact}(\text{palm, object}) \land \left(\sum_{\text{finger}} \text{IsContact}(\text{finger, object}) \geq 2\right)</span> 여기서 <span class="math inline">\text{IsContact}</span>는 충돌 감지 부울 함수입니다. 손바닥과 최소 두 손가락이 물체에 접촉할 때 좋은 접촉이 형성된 것으로 간주합니다.</li>
</ul></li>
<li><strong>부분 조작 단계:</strong>
<ul>
<li>진행 보상: <span class="math inline">r_{\text{progress}} = \mathbf{1}(\text{stage} == 3)\text{Progress}(\text{task})</span> <span class="math inline">\text{Progress}</span>는 작업 진행도를 나타내는 작업별 평가 함수입니다.</li>
</ul></li>
<li><strong>패널티:</strong> 로봇 움직임의 불안정성을 줄이기 위해 행동의 <span class="math inline">L_2</span> norm과 작업별 항을 포함하는 패널티 <span class="math inline">r_{\text{penalty}}</span>를 추가합니다. 총 보상은 이 네 가지 보상 항의 가중 합입니다.</li>
</ul></li>
<li><strong>자산 선택 및 주석:</strong> PartNet-Mobility 데이터셋의 가동형 물체 모델을 사용하며, 각 작업에 적합하도록 수동으로 선택하고, 스케일 및 초기 위치를 주석 처리합니다. 로봇과의 초기 교차를 방지하고 목표 달성을 보장하기 위해 무작위성을 적용합니다.</li>
</ul></li>
<li><strong>정책 학습 아키텍처 및 시각적 사전 학습(Visual Pre-training):</strong>
<ul>
<li><strong>정책 학습:</strong> 카테고리 수준의 일반화를 위해 3D 점군을 관측으로 사용하고 PPO (Proximal Policy Optimization) 알고리즘을 RL 알고리즘으로 채택합니다. PointNet을 점군 특징 추출기(feature extractor)로 사용하며, 이 특징은 로봇 고유 수용 벡터 <span class="math inline">S_r</span>에서 추출된 특징과 결합되어 가치망(value network)과 정책망(policy network)으로 전달됩니다.</li>
<li><strong>점군 상상(Point Cloud Imagination):</strong> 로봇-물체 상호작용 시 발생하는 폐색(occlusion)과 메모리 제약으로 인한 저해상도 점군 문제를 해결하기 위해, 순방향 운동학(forward kinematics)을 통해 로봇 손가락의 기하학적 형태를 계산하여 가상 점군 <span class="math inline">P_i</span>를 샘플링하고 관측 점군 <span class="math inline">P_o</span>와 함께 PointNet 입력으로 사용합니다. 이는 실제 로봇 환경에서도 접근 가능한 정보입니다.</li>
<li><strong>사전 학습 데이터셋:</strong>
<ul>
<li><strong>DexArt Manipulation Dataset (DAM):</strong> 조작 작업과 동일한 설정으로 렌더링된 점군 관측 데이터를 포함합니다. 로봇과 가동형 물체의 상태를 무작위로 샘플링하여 관측 및 가상 점군을 생성합니다. 분할(segmentation) 사전 학습을 위해 점군을 기능 부분, 나머지 물체, 로봇 손, 로봇 팔의 4개 그룹으로 레이블링합니다.</li>
<li><strong>PartNet-Mobility Manipulation Dataset (PMM):</strong> PartNet-Mobility에서 직접 렌더링되며, 46개의 물체 카테고리와 각 카테고리당 1,000개의 점군을 포함합니다. 물체 상태와 카메라 시점은 무작위로 샘플링됩니다. 분류(classification)를 위해 각 물체는 동일한 카테고리 레이블을 공유하며, 분할을 위해 가동형 물체의 기능 부분에 대한 정답 분할 마스크를 생성합니다.</li>
</ul></li>
<li><strong>사전 학습 방법:</strong> 시각적 특징 추출기(PointNet)의 초기화를 위해 다양한 3D 표현 학습 방법을 벤치마킹합니다.
<ul>
<li><strong>지도 학습(Supervised Pre-training):</strong>
<ul>
<li><strong>의미 분할(Semantic Segmentation):</strong> DAM 및 PMM 데이터셋에서 PointNet을 학습시켜 점군을 기능 부분, 나머지 물체, 로봇 손, 로봇 팔 등으로 분할합니다.</li>
<li><strong>분류(Classification):</strong> PMM 데이터셋에서 PointNet을 학습시켜 46개 물체 카테고리 중 하나로 분류합니다.</li>
</ul></li>
<li><strong>자기 지도 학습(Self-supervised Pre-training):</strong>
<ul>
<li><strong>점군 재구성(Point Cloud Reconstruction):</strong> OcCo 연구를 따라 DAM 데이터셋에서 인코더-디코더(PointNet 인코더 + PCN 디코더) 아키텍처를 사용하여 원본 점군을 재구성합니다. 재구성 손실로는 Chamfer loss를 사용합니다.</li>
<li><strong>SimSiam:</strong> DAM 데이터셋에서 PointNet을 사용하여 siamese 네트워크를 설계합니다. 동일한 점군의 두 가지 증강된 뷰를 입력으로 받아 PointNet 인코더를 통과시킨 후, 한쪽에서 유사성을 예측하고 다른 쪽에서는 기울기 전파를 중단하여 양쪽의 유사성을 최대화하도록 학습합니다.</li>
</ul></li>
</ul></li>
</ul></li>
</ol>
<p><strong>실험 결과 및 주요 관찰 (Experiments and Key Observations)</strong></p>
<ul>
<li><strong>주요 결과:</strong> 적절한 시각적 사전 학습이 정책 학습에 이점을 제공하며, 특히 “부분 분할(part segmentation)” 사전 학습은 모든 작업에서 가장 좋은 성능을 보였습니다. 이는 PointNet이 기능적 부분을 더 잘 구별하고 위치를 파악하게 하여, 섬세한 조작 작업에 필수적임을 시사합니다.</li>
<li><strong>어블레이션 연구(Ablation Study):</strong>
<ul>
<li><strong>훈련에 사용된 물체 수:</strong> 더 많은 미등록 물체를 사용한 훈련이 정책의 일반화 능력에 중요함을 보여주었습니다. 50%의 등록된 물체로 훈련한 경우보다 100%를 사용한 경우가 미등록 물체에 대해 일관되게 더 높은 성공률을 보였습니다.</li>
<li><strong>시각 특징 추출기 크기:</strong> 가장 작은 PointNet(은닉 계층이 하나)이 가장 좋은 성능을 달성하고 샘플 효율성도 뛰어났습니다. 이는 일반적으로 시각 분야에서 더 큰 네트워크가 더 나은 성능을 보이는 것과 상반되는 결과로, RL 최적화에서 큰 인코더가 더 어려운 문제를 야기할 수 있음을 시사합니다.</li>
<li><strong>비-3D 표현(Non-3D Representation):</strong> R3M의 ResNet-18과 같은 2D 기반 사전 학습 표현과 비교했을 때, PointNet을 사용한 3D 시각 표현 학습이 등록 및 미등록 물체 모두에서 더 나은 조작 성능을 달성했습니다.</li>
</ul></li>
<li><strong>시점 변화에 대한 견고성(Robustness to Viewpoint Change):</strong> PointNet 기반 정책은 카메라 시점 변화에 대해 뛰어난 견고성을 보였습니다. 훈련 시점과 크게 다른 시점에서도 성공률이 일관되게 유지되었습니다. 이는 PointNet 아키텍처와 점군 표현 학습에서 비롯된 것으로 분석됩니다.</li>
</ul>
<p><strong>결론 (Conclusion)</strong></p>
<p>이 연구는 가동형 물체에 대한 정교한 조작을 위한 새로운 벤치마크 DexArt를 제안하고, RL 정책의 일반화 능력을 연구했습니다. 주요 통찰력은 다음과 같습니다.</p>
<ol type="i">
<li>더 다양한 물체로 RL을 훈련하면 더 나은 일반화 능력을 얻을 수 있습니다.</li>
<li>RL 훈련에는 큰 인코더가 항상 필요한 것은 아니며, 가장 단순한 PointNet이 가장 좋은 샘플 효율성과 일반화 능력을 보였습니다.</li>
<li>3D 시각 이해, 특히 부분 분할 사전 학습은 미세한 기능 부분 조작에 도움이 되며, 모든 시각 사전 학습 방법은 큰 기능 부분 조작에 도움이 됩니다.</li>
<li>PointNet 특징 추출기를 사용한 기하학적 표현 학습은 카메라 시점 변화에 대한 정책의 강력한 견고성을 제공합니다. DexArt가 일반화 가능한 정교한 조작 기술 및 인지(perception)와 의사 결정 간의 공동 발전을 연구하는 플랫폼 역할을 할 수 있기를 기대합니다.</li>
</ol>
<hr>
</section>
<section id="detail-review" class="level1">
<h1>Detail Review</h1>
<blockquote class="blockquote">
<p>DexArt: 관절형 객체 섬세 조작을 위한 범용 벤치마크</p>
</blockquote>
<section id="배경-로봇-섬세-조작과-관절-객체의-도전" class="level2">
<h2 class="anchored" data-anchor-id="배경-로봇-섬세-조작과-관절-객체의-도전">배경: 로봇 섬세 조작과 관절 객체의 도전</h2>
<p>가정에서 인간이 다루는 일상 물체들의 상당수는 <strong>관절형 객체(articulated objects)</strong>입니다. 문손잡이, 수납장 도어, 수도꼭지, 뚜껑 등은 모두 하나 이상의 회전 또는 슬라이딩 관절을 지니고 있어, 물체 일부를 움직여야 전체 기능을 사용할 수 있습니다. 이러한 물체를 사람처럼 능숙하게 다루는 능력은 <strong>범용 가정용 로봇</strong>에게 필수적입니다. 그러나 로봇에게 인간 수준의 <strong>섬세 조작(dexterous manipulation)</strong> 기술을 학습시키는 일은 쉽지 않습니다. 기존 로봇 팔은 주로 두 손가락 집게 형태의 <strong>패러럴 그리퍼(parallel gripper)</strong>를 사용해왔는데, 이는 구조가 단순한 대신 취급할 수 있는 물체 형태에 제약이 크다는 한계가 있습니다. 예를 들어, 집게형 그리퍼로는 양동이의 손잡이를 들어올리거나 불규칙한 모양의 뚜껑을 여는 등 <strong>복잡한 형상의 물체</strong>를 다루기가 어렵습니다. 반면 <strong>다섯 손가락을 갖춘 인간형 로봇 손</strong>을 사용하면 인간의 손 동작을 보다 가깝게 모방할 수 있어 훨씬 다양한 물체를 조작할 수 있을 것으로 기대됩니다. 물론 다관절 로봇 손 자체가 갖는 높은 자유도(DoF) 때문에 제어가 복잡해지며, 거기에 더해 관절로 연결된 물체의 동적인 움직임까지 다뤄야 하므로 <strong>상태공간과 행동공간이 폭발적으로 늘어나</strong> 학습이 매우 어려운 문제가 됩니다. 사실 최근까지도 강화학습 등을 통해 로봇 손의 섬세 조작을 다루는 연구들은 주로 공 하나를 쥐고 흔들기, 손바닥 위에서 물체 돌리기 등의 <strong>단일 강체 물체</strong>에 국한되는 경우가 많았습니다. 다양한 <strong>관절형 도구</strong>들을 다루는 범용 스킬로 확장하려면, 시각적인 인식과 복잡한 제어 사이의 통합적 접근이 필요하며 이에 따른 새로운 연구 난제가 제기됩니다.</p>
</section>
<section id="기존-벤치마크의-한계" class="level2">
<h2 class="anchored" data-anchor-id="기존-벤치마크의-한계">기존 벤치마크의 한계</h2>
<p>강화학습 및 로봇 제어 연구의 발전을 위해 여러 <strong>로봇 조작 벤치마크</strong>가 제안되어 왔습니다. 예를 들어, MetaWorld 벤치마크는 50개가 넘는 다양한 작업(task) 환경을 제공하여 강화학습 알고리즘을 평가할 수 있도록 합니다. 그러나 MetaWorld의 각 작업은 하나의 특정 물체만을 대상으로 설계되어 있어, <strong>동일 작업에서 새로운 물체로의 일반화</strong>(generalization)를 측정하기 어렵다는 한계가 있습니다. 이러한 일반화 능력을 다루기 위해 나온 ManiSkill 벤치마크는 여러 유형의 조작 과제와 함께 과제당 다수의 객체 모델을 포함시켜, 한 정책이 <strong>여러 객체 인스턴스에 걸쳐 작동</strong>하도록 평가합니다. 이는 로봇의 범용성을 높이는 방향으로 고무적이었지만, ManiSkill이 취한 <strong>패러럴 그리퍼 사용</strong>이라는 전제에는 근본적인 제약이 있습니다. 두 손가락 그리퍼만으로는 로봇이 할 수 있는 조작의 종류와 방식이 제한되기 때문에, 양동이 손잡이를 드는 등 <strong>멀티핑거 손이 요구되는 섬세 작업</strong>을 다루지 못합니다. 요컨대 기존 벤치마크들은 일반화 문제를 충분히 고려하지 않거나, 로봇 손의 능력이 제한되어 실제 인간 수준의 다양한 작업을 포괄하지 못했습니다. 이로 인해 <strong>관절형 객체</strong>를 사람처럼 자유롭게 다루는 범용적이고 섬세한 조작 기술을 평가하고 향상시키는 데에는 여전히 적절한 평가 환경이 부족했습니다.</p>
</section>
<section id="dexart-벤치마크-구성과-특징" class="level2">
<h2 class="anchored" data-anchor-id="dexart-벤치마크-구성과-특징">DexArt 벤치마크: 구성과 특징</h2>
<p>이러한 한계를 해결하고자 2023년 CVPR에서 발표된 <strong>DexArt</strong> 벤치마크는, <strong>다관절 로봇 손을 이용해 다양한 관절형 물체를 조작</strong>하는 새로운 평가 표준을 제시했습니다. DexArt는 물리 시뮬레이터 상에서 정의된 여러 개의 조작 <strong>과제(task)</strong>들로 이루어져 있으며, 각 과제마다 <strong>훈련용으로 미리 본 객체(seen)</strong>와 <strong>테스트용으로 처음 보는 객체(unseen)</strong>의 구분을 통해 <strong>정책의 일반화 성능</strong>을 엄밀히 평가할 수 있게 합니다. 이번 벤치마크에서는 대표적인 4가지 조작 과제가 선정되었는데, 구체적인 내용은 다음과 같습니다:</p>
<ul>
<li><strong>수도꼭지 돌리기 (Faucet)</strong>: 로봇 손으로 수도꼭지의 손잡이를 잡고 약 90도 정도 회전시켜 <strong>물을 트는 동작</strong>입니다. 이 작업에서는 로봇 팔의 움직임과 다관절 손가락의 협응이 모두 필요하며, 성공 여부는 수도꼭지 손잡이를 돌린 각도로 평가합니다. (이 과제에는 18개의 수도꼭지 모델 중 11개를 훈련에 사용하고 7개로 일반화 성능을 평가합니다.)</li>
<li><strong>양동이 들기 (Bucket)</strong>: 로봇 손을 양동이의 좁은 손잡이 밑으로 집어넣어 손잡이를 <strong>아래에서 들어올려 드는</strong> 작업입니다. 로봇 손가락을 펼쳐 손잡이를 아래에서 받치고 쥐는 <strong>형상 폐쇄(form closure)</strong>를 구현해야 안정적으로 들 수 있으며, 충분한 마찰 없이는 이 작업이 어렵습니다. 평가 기준은 양동이를 일정 높이 이상 들어올렸는지로 정의됩니다. (이 작업에는 총 19개 양동이 모델 중 11개를 훈련에, 8개를 테스트에 사용합니다.)</li>
<li><strong>노트북 열기 (Laptop)</strong>: 닫힌 노트북의 화면을 중간 부분에서 손가락들로 집어들어 <strong>노트북을 여는</strong> 작업입니다. 로봇 손가락으로 화면 판을 잡고 젖혀 올리는 동작으로, 평행 그리퍼로도 시도할 수는 있으나 매우 정확한 위치로 파지를 해야 하고 큰 작업 공간이 필요해 어렵습니다. 다관절 손을 활용하면 보다 유연하게 화면을 파지하고 젖힐 수 있으며, 열림 각도의 변화를 가지고 성공을 측정합니다. (노트북 과제에는 17개 모델 중 11개 훈련, 6개 테스트로 사용됩니다.)</li>
<li><strong>변기 뚜껑 열기 (Toilet)</strong>: 노트북 열기와 유사하게, 닫힌 양변기 뚜껑을 들어올려 여는 작업입니다. 변기 뚜껑은 모양이 크고 불규칙하여 화면이 평평한 노트북보다 <strong>파지가 까다롭고 무거운</strong> 경우가 많아 작업 난이도가 높습니다. 로봇이 뚜껑을 일정 각도 이상 열면 성공으로 간주하며, 이 작업을 통해 보다 <strong>복잡한 형상의 관절물체 조작</strong>에 대한 성능을 평가합니다. (변기 뚜껑은 28개 모델 중 17개 훈련, 11개가 테스트에 사용됩니다.)</li>
</ul>
<p>각 과제마다 17~28개의 다양한 객체 모델이 포함되어 있으며, 이 중 약 60%는 훈련에 사용되고 40%는 <strong>한 번도 본 적 없는 새로운 객체</strong>로 분리되어 성능 평가에 활용됩니다. 이러한 구성으로, 예를 들어 로봇이 수도꼭지 과제에서 11개의 수도꼭지 모델을 보고 학습한 후 <strong>처음 보는 7가지 새로운 디자인</strong>의 수도꼭지를 얼마나 성공적으로 틀 수 있는지를 시험함으로써, <strong>범주 수준(category-level)의 일반화 능력</strong>을 객관적으로 측정할 수 있습니다.</p>
<p>DexArt의 모든 작업 환경은 <strong>SAPIEN</strong> 물리 시뮬레이터 상에 구현되었고, 로봇 플랫폼으로는 6자유도 산업용 로봇팔 <strong>XArm6</strong> 끝에 인간 손과 비슷한 4손가락 <strong>알레그로 로봇 손(Allegro Hand)</strong>(16자유도 손가락 관절)을 장착한 형태를 사용합니다. 로봇이 받는 <strong>관측(observation)</strong> 정보는 두 부분으로 구성되는데, 첫째는 로봇 자체의 관절 각도, 속도, 팔 끝단(손바닥)의 위치와 자세 등의 <strong>프리오프리셉션(proprioception)</strong>이고, 둘째는 장면을 보는 <strong>깊이 카메라로부터 획득한 부분적인 포인트클라우드</strong>입니다. 이 3차원 점군은 로봇 팔과 물체가 놓인 작업공간 주위로 한정하고 다운샘플링하여 사용하며, 거기에 로봇 자신의 모델에서 생성한 점군도 합쳐 입력으로 제공합니다. 이러한 3D 시각 정보는 <strong>PointNet</strong> 신경망으로 처리되어 중요한 물체의 형태와 부위 특성을 인코딩하고, 이를 기반으로 정책이 의사결정을 하게 됩니다. 한편 <strong>행동(action)</strong> 공간은 로봇 팔의 6-DoF 속도 제어 지령과 손가락 16개 관절의 목표 위치로 이루어진 <strong>22차원 연속 벡터</strong>로 정의됩니다. 구체적으로 팔은 Operational Space Control 방식으로 손바닥의 선속도 및 각속도를 명령하고, 손가락은 각 관절의 <strong>목표 각도(position control)</strong>를 PD 제어로 수행하는 형태입니다. 이러한 정의를 통해 로봇은 자유롭게 팔을 움직여 물체를 쥐고 힘을 줄 수 있으며, 다양한 손 모양을 만들어낼 수 있습니다.</p>
<p>학습을 원활하게 하기 위해 <strong>보상 설계</strong>에도 신경을 썼습니다. DexArt의 모든 과제는 공통적으로 <strong>3단계의 세분화된 보상</strong> 구조를 갖는데, 이를 통해 에이전트가 <strong>접근 → 파지(grasp) → 조작 수행</strong>의 순차 단계를 밟도록 유도합니다. 첫 번째 단계에서는 로봇 손바닥이 해당 물체의 기능적 부위(예를 들어 수도꼭지 손잡이)에 충분히 가까이 접근하면 <strong>거리 기반의 보상</strong>을 줍니다. 둘째 단계에서는 손바닥과 <strong>여러 손가락이 물체와 접촉하여 안정적인 파지</strong>를 형성하면 추가 보상을 지급합니다. 논문에서는 손바닥(palm)과 <strong>최소 두 개 이상의 손가락이 물체와 접촉</strong>한 상태를 만족도 높은 파지로 간주하여 보상하도록 구현했습니다. 마지막 단계에서는 물체의 관절을 목표치까지 실제로 움직여 과제를 <strong>완수한 정도(진행율)</strong>에 따라 보상을 부여합니다. 예를 들어 수도꼭지라면 현재 밸브 손잡이를 얼마나 돌렸는지 각도 변화량을 계산하여, 90도에 가까워질수록 높은 보상을 주는 식입니다. 추가적으로, 불필요하게 과격하거나 불안정한 움직임을 피하도록 <strong>패널티 항</strong>도 포함되었는데, 이는 행동 벡터의 크기에 대한 L2 노름 제재와 과제별로 정의된 약간의 벌점 항으로 구성됩니다. 전체 보상은 이 세 단계 보상과 패널티를 가중합하여 계산되며, 각 작업에 <strong>거의 동일한 구조</strong>를 적용함으로써 학습 난이도와 보상의 일관성을 유지했습니다. 요약하면, DexArt는 다양한 관절형 물체 모델들을 활용한 네 가지 과제 세트와, 다관절 로봇 손을 활용한 표준화된 시뮬레이션 환경, 그리고 일반화 성능을 고려한 평가 프로토콜로 구성되어 있습니다. 객체 모델들은 <strong>PartNet-Mobility</strong> 데이터셋으로부터 선별되었으며, 일관된 물리 모델을 위해 부적절한 모델은 제외하고 크기나 초기 위치 등을 사람이 직접 조정했습니다. 훈련 중에도 에피소드마다 객체의 초기 배치 각도나 위치를 약간씩 랜덤하게 변화시켜, 정책이 보다 <strong>다양한 상황</strong>에 노출되도록 처리했습니다. 이러한 세심한 환경 구축으로, DexArt는 기존에 다루기 어려웠던 범용 <strong>섬세 조작</strong>의 학습을 체계적으로 연구할 수 있는 장을 제공합니다.</p>
</section>
<section id="성능-평가와-실험-설정" class="level2">
<h2 class="anchored" data-anchor-id="성능-평가와-실험-설정">성능 평가와 실험 설정</h2>
<p>DexArt에서는 학습된 정책의 성능을 판단하기 위해 각 에피소드가 <strong>성공적으로 완료</strong>되었는지의 비율인 <strong>성공률(success rate)</strong>을 주된 지표로 사용합니다. 성공 기준은 과제에 따라 앞서 언급한 관절 이동이 일정 임계치 이상 달성되었는지로 정의되며, 예를 들어 수도꼭지의 경우 제한 시간 내에 밸브를 90도 가까이 돌렸다면 성공으로 기록합니다. 특히 중요한 것은 <strong>일반화 평가</strong>로서, <strong>훈련에 사용된 물체들(Seen)</strong>에서의 성공률뿐 아니라 <strong>처음 접하는 새 물체(Unseen)</strong>들에서의 성공률을 별도로 측정한다는 점입니다. 이를 통해 정책이 훈련 때 본 적 없는 모양의 객체에도 얼마나 잘 대응하는지를 객관적으로 확인할 수 있습니다. 그 외 보조 지표로 에피소드당 누적 보상(<strong>return</strong>)의 평균도 보고하며, 학습 <strong>샘플 효율성</strong>을 비교하기 위해 학습이 진행됨에 따라 성공률이 상승하는 곡선의 기울기 등을 함께 분석합니다. 모든 실험은 동일한 PPO(Proximal Policy Optimization) 알고리즘과 파라미터 세팅 하에 과제별로 <strong>3개의 서로 다른 시드</strong>를 사용해 반복 학습하여 결과의 신뢰도를 높였습니다.</p>
<p>본 논문에서는 <strong>여러 가지 학습 설정을 비교 평가</strong>하여 DexArt 과제에서의 성능 변화를 상세히 분석하였습니다. 먼저, <strong>시각 인코더 신경망</strong>(PointNet)에 대해 서로 다른 <strong>사전 학습(pre-training)</strong> 방법들을 적용한 후 강화학습을 진행한 경우들을 비교했습니다. 구체적으로, PointNet을 <strong>지도학습 방식</strong>으로 객체 <strong>분류</strong>(46개 범주의 객체 분류) 또는 <strong>부분 분할(segmentation)</strong> 과제를 수행하도록 미리 학습시키거나, <strong>자기지도학습 방식</strong>으로 <strong>포인트클라우드 복원(reconstruction)</strong>이나 <strong>SimSiam</strong> 방식으로 사전학습시킨 후, 이렇게 얻은 가중치를 초기화값으로 써서 RL을 진행하는 실험들이 수행되었습니다. 그리고 이들과 <strong>아무 사전학습 없이</strong> 처음부터 학습한 경우를 대비하여, <strong>시각 표현 학습의 효과</strong>를 정량적으로 평가했습니다. 다음으로, <strong>훈련에 사용된 객체의 수를 절반으로 줄였을 때와 모두 사용했을 때</strong>를 비교하여, 주어진 <strong>훈련 데이터의 다양성</strong>이 일반화 성능에 미치는 영향을 실험적으로 검증했습니다. 예를 들어 수도꼭지 작업에서 원래 11개의 훈련 객체 중 5~6개만 가지고 학습시킨 정책과 11개 모두 사용한 경우를 비교하는 식입니다. 세 번째로, PointNet <strong>시각 인코더의 모델 크기</strong>를 작게/중간/크게 세 가지로 변경하여, <strong>신경망 용량</strong>에 따른 학습 속도와 성능 차이를 살펴보았습니다. 마지막으로, 학습된 정책의 <strong>카메라 시점 변화에 대한 강인성</strong>을 평가했습니다. 이는 학습 당시 고정된 시점이 아니라, <strong>임의의 새로운 각도</strong>에서 촬영된 깊이 이미지로부터 얻은 포인트클라우드를 입력했을 때도 정책이 잘 동작하는지를 보는 실험입니다. 특히 이 실험에서는 <strong>3D 포인트넷 기반 정책</strong>과, 대비군으로 <strong>2D 이미지 기반 정책</strong>을 함께 시험하였습니다. 2D 정책은 RGB 카메라 영상을 입력으로 하고 ResNet-18 신경망을 시각 백본으로 사용하는데, 사전학습으로 <strong>R3M</strong> (대규모 인간 동작 영상으로 학습된 표현) 모델 가중치를 초기화한 후 DexArt 과제를 학습시킨 것입니다. 두 정책을 모두 다양한 시점의 입력에 놓아보며, <strong>3D 대 2D 시각 표현의 견고성 차이</strong>도 분석했습니다. 이러한 다양한 실험 설정은 DexArt 벤치마크의 포괄성을 잘 보여주며, 각각 정책의 <strong>표현 학습, 훈련 데이터 구성, 모델 설계, 일반화 및 강인성</strong> 측면에 대한 유의미한 정보를 제공합니다.</p>
</section>
<section id="주요-결과와-통찰" class="level2">
<h2 class="anchored" data-anchor-id="주요-결과와-통찰">주요 결과와 통찰</h2>
<p>위와 같은 벤치마크 실험을 통해 여러 흥미로운 결과가 도출되었으며, 특히 다음과 같은 <strong>핵심 통찰</strong>을 얻을 수 있었습니다:</p>
<ul>
<li><p><strong>훈련 데이터 다양성의 중요성:</strong> 한 작업에 대해 <strong>훈련에 사용한 객체 종류가 많을수록</strong> 새로운 객체에 대한 일반화 성능이 유의미하게 향상되었습니다. 각 과제에서 훈련에 투입된 객체 수를 절반으로 줄인 경우와 100% 모두 사용한 경우를 비교하면, 후자가 <strong>훈련 중 내내 테스트 객체에 대한 성공률이 더 높게 유지</strong>되는 양상을 보였습니다. 이는 다양한 형태의 물체들을 두루 경험하며 학습하는 것이 <strong>더 범용적인 시각 표현</strong>을 익히게 함을 의미합니다. 다만 객체 종류가 늘어나면 한꺼번에 학습해야 할 변수가 많아져 <strong>학습 속도는 오히려 느려질 수도 있다</strong>는 관찰도 있었는데, 실제 실험에서 훈련 초기 수렴 속도는 적은 객체로 학습한 쪽이 빠르지만 최종 성능은 다양한 객체를 사용한 쪽이 높았습니다. 결국 충분한 훈련 데이터 다양성이 <strong>정책의 일반화 능력을 높이는 열쇠</strong>임을 확인한 것입니다.</p></li>
<li><p><strong>큰 신경망이 항상 유리한 것은 아님:</strong> 시각 특성을 뽑는 PointNet의 <strong>모델 크기</strong>를 달리한 실험에서 의외의 결과가 나왔습니다. 복잡한 구조의 대형 모델보다 <strong>간결한 소형 모델</strong>이 일관되게 <strong>더 나은 학습 성능</strong>을 보인 것입니다. 가장 작은 PointNet이 모든 환경에서 <strong>에피소드 성공률과 반환값 측면 모두 최고 성과</strong>를 냈고, 학습도 가장 효율적이었습니다. 이는 일반적인 컴퓨터 비전 관점에서 생각하면 다소 놀라운 결과인데, 논문 저자들은 <strong>대규모 신경망은 강화학습에서 최적화가 어려워지는 경향</strong>이 있으며 이전 연구들에서도 유사한 보고가 있었다고 언급합니다. 이번 결과는 <strong>파라미터 수를 줄여 모델을 단순화</strong>하는 것이 오히려 탐색을 용이하게 하고 과적합을 줄여, <strong>샘플 효율을 높이는 효과</strong>가 있을 수 있음을 시사합니다.</p></li>
<li><p><strong>객체 부위 인식의 중요성:</strong> 멀티핑거 로봇 손으로 <strong>물체의 일부분(기능적 부위)을 조작</strong>해야 하는 과제의 특성상, 정책이 그 <strong>물체의 부위를 식별하고 파악</strong>하는 능력이 성능에 큰 영향을 미칩니다. 실험에서 <strong>부위 분할(segmentation)</strong> 과제로 PointNet을 사전학습한 경우, 네 가지 모든 작업에서 <strong>가장 높은 최종 성공률</strong>을 기록했고 학습 초기의 향상 속도도 빨랐습니다. 다른 사전학습 방법들도 노트북 열기 등의 일부 과제에서는 성능 향상에 도움을 주었지만, <strong>작은 손잡이와 같은 섬세한 부위</strong>가 중요한 작업들에서 분할 사전학습의 이점이 특히 두드러졌습니다. 연구진이 시각화한 바에 따르면, 분할 학습을 거친 모델은 수도꼭지의 작은 손잡이 부분을 포인트클라우드 상에서 정확히 구별해내지만, <strong>재구성</strong> 위주로 학습한 모델은 물체의 전체 형태만 파악할 뿐 세밀한 부분은 놓치는 경향이 있었습니다. 결국 <strong>부위 인지 능력</strong>을 기르는 사전학습(예: 기능성 부위에 라벨을 준 3D 분할 데이터로의 학습)이 <strong>관절 객체 조작에 특화된 시각 표현</strong>을 형성하여 정책 학습을 크게 도와준다는 결론을 얻을 수 있습니다.</p></li>
<li><p><strong>3D 표현 학습의 강인성:</strong> 포인트클라우드 기반으로 학습한 정책은 <strong>카메라 시점이 달라져도 성능이 안정적</strong>으로 나타났습니다. 한 각도에서 학습한 정책을 전혀 다른 방향에서 본 입력으로 실행해도 성공률 저하가 미미했고, <strong>상당한 시점 변화에도 정확도가 유지</strong>되었습니다. 반면 동일한 작업을 <strong>2D 카메라 영상</strong>으로 학습한 ResNet-18 기반 정책은, 훈련 때와 다른 뷰포인트의 입력에 대해서 <strong>성공률이 급격히 떨어지는 현상</strong>을 보였습니다. 이는 3차원 포인트클라우드로 학습된 표현이 <strong>시각적 관점 변화에 본질적으로 불변</strong>(invariant)한 성질을 가지고 있는 반면, 평면 영상 기반 표현은 카메라 각도의 변화에 민감함을 보여줍니다. DexArt 결과는 이러한 3D 표현 학습의 이점을 정량적으로 증명해주었고, 특히 시뮬레이터와 현실 로봇 간 <strong>카메라 위치 불일치</strong> 문제 등에서 3D 기반 접근이 얼마나 유용한지 강조하고 있습니다. 실제 로봇에 정책을 이식할 때 카메라 캘리브레이션이나 시점 변화로 인한 성능 저하를 최소화할 수 있다는 점에서, <strong>기하학적 3D 표현의 활용</strong>은 큰 강점으로 작용할 것입니다.</p></li>
</ul>
<p>이 외에도 실험에서 <strong>2D 대 3D 입력의 절대 성능 비교</strong>를 보면, 동일한 강화학습 알고리즘과 비슷한 사전학습을 했을 때 <strong>PointNet(3D)</strong> 기반 정책이 <strong>ResNet-18(2D)</strong> 기반 정책보다 훈련이 잘 되고 최종 성공률도 높았습니다. 이는 관절 조작과 같이 <strong>정확한 형상 파악이 필요한 작업에는 3D 정보가 훨씬 유리함</strong>을 보여주는 결과입니다. 전반적으로 DexArt를 통해 얻은 통찰들은 향후 로봇 학습 연구에서 <strong>데이터 다양성</strong>, <strong>표현 학습 기법</strong>, <strong>모델 구조 선택</strong>, <strong>입력 형태 결정</strong> 등에 중요한 지침을 제시합니다.</p>
</section>
<section id="한계점-및-향후-과제" class="level2">
<h2 class="anchored" data-anchor-id="한계점-및-향후-과제">한계점 및 향후 과제</h2>
<p>DexArt 벤치마크와 연구는 <strong>범용 로봇 섬세 조작</strong>을 향해 나아가는 의미있는 진전을 이루었지만, 동시에 몇 가지 <strong>제약과 향후 과제</strong>를 남겨두고 있습니다. 첫째, 본 연구 결과들은 모두 <strong>시뮬레이터 환경</strong>에서 얻어진 것이므로, 이를 실제 로봇에 적용하기 위해 넘어야 할 <strong>시뮬레이션-현실 간 격차(sim-to-real gap)</strong>가 존재합니다. 현실에서는 센서 잡음, 정확한 물리 파라미터 차이, 마찰 등 여러 불확실성이 추가되며, 시뮬레이터에서처럼 카메라 시점을 이상적으로 맞추기도 어렵습니다. 따라서 학습된 정책을 <strong>실제 로봇에 이식하여 실험</strong>하고, 필요한 도메인 적응이나 보정 기법을 연구하는 것이 다음 단계로 필요합니다. 둘째, DexArt에서 다룬 작업 유형이 아직은 제한적입니다. 주로 <strong>회전 관절</strong>(힌지 형태)의 움직임을 다루는 과제들로 구성되어 있는데, 서랍을 여는 <strong>슬라이딩 관절</strong> 조작이나 가위 사용처럼 <strong>복합적인 다단계 작업</strong> 등은 포함되지 않았습니다. 향후 벤치마크를 확장하면서 이러한 다양한 형태의 <strong>일상 조작 시나리오</strong>를 추가한다면, 로봇의 범용 능력을 더욱 폭넓게 평가하고 향상시킬 수 있을 것입니다. 마지막으로, 본 논문에서는 각 과제마다 <strong>별도의 정책</strong>을 학습시켰지만, 실제로는 한 로봇이 여러 작업을 수행할 수 있어야 합니다. 따라서 <strong>멀티태스크 학습</strong>으로 여러 종류의 조작 기술을 단일 정책에 통합하거나, 혹은 사람의 시범 없이 스스로 학습하도록 하는 <strong>자율학습</strong> 기술 등으로 발전시킬 필요가 있습니다. 이를 통해 <strong>보상 설계의 부담을 줄이고</strong> 더욱 <strong>일반적인 학습 프레임워크</strong>로 나아가는 연구가 이어질 것으로 보입니다. DexArt가 제시한 환경과 평가 체계는 이러한 향후 연구를 촉진하는 <strong>발판</strong>이 될 것이며, 궁극적으로 가정용 로봇이 사람처럼 다양한 물건을 능숙하게 다루는 날을 앞당기는 데 기여할 것으로 기대됩니다.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<script src="https://utteranc.es/client.js" repo="curieuxjy/blog_comments" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Copyright 2024, Jung Yeon Lee</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/curieuxjy">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>