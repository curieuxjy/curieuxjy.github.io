<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.251">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2022-06-26">
<meta name="description" content="Fine-Tuning Locomotion Policies in the Real World">

<title>Curieux.JY - ğŸ“ƒLegged Robots that Keep on Learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../profile.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css">

</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Curieux.JY</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html">Jung Yeon Lee</a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../note.html">âœ’ï¸</a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/curieuxjy"><i class="bi bi-github" role="img">
</i> 
 </a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#abstract" id="toc-abstract" class="nav-link active" data-scroll-target="#abstract">0. Abstract</a></li>
  <li><a href="#i.-introduction" id="toc-i.-introduction" class="nav-link" data-scroll-target="#i.-introduction">I. Introduction</a>
  <ul class="collapse">
  <li><a href="#system-process" id="toc-system-process" class="nav-link" data-scroll-target="#system-process">System Process</a></li>
  <li><a href="#how" id="toc-how" class="nav-link" data-scroll-target="#how">How</a></li>
  <li><a href="#main-contribution" id="toc-main-contribution" class="nav-link" data-scroll-target="#main-contribution">Main Contribution</a></li>
  <li><a href="#details-with-hash-tags" id="toc-details-with-hash-tags" class="nav-link" data-scroll-target="#details-with-hash-tags">Details with Hash tags</a></li>
  </ul></li>
  <li><a href="#ii.-fine-tuning-locomotion-in-the-real-world" id="toc-ii.-fine-tuning-locomotion-in-the-real-world" class="nav-link" data-scroll-target="#ii.-fine-tuning-locomotion-in-the-real-world">II. Fine-tuning Locomotion in the Real World</a>
  <ul class="collapse">
  <li><a href="#a-overview" id="toc-a-overview" class="nav-link" data-scroll-target="#a-overview">a) Overview</a></li>
  <li><a href="#b-motion-imitation" id="toc-b-motion-imitation" class="nav-link" data-scroll-target="#b-motion-imitation">b) Motion Imitation</a></li>
  <li><a href="#c-off-policy-rl" id="toc-c-off-policy-rl" class="nav-link" data-scroll-target="#c-off-policy-rl">c) Off-policy RL</a></li>
  </ul></li>
  <li><a href="#iii.-system-design" id="toc-iii.-system-design" class="nav-link" data-scroll-target="#iii.-system-design">III. System Design</a>
  <ul class="collapse">
  <li><a href="#a.-state-action-spaces" id="toc-a.-state-action-spaces" class="nav-link" data-scroll-target="#a.-state-action-spaces">A. State &amp; Action Spaces</a></li>
  <li><a href="#b.-reward-function" id="toc-b.-reward-function" class="nav-link" data-scroll-target="#b.-reward-function">B. Reward Function</a></li>
  <li><a href="#c.-reset-controller" id="toc-c.-reset-controller" class="nav-link" data-scroll-target="#c.-reset-controller">C. Reset Controller</a></li>
  </ul></li>
  <li><a href="#iv.-experiments" id="toc-iv.-experiments" class="nav-link" data-scroll-target="#iv.-experiments">IV. Experiments</a>
  <ul class="collapse">
  <li><a href="#a.-simulation-experiments" id="toc-a.-simulation-experiments" class="nav-link" data-scroll-target="#a.-simulation-experiments">A. Simulation Experiments</a></li>
  <li><a href="#b.-real-world-experiments" id="toc-b.-real-world-experiments" class="nav-link" data-scroll-target="#b.-real-world-experiments">B. Real-World Experiments</a></li>
  <li><a href="#c.-semi-autonomous-training" id="toc-c.-semi-autonomous-training" class="nav-link" data-scroll-target="#c.-semi-autonomous-training">C. Semi-autonomous training</a></li>
  </ul></li>
  <li><a href="#v.-conclusion" id="toc-v.-conclusion" class="nav-link" data-scroll-target="#v.-conclusion">V. Conclusion</a></li>
  <li><a href="#review" id="toc-review" class="nav-link" data-scroll-target="#review">Review</a></li>
  <li><a href="#reference" id="toc-reference" class="nav-link" data-scroll-target="#reference">Reference</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-page-left" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">ğŸ“ƒLegged Robots that Keep on Learning</h1>
  <div class="quarto-categories">
    <div class="quarto-category">quadruped</div>
    <div class="quarto-category">rl</div>
    <div class="quarto-category">redq</div>
    <div class="quarto-category">paper</div>
  </div>
  </div>

<div>
  <div class="description">
    Fine-Tuning Locomotion Policies in the Real World
  </div>
</div>


<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">June 26, 2022</p>
    </div>
  </div>
    
  </div>
  

</header>

<section id="abstract" class="level1">
<h1>0. Abstract</h1>
<blockquote class="blockquote">
<p>Legged robots are physically capable of traversing a wide range of challenging environments but designing controllers that are sufficiently robust to handle this diversity has been a long-standing challenge in robotics. Reinforcement learning presents an appealing approach for automating the controller design process and has been able to produce remarkably robust controllers when trained in a suitable range of environments. However, it is <code>difficult to predict all likely conditions the robot will encounter</code> during deployment and enumerate them at training-time. What if instead of training controllers that are robust enough to handle any eventuality, <code>we enable the robot to continually learn in any setting it finds itself in?</code> This kind of real-world reinforcement learning poses a number of challenges, including efficiency, safety, and autonomy. To address these challenges, we propose a practical robot reinforcement learning system for <code>fine-tuning locomotion policies in the real world.</code> We demonstrate that a modest amount of real-world training can substantially improve performance during deployment, and this enables <code>a real A1 quadrupedal robot</code> to autonomously fine-tune multiple locomotion skills in a range of environments, including <code>an outdoor lawn and a variety of indoor terrains.</code></p>
</blockquote>
</section>
<section id="i.-introduction" class="level1">
<h1>I. Introduction</h1>
<p><em>ê°•í™”í•™ìŠµì´ ë¡œë´‡ ì œì–´ ë¶„ì•¼ì—ì„œ ê°ê´‘ ë°›ëŠ” ì´ìœ ê°€ ë¬´ì—‡ì¼ê¹Œ?</em> ê¸°ì¡´ì˜ ë¡œë´‡ ì œì–´ ì•Œê³ ë¦¬ì¦˜ë“¤ì€ ì •ë§ ë§ì€ engineering ì ì¸ ê³ ë ¤ì™€ ë³µì¡í•œ ìˆ˜í•™ì  ëª¨ë¸ë§ì´ í•„ìš”í•˜ë‹¤. ê·¸ëŸ°ë° ê·¸ë§ˆì € ì—”ì§€ë‹ˆì–´ê°€ ë¯¸ì²˜ ê³ ë ¤í•˜ì§€ ëª»í•œ ì‘ë™ì„ í•´ì•¼ í•  ë•ŒëŠ” ë°”ë¡œ ì‹¤íŒ¨í•œ controller ë””ìì¸ì´ ë˜ì–´ ë²„ë¦¬ê¸° ë•Œë¬¸ì— ë¡œë´‡ ì œì–´ëŠ” ì‰½ì§€ ì•Šì€ ë¬¸ì œì˜€ë‹¤. ì´ëŸ° ë©´ì—ì„œ ê°•í™”í•™ìŠµì€ controllerë¥¼ <code>trial-and-error</code>ë¡œ ë¡œë´‡ agentê°€ ì•Œì•„ì„œ ì–´ë–»ê²Œ ì‘ë™í•´ì•¼ í• ì§€ í•™ìŠµí•˜ê¸° ë•Œë¬¸ì— ê³µí•™ìì—ê²Œ controller ë””ìì¸ì— ëŒ€í•œ ë¶€ë‹´ì„ ì¤„ì—¬ì£¼ì—ˆê³  ì´ëŸ° ì ì— ê°•í™”í•™ìŠµì´ ë¡œë´‡ ì œì–´ ë¶„ì•¼ì—ì„œ ì£¼ëª© ë°›ëŠ” ì´ìœ ì˜€ë‹¤.</p>
<p>í•˜ì§€ë§Œ, ì•ˆíƒ€ê¹ê²Œë„ ê°•í™”í•™ìŠµì´ controllerë¥¼ ë§Œë“œëŠ” ê²ƒì˜ ë¶€ë‹´ì„ ì¤„ì—¬ì£¼ì—ˆì§€ë§Œ ê°•í™”í•™ìŠµì˜ environment ì„¤ê³„ì— ëŒ€í•œ ë¶€ë‹´ì´ì—ˆë‹¤. ìœ„ì—ì„œ ì„¤ëª…í•œ ëŒ€ë¡œ ê°•í™”í•™ìŠµì—ì„œ trial-and-errorë¡œ <code>ì•Œì•„ì„œ</code> í•™ìŠµí•œë‹¤ëŠ” ì ì´ ë§¤ë ¥ì ì´ì§€ë§Œ, ì´ëŸ° í•™ìŠµì˜ ì¡°ê±´ì—ëŠ” ì¢‹ì€ environmentê°€ í•„ìš”í•˜ë‹¤. ê°•í™”í•™ìŠµ ë¶„ì•¼ì—ì„œ ìì£¼ ì–¸ê¸‰ë˜ëŠ” <code>ì¢‹ì€ agentì˜ ë°°ê²½ì—ëŠ” ì¢‹ì€ environmentê°€ ìˆë‹¤.</code>ëŠ” ë§ì²˜ëŸ¼ agentê°€ environmentì—ì„œ ê²½í—˜í•˜ë©´ì„œ ì¢‹ì€ í•™ìŠµì„ í•˜ì§€ ëª»í•˜ë©´ ì¢‹ì€ ê²°ê³¼ë¥¼ ê¸°ëŒ€í•  ìˆ˜ ì—†ë‹¤. ë”°ë¼ì„œ ë§ˆì¹˜ controller ë””ìì¸ê³¼ environment ë””ìì¸ì€ trade-off ê´€ê³„ë¡œ ì—”ì§€ë‹ˆì–´ì—ê²Œ ê³¼ì œë¥¼ ë‚¨ê¸°ê²Œ ëœë‹¤.</p>
<p>agentê°€ í•™ìŠµí•˜ëŠ” ë™ì•ˆì— ê²½í—˜í•˜ê²Œ ë˜ëŠ” environmentì™€ í…ŒìŠ¤íŠ¸ ì‹œ(ì‹¤ì‚¬ìš© ì‹œ) ê²½í—˜í•˜ê²Œ ë˜ëŠ” environmentì˜ ì°¨ì´ê°€ í¬ë©´ í´ìˆ˜ë¡ agentëŠ” ì œëŒ€ë¡œ ì‘ë™í•  ìˆ˜ ì—†ë‹¤. í•™ìŠµë˜ì§€ ì•Šì€ ê²½í—˜ë“¤ì´ê¸° ë•Œë¬¸ì— í•™ìŠµëœ agentì˜ policyê°€ ì¢‹ì€ actionì„ í•  ìˆ˜ ì—†ë‹¤. ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ì„œ ê²½í—˜í•´ë³´ì§€ ëª»í•œ, ì¦‰ í•™ìŠµí•˜ì§€ ëª»í•œ ê²½ìš°ì— ëŒ€í•´ì„œë„ ì œëŒ€ë¡œ agentê°€ ë™ì‘í•˜ê¸° ìœ„í•´ <code>zero-shot generalization</code>(í•œë²ˆë„ ë³´ì§€ ëª»í•œ-zero shot ê²½í—˜ ë°ì´í„°ì— ëŒ€í•´ ì˜ ì¼ë°˜í™”-generalization í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥) ì´ í•„ìš”í•˜ì§€ë§Œ, ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì™„ë²½í•œ <code>zero-shot generalization</code>ì€ ì¼ì–´ë‚  ìˆ˜ ì—†ë‹¤ëŠ” ê°€ì •í•˜ì— ë¬¸ì œë¥¼ ì–´ë–»ê²Œ í’€ê²ƒì¸ê°€ ê³ ë¯¼í–ˆë‹¤.</p>
<p>ê·¸ë ‡ê²Œ í•´ì„œ ì œì•ˆëœ ë°©ë²•ì€ <code>í…ŒìŠ¤íŠ¸ í™˜ê²½ì—ì„œ ë¹ ë¥´ê²Œ fine-tuning í•´ì„œ agentê°€ ì˜ ë™ì‘í•˜ê²Œ ë§Œë“¤ì</code>ì˜€ê³ , ì´ ë°©ë²•ì´ ê°€ëŠ¥í•˜ë‹¤ë©´ ë¡œë´‡ì€ ì‹¤ì œë¡œ ë™ì‘í•˜ë©´ì„œ ì–¸ì œë“ ì§€ ë§ˆì£¼ì¹  ìˆ˜ ìˆëŠ” ìƒˆë¡œìš´ í™˜ê²½ì— ì ì‘í•´ì„œ(fine-tuned) ì˜ ë™ì‘í•  ìˆ˜ ìˆì„ ê²ƒì´ë‹¤.</p>
<blockquote class="blockquote">
<p>ğŸ¯ ë³¸ ë…¼ë¬¸ì˜ ëª©í‘œëŠ” ì‹¤ì œ í™˜ê²½(real-world)ì—ì„œ ë¡œë´‡ì˜ locomotion policyë“¤ì´ fine-tuningí•  ìˆ˜ ìˆëŠ” ì™„ì „í•œ ì‹œìŠ¤í…œì„ ë””ìì¸ í•˜ëŠ” ê²ƒì´ë‹¤.</p>
</blockquote>
<section id="system-process" class="level2">
<h2 class="anchored" data-anchor-id="system-process">System Process</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://i.imgur.com/vJJH1oF.png?1" class="img-fluid figure-img"></p>
</figure>
</div>
<ol type="1">
<li>ìœ„ì˜ ì‚¬ì§„ì— ë³´ì´ëŠ” ê³µì›ê³¼ ê°™ì€ <code>ìƒˆë¡œìš´ í™˜ê²½</code>ì—ì„œ ë¨¼ì € ë¡œë´‡ agentê°€ ì²«ë²ˆì§¸ ì‹œë„ë¡œ locomotion taskë¥¼ ì§„í–‰í•œë‹¤.</li>
<li>ë§Œì•½ì— ë•…ì´ ê³ ë¥´ì§€ ëª»í•´ì„œ agentì˜ í•™ìŠµëœ policyë¥¼ í™œìš©í•  ìˆ˜ ì—†ëŠ” ìƒí™©ì´ ë˜ì–´ì„œ ë„˜ì–´ì§€ê²Œ ë˜ëŠ” ìƒí™©ì´ ë  ìˆ˜ ë„ ìˆë‹¤.</li>
<li>ì´ë•Œ <code>reset controller</code>ë¥¼ ì´ìš©í•´ì„œ ë¹ ë¥´ê²Œ ë‹¤ì‹œ ì¼ì–´ë‚œë‹¤.</li>
<li>ì‹¤ì œ taskì—ì„œ ì¢€ ë” ëª‡ ë²ˆ ì‹œë„ë¥¼ í•˜ë©´ì„œ 1~3ì˜ ê³¼ì •ì„ ëª‡ ë²ˆ ë°˜ë³µí•˜ê²Œ ë˜ê³  ì´ ê³¼ì •ì—ì„œ <code>policyê°€ ì—…ë°ì´íŠ¸</code> ë˜ê²Œ ëœë‹¤.</li>
<li>ì—…ë°ì´íŠ¸ê°€ ë˜ë©´ì„œ policyëŠ” <code>ìƒˆë¡œìš´ test í™˜ê²½ì—ì„œ ì œëŒ€ë¡œ ì‘ë™</code>í•  ìˆ˜ ìˆê²Œ ëœë‹¤.</li>
</ol>
</section>
<section id="how" class="level2">
<h2 class="anchored" data-anchor-id="how">How</h2>
<ul>
<li>ê°•í™”í•™ìŠµì˜ reward ê°€ robotì˜ <code>on-board ì„¼ì„œë¡œ ì¸¡ì •ë˜ëŠ” ê°’ë“¤ë¡œë§Œ</code> ë””ìì¸ ë˜ì–´ì•¼ ì‹¤ì œ Real-worldì—ì„œ ì‘ë™í•˜ë©´ì„œ fine tuningì„ í•  ìˆ˜ ìˆë‹¤.</li>
<li>Agileí•œ behaviorë¥¼ í•™ìŠµí•˜ê¸° ìœ„í•´ì„œ <code>Motion imitation</code> ê¸°ë²•ì„ í™œìš©í–ˆë‹¤.</li>
<li>ë¡œë´‡ì˜ ë„˜ì–´ì§€ê³  ë‚˜ì„œ ë¹ ë¥´ê²Œ ì •ìƒìì„¸ë¡œ íšŒë³µí•  ìˆ˜ ìˆë„ë¡ <code>Recovery policy</code>ë¥¼ í•™ìŠµí–ˆë‹¤.</li>
<li>ê°•í™”í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ë“¤ ì¤‘ì—ì„œ <a href="https://arxiv.org/abs/2101.05982"><code>REDQ(Randomized Ensembled Double Q-Learning)</code></a> ë¼ëŠ” ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í–ˆëŠ”ë°, ì´ ì•Œê³ ë¦¬ì¦˜ì€ ì—¬ëŸ¬ê°œ Q-networkë“¤ì˜ ì•™ìƒë¸”ì„ í†µí•´ randomizationì„ í•´ì„œ Q-learning ê³„ì—´ì˜ ì•Œê³ ë¦¬ì¦˜ë“¤ì˜ sample-efficiencyì™€ ì•ˆì •ì„±ì„ í–¥ìƒì‹œí‚¨ ì•Œê³ ë¦¬ì¦˜ì´ë‹¤.</li>
</ul>
</section>
<section id="main-contribution" class="level2">
<h2 class="anchored" data-anchor-id="main-contribution">Main Contribution</h2>
<blockquote class="blockquote">
<p>ë³¸ ë…¼ë¬¸ì˜ ì£¼ìš” contributionì€ ë‹¤ìŒê³¼ ê°™ë‹¤.</p>
</blockquote>
<ul>
<li>4ì¡± ë³´í–‰ ë¡œë´‡ì˜ agileí•œ locomotion skillì„ real-worldì—ì„œ í•™ìŠµí•˜ê¸° ìœ„í•œ <code>fine-tuning ìë™í™” ì‹œìŠ¤í…œ</code>ì„ ì œì•ˆí•˜ì˜€ë‹¤.</li>
<li>ì²˜ìŒìœ¼ë¡œ <code>ìë™í™” reset</code>ê³¼ <code>on-board ìƒíƒœ ì¶”ì •</code>ì„ í†µí•´ real-worldì—ì„œ fine-tuningì´ ë  ìˆ˜ ìˆìŒìœ¼ë¡œ ë³´ì˜€ë‹¤.</li>
<li><code>A1</code> ë¡œë´‡ì„ ê°€ì§€ê³  dynamic skillë“¤ì„ í•™ìŠµí•´ì„œ ì™¸ë¶€ ì”ë””ì—ì„œ ì•ìœ¼ë¡œ, ë’¤ë¡œ pacingì„ í•˜ê³  3ê°€ì§€ ë‹¤ë¥¸ ì§€í˜• íŠ¹ì§•ì„ ê°€ì§„ í™˜ê²½ì—ì„œ side-steppingì„ í•  ìˆ˜ ìˆì—ˆë‹¤.</li>
</ul>
</section>
<section id="details-with-hash-tags" class="level2">
<h2 class="anchored" data-anchor-id="details-with-hash-tags">Details with Hash tags</h2>
<blockquote class="blockquote">
<p>ì› ë…¼ë¬¸ì˜ <code>II. Related Work</code> section ì°¸ê³ </p>
</blockquote>
<p><code>#Cumbersome controller designs</code></p>
<ul>
<li>ì´ì „ì˜ ë¡œë´‡ controllerë“¤ì€ footstep planning, trajectory optimization, model-predictive control (MPC) ë“±ì˜ ì¡°í•©ìœ¼ë¡œ ë§Œë“¤ì–´ì§€ê³  ìˆì—ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ëŸ° ë°©ë²•ë“¤ì€ ë¡œë´‡ì˜ ë™ì—­í•™ê³¼ ê° ë¡œë´‡ë§ˆë‹¤ ë‹¤ë¥´ê³  ê° skillë§ˆë‹¤ ë‹¤ë¥¸ ë§ì€ ìš”ì†Œë“¤ì„ ê³ ë ¤í•´ì•¼ í•˜ê¸° ë•Œë¬¸ì— ì •ë§ ì–´ë ¤ì› ë‹¤.</li>
</ul>
<p><code>#Sim2Real</code></p>
<ul>
<li><code>trial-and-error</code>ë¼ëŠ” ë°ì´í„°ì— ë§¤ìš° ì˜ì¡´ì„±ì´ ë†’ì€ ê°•í™”í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì˜ íŠ¹ì„±ê³¼ í•˜ë“œì›¨ì–´ì˜ safety ì´ìŠˆ ë•Œë¬¸ì— ë³´í†µ ë¡œë´‡ ê°•í™”í•™ìŠµ agentëŠ” <code>ì‹œë®¬ë ˆì´ì…˜ ê¸°ë°˜</code>ìœ¼ë¡œ í•™ìŠµëœë‹¤. í•˜ì§€ë§Œ ì‹œë®¬ë ˆì´ì…˜ì—ì„œ í•™ìŠµí•˜ë©´ì„œ ì‹¤ì œë¡œ ë§Œë‚˜ë³´ì§€ ì•Šì€ real-worldì˜ ëª¨ë“  ì¡°ê±´ë“¤ì„ ì˜ˆìƒí•˜ê³  í•™ìŠµí•˜ê¸°ë€ ì‚¬ì‹¤ìƒ ë¶ˆê°€ëŠ¥í•˜ë©° ê°€ì¥ robustí•œ policyë¼ê³  í• ì§€ë¼ë„ ëª¨ë“  ìƒí™©ì— ëŒ€í•´ generalization ë˜ì—ˆë‹¤ê³  í•  ìˆ˜ ì—†ë‹¤.</li>
</ul>
<p><code>#Real-world</code></p>
<ul>
<li><p>ì´ì „ì— ë³µì¡í•œ motionë“¤ì„ í•™ìŠµí•˜ê²Œ í•˜ê¸° ìœ„í•´ì„œ environmentì˜ ë‹¤ì–‘í•œ ì¥ì¹˜ë“¤ë¡œ ë‹¤ì–‘í•œ ìƒíƒœ ì •ë³´ë¥¼ ë§Œë“¤ì–´ì„œ ì‚¬ìš©í–ˆì§€ë§Œ ë³¸ ì—°êµ¬ì—ì„œëŠ” real-worldì—ì„œ ì‘ë™í•˜ê³  ìˆëŠ” ë¡œë´‡ì—ì„œ fine-tuningì„ í•´ì•¼ í•˜ê¸° ë•Œë¬¸ì— <code>ë¡œë´‡ì˜ on-boardì—ì„œ ë°›ì„ ìˆ˜ ìˆëŠ” ëª¨ë“  state estimation ì •ë³´ë“¤ì„ ê°€ì§€ê³ ë§Œ</code> ì§„í–‰í–ˆìœ¼ë©° motion captureë‚˜ ì™¸ë¶€ ì¥ì¹˜ë“¤ì„ ë³„ë„ë¡œ ì‚¬ìš©í•˜ì§€ ì•Šì•˜ë‹¤.</p></li>
<li><p>scratchë¶€í„° ì‹¤ì œ í™˜ê²½ì—ì„œ ë‹¨ìˆœí•œ êµ¬ì¡°ì˜ ë¡œë´‡ë“¤ë¡œ walking gaitsë“¤ì„ í•™ìŠµí•˜ëŠ”ê²Œ ì•„ë‹ˆë¼, <code>A1</code> ë¡œë´‡ìœ¼ë¡œ <code>pacing, side stepping</code> ë“± ë§¤ìš° ìì—°ìŠ¤ëŸ½ê³  ì¡°ê¸ˆì€ ë¶ˆì•ˆì •í•˜ê³  ì„¸ë°€í•œ balancingì´ ìš”êµ¬ë˜ëŠ” skillë“¤ì„ í•™ìŠµí•  ìˆ˜ ìˆì—ˆë‹¤. (ê¸°ì¡´ì˜ ì—°êµ¬ë“¤ì€ balancingì— ë§¤ìš° ì‹ ê²½ì“´ ë‚˜ë¨¸ì§€ ëŠë¦¬ê³  ë¶€ìì—°ìŠ¤ëŸ¬ìš´ walking gaits ì— ì¹˜ì¤‘í•œ ë©´ì´ ìˆì—ˆë‹¤.) ë³¸ ë…¼ë¬¸ì˜ ì—°êµ¬ì—ì„œ <code>motion imitationê³¼ ì‹¤ì œ í™˜ê²½ì—ì„œì˜ fine-tuning</code> ì´ ì´ëŸ° ë‹¤ì´ë‚˜ë¯¹í•œ taskë“¤ì„ ì„±ê³µì‹œí‚¤ëŠ”ë° ë§¤ìš° ì¤‘ìš”í•œ ì—­í• ì„ í–ˆë‹¤. ë˜í•œ ì‹¤ì œ í™˜ê²½ì—ì„œ ë¡œë´‡ì´ ì‘ë™í•˜ë©´ì„œ ë„˜ì–´ì§ˆ ë•Œ, manualí•˜ê²Œ ë¡œë´‡ì˜ resetí•˜ê±°ë‚˜ recoveryì‹œí‚¤ì§€ ì•Šê³  <code>ê°•í™”í•™ìŠµìœ¼ë¡œ ìë™ì ìœ¼ë¡œ reset</code> í•  ìˆ˜ ìˆëŠ” controllerë¥¼ ë§Œë“¤ì–´ì„œ ì‚¬ìš©í–ˆë‹¤.</p></li>
</ul>
<p><code>#Few-shot adaptation</code></p>
<ul>
<li>ê¸°ì¡´ì˜ <code>Adaptation structure</code>ë¼ëŠ” êµ¬ì¡°ë¥¼ ë§Œë“¤ì–´ì„œ í•™ìŠµì‹œì¼œì„œ latent ë˜ëŠ” explicití•œ í™˜ê²½ì— ëŒ€í•œ descriptorë¡œ adaptiveí•œ policyë¥¼ ë§Œë“œëŠ” ì—°êµ¬ë“¤ì´ ìˆì—ˆìœ¼ë‚˜, ì´ ê¸°ë²•ë“¤ ë˜í•œ ê²°êµ­ trainingì—ì„œ ê²½í—˜í–ˆë˜ ê²ƒë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ adaptiveí•¨ì„ ë³´ì´ëŠ” ê²ƒì´ë¯€ë¡œ ì‹¤ì œ test í™˜ê²½ì´ ì´ í—ˆìš© ë²”ìœ„ì—ì„œ ë§ì´ ë²—ì–´ë‚  ê²½ìš° ì œëŒ€ë¡œ ì‘ë™ì•ˆë˜ëŠ” ê²ƒì€ ë˜‘ê°™ë‹¤. ë”°ë¼ì„œ ê°•í™”í•™ìŠµìœ¼ë¡œ ì§€ì†ì ì¸ ì ì‘ì ì¸ í•™ìŠµëŠ¥ë ¥ì„ ë³´ì¥í•´ì„œ <code>ì–´ë–¤ test í™˜ê²½ì—ì„œë“  ì˜ ì‘ë™í•  ìˆ˜ ìˆë„ë¡</code> í–ˆë‹¤.</li>
</ul>
<p><code>#RL Algorithm</code></p>
<ul>
<li>ê°•í™”í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œëŠ” ê¸°ì¡´ì˜ vision ê¸°ë°˜ ë§¤ë‹ˆí“°ë ˆì´í„°ë“¤ì—ì„œ grasping ì‘ì—…ì„ í•˜ëŠ” taskë“¤ì—ì„œ ë§ì´ ì“°ì¸ <code>off-policy model-free</code> RL ê¸°ë²•ë“¤ì„ ì°¸ê³ í•˜ì—¬ fixedë˜ì–´ ìˆëŠ” ë§¤ë‹ˆí“°ë ˆì´í„°ë“¤ë³´ë‹¤ ë” challengingí•œ <code>floating-based ë³´í–‰ ë¡œë´‡ì˜ locomotion</code>ì— ì ìš©í•´ì„œ ì„±ê³µì‹œì¼°ë‹¤.</li>
</ul>
</section>
</section>
<section id="ii.-fine-tuning-locomotion-in-the-real-world" class="level1">
<h1>II. Fine-tuning Locomotion in the Real World</h1>
<p>ê°•í™”í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ <code>multi-tasking</code>ì„ í•  ìˆ˜ ìˆë„ë¡ í•™ìŠµì‹œì¼°ë‹¤.</p>
<ul>
<li><code>REDQ</code> ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ì´ìš©í•´ì„œ sample efficiencyë¥¼ ë†’ì¼ ìˆ˜ ìˆì—ˆë‹¤.</li>
<li>í•™ìŠµëœ <code>reset policy</code>ë¥¼ ì´ìš©í•´ì„œ ì—¬ëŸ¬ê°œì˜ episodeë“¤ì„ ì´ì–´ì„œ(stitch together) í•™ìŠµì‹œì¼°ë‹¤.</li>
</ul>
<section id="a-overview" class="level2">
<h2 class="anchored" data-anchor-id="a-overview">a) Overview</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://i.imgur.com/2q4OYul.png?1" class="img-fluid figure-img"></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://i.imgur.com/kIL9RPT.png?1" class="img-fluid figure-img"></p>
</figure>
</div>
<ul>
<li>ìœ„ ì‚¬ì§„ì˜ ì „ì²´ ì‹œìŠ¤í…œì˜ ê°œëµë„ì—ì„œ ë³¼ ìˆ˜ ìˆë“¯ì´ <strong>ê°ê°ì˜ policy</strong>ëŠ” <strong>í•˜ë‚˜ì˜ desired skill</strong>ì„ í•™ìŠµí•˜ê²Œ ëœë‹¤. (forward, backward, reset)</li>
<li>Agentì˜ policyëŠ” <strong>ì‹œë®¬ë ˆì´ì…˜ì—ì„œ pretrained</strong> í•œë‹¤. (Algorithm2: line 2~7)
<ul>
<li>ê° ì—í”¼ì†Œë“œê°€ ëë‚  ë•Œë§ˆë‹¤ <strong>í•™ìŠµëœ recovery policy</strong>ê°€ ë¡œë´‡ì„ ë‹¤ìŒ rolloutì„ í•  ìˆ˜ ìˆë„ë¡ ì¤€ë¹„ì‹œì¼œì¤€ë‹¤.</li>
<li>ê° skillì„ ìœ„í•œ policyë“¤ì€ <strong>ë…ë¦½ì ìœ¼ë¡œ í•™ìŠµ</strong>ë˜ê³  recovery policyë„ ë§ˆì°¬ê°€ì§€ë¡œ ë…ë¦½ì ìœ¼ë¡œ í•™ìŠµëœë‹¤.</li>
</ul></li>
<li><strong>Fine-tuningì„ ì‹¤ì œ ë¬¼ë¦¬ì ì¸ í™˜ê²½ì—ì„œ</strong> ì§„í–‰í•˜ë©´ì„œ training processë¥¼ ê³„ì† ì´ì–´ë‚˜ê°ˆ ìˆ˜ ìˆë‹¤. (Algorithm2: line 8~14)
<ul>
<li>ì‹œë®¬ë ˆì´ì…˜ê³¼ ì‹¤ì œ í™˜ê²½ì˜ ì°¨ì´ë¥¼ ê³ ë ¤í•˜ì—¬ <strong>ê° policyë“¤ì˜ replay bufferëŠ” ì´ˆê¸°í™”</strong> ì‹œì¼œì¤€ë‹¤.(Algorithm2: line 12)</li>
</ul></li>
<li><strong>Multitask framework</strong>ë¥¼ ì‚¬ìš©í–ˆë‹¤.(Algorithm2 ì°¸ê³ )</li>
</ul>
</section>
<section id="b-motion-imitation" class="level2">
<h2 class="anchored" data-anchor-id="b-motion-imitation">b) Motion Imitation</h2>
<ul>
<li><code>Motion Imiation</code> ë°©ë²•ì„ ì´ìš©í•˜ì—¬ reference motion clipë“¤ì˜ skillë“¤ì„ ëª¨ë°© í•™ìŠµí•˜ë„ë¡ í–ˆëŠ”ë° ì´ëŠ” <a href="https://arxiv.org/abs/2004.00784"><code>Learning Agile Robotic Locomotion Skills by Imitating Animals</code></a>ë¼ëŠ” ë…¼ë¬¸ì—ì„œ ì œì‹œí•œ ë°©ë²•ì„ ë”°ë¼í–ˆë‹¤. (Algorithm 1: line1~4)</li>
<li><strong>Reference motion <span class="math inline">M</span></strong>ì´ ì£¼ì–´ì§€ë©´ agentì˜ì¼ë ¨ì˜ poseë“¤ê³¼ ë¹„êµí•˜ì—¬ section <code>III-B</code>ì—ì„œ ì†Œê°œë  reward functionì„ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµí•œë‹¤.
<ul>
<li>ì´ ë°©ë²•ì„ í†µí•´ <strong>reference motion data</strong>ë§Œ ë°”ê¿”ì£¼ë©´ ë°”ë¡œ ë‹¤ë¥¸ ì—¬ëŸ¬ skillë“¤ì„ ë°°ìš¸ ìˆ˜ ìˆë‹¤.</li>
<li><strong>recovery policy</strong>ë¥¼ í•™ìŠµí•˜ê¸° ìœ„í•´ì„œ <strong>standing pose</strong>ë¥¼ ëª¨ë°©í•˜ë„ë¡ í•  ìˆ˜ ìˆë‹¤.(<code>III-C</code> ì°¸ê³ )</li>
</ul></li>
</ul>
</section>
<section id="c-off-policy-rl" class="level2">
<h2 class="anchored" data-anchor-id="c-off-policy-rl">c) Off-policy RL</h2>
<ul>
<li>off-policy ì•Œê³ ë¦¬ì¦˜ì¸ <strong>REDQ algorithm</strong> ì‚¬ìš©í–ˆë‹¤.(Algorithm 1: line5~9)
<ul>
<li>SAC ì•Œê³ ë¦¬ì¦˜ì„ ë” ë°œì „ì‹œí‚¨ ì•Œê³ ë¦¬ì¦˜</li>
<li>time stepì— ëŒ€í•œ gradient stepë¹„ìœ¨ì„ ì¦ê°€ì‹œì¼œì„œ ê°•í™”í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì˜sample efficiencyë¥¼ ë†’ì˜€ë‹¤.</li>
<li>ë„ˆë¬´ ë§ì€ gradient stepì„ í•  ê²½ìš°ì— ì¼ì–´ë‚  ìˆ˜ ìˆëŠ” overestimation issueë¥¼ ì•™ìƒë¸” ê¸°ë²•ì„ ì´ìš©í•´ì„œ ì™„í™”í•  ìˆ˜ ìˆì—ˆë‹¤.</li>
</ul></li>
</ul>
<p>(ìì„¸í•œ ëª¨ë°©í•™ìŠµê³¼ ê°•í™”í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì˜ training ê³¼ì • ì•Œê³ ë¦¬ì¦˜ì€ <code>Algorithm 1</code>ì„ ì°¸ê³ ) <img src="https://i.imgur.com/sBvIszd.png?1" class="img-fluid" data-fig-align="default"></p>
</section>
</section>
<section id="iii.-system-design" class="level1">
<h1>III. System Design</h1>
<blockquote class="blockquote">
<p>Setting - A1 robot from Unitree - PyBullet simulator - <strong>motion imitation skills</strong>ì„ ì–»ê¸° ìœ„í•´ì„œ - ê³µê°œëœ ë°ì´í„° ì…‹ë“¤ ì¤‘ì— <strong>dog pacing</strong>ì˜ mocapì„ ë…¹í™”í•˜ê³  retargetting í•˜ì˜€ë‹¤. - ë¡œë´‡ì˜ ì—­ê¸°êµ¬í•™ì„ ì´ìš©í•´ì„œ A1 ë¡œë´‡ì˜ <strong>side-step motion</strong>ì„ ì• ë‹ˆë©”ì´ì…˜ìœ¼ë¡œ ë§Œë“¤ì–´ì„œ ì‚¬ìš©í–ˆë‹¤. - REDQ ì•Œê³ ë¦¬ì¦˜ - Adam optimizer - learning rate of 10âˆ’4 - batch size of 256 transitions - TensorFlow</p>
</blockquote>
<section id="a.-state-action-spaces" class="level2">
<h2 class="anchored" data-anchor-id="a.-state-action-spaces">A. State &amp; Action Spaces</h2>
<ol type="1">
<li><p>State space</p>
<ul>
<li>StateëŠ” ì—°ì†ì ì¸ <strong>3 timesteps</strong>ì—ì„œ ì–»ì€ ì•„ë˜ ì •ë³´ë“¤ë¡œ ì •ì˜í–ˆë‹¤.
<ul>
<li>Root orientation (read from the IMU)</li>
<li>Joint angles</li>
<li>Previous actions</li>
</ul></li>
<li><strong>Policy</strong>ëŠ” ìœ„ì—ì„œ ë§í•œ <strong>Proprioceptive input</strong> ë¿ë§Œ ì•„ë‹ˆë¼ <strong>a goal <span class="math inline">g_t</span></strong>ì— ëŒ€í•œ ì •ë³´ë„ inputìœ¼ë¡œ ë°›ê²Œ ëœë‹¤.
<ul>
<li><span class="math inline">g_t</span>ëŠ” future timestepsì—ì„œì˜ reference motionì—ì„œ ê³„ì‚°ëœ <strong>Target pose (root position, root rotation, joint angles)</strong>ì˜ ì •ë³´ë¥¼ í¬í•¨í•œë‹¤.</li>
<li><strong>4 future target poses</strong> ëŠ” í˜„ì¬ timestepì—ì„œ ì•½ 1ì´ˆ ì •ë„ ì´í›„ì˜ poseë“¤ì´ë‹¤.</li>
</ul></li>
</ul></li>
<li><p>Action space</p>
<ul>
<li>Actionì€ <strong>12 joints</strong>ë“¤ì— ëŒ€í•œ <strong>PD position targets</strong> ì´ë‹¤.</li>
<li><strong>33Hz</strong>ì˜ ì£¼íŒŒìˆ˜ë¡œ commandê°€ ì ìš©ëœë‹¤.</li>
<li>ìì—°ìŠ¤ëŸ¬ìš´ ì›€ì§ì„ì„ ìœ„í•´ PD targetsì„ <strong>low-pass filter</strong>ë¥¼ ë¡œë´‡ì— ì ìš©í•˜ê¸° ì „ì— í†µê³¼ì‹œì¼œì¤€ë‹¤.</li>
</ul></li>
</ol>
</section>
<section id="b.-reward-function" class="level2">
<h2 class="anchored" data-anchor-id="b.-reward-function">B. Reward Function</h2>
<p><span class="math display">
\begin{gathered}r_{t}=w^{\mathrm{p}} r_{t}^{\mathrm{p}}+w^{\mathrm{v}} r_{t}^{\mathrm{v}}+w^{\mathrm{e}} r_{t}^{\mathrm{e}}+w^{\mathrm{rp}} r_{t}^{\mathrm{rp}}+w^{\mathrm{rv}} r_{t}^{\mathrm{rv}} \\w^{\mathrm{p}}=0.5, w^{\mathrm{v}}=0.05, w^{\mathrm{e}}=0.2, w^{\mathrm{rp}}=0.15, w^{\mathrm{rv}}=0.1\end{gathered}
</span></p>
<hr>
<ul>
<li><p><span class="math inline">r_{t}^{\mathrm{p}}</span> : ë¡œë´‡ì˜ <strong>joint rotation</strong> ê°’ë“¤ì„ reference motionì˜ joint rotationê³¼ ë§ì¶”ë„ë¡ í•˜ëŠ” reward term</p>
<p><span class="math display">
  r_{t}^{\mathrm{p}}=\exp \left[-5 \sum_{j}\left\|\hat{q}_{t}^{j}-q_{t}^{j}\right\|^{2}\right]
  </span></p>
<ul>
<li><span class="math inline">\hat{q}_{t}^{j}</span> : ì‹œì  <span class="math inline">t</span>ì— reference motionì˜ <span class="math inline">j</span>ë²ˆì§¸ jointì˜ <strong>local rotation</strong></li>
<li><span class="math inline">q_{t}^{j}</span> : ë¡œë´‡ì˜ <span class="math inline">j</span>ë²ˆì§¸ joint <strong>local rotation</strong></li>
</ul></li>
<li><p><span class="math inline">r_{t}^{\mathrm{v}}</span> : <strong>joint velocities</strong></p></li>
<li><p><span class="math inline">r_{t}^{\mathrm{e}}</span> : <strong>end-effector positions</strong></p></li>
<li><p>ë¡œë´‡ì´ reference root motionì„ ì˜ tracking í•˜ê²Œ í•˜ê¸° ìœ„í•œ reward term</p>
<ul>
<li><span class="math inline">r_{t}^{\mathrm{rp}}</span> : <strong>root pose reward</strong></li>
<li><span class="math inline">r_{t}^{\mathrm{rv}}</span> : <strong>root velocity reward</strong></li>
</ul></li>
</ul>
<hr>
<p>ì´ì „ë¶€í„° ê°•ì¡°í•´ì™”ë“¯ì´, ì‹¤ì œ í™˜ê²½ì—ì„œ <code>fine-tuning</code>ê³¼ì •ì„ ì§„í–‰í•˜ê¸° ìœ„í•´ì„œ on-board ì„¼ì„œë“¤ì˜ ê°’ì„ ì´ìš©í•´ì„œ reward functionì„ ë””ìì¸í•˜ì˜€ê³  ì‹¤ì œ ë¬¼ë¦¬ì ì¸ í™˜ê²½ì—ì„œ êµ¬ë™í•  ë•Œ ì´ë¥¼ ìƒíƒœ ì¶”ì • ê¸°ë²•ì„ ì´ìš©í•´ì„œ rewardë¥¼ êµ¬í•˜ê²Œ ëœë‹¤. ë”°ë¼ì„œ ì•„ë˜ì˜ ìƒíƒœ ì¶”ì • ë°©ë²•(State Estimation)ì´ fine-tuningì˜ ì„±ëŠ¥ì„ ê²°ì •í•˜ëŠ” ì¤‘ìš”í•œ ë¶€ë¶„ì´ ëœë‹¤.</p>
<ul>
<li>Real-worldì—ì„œ ë¡œë´‡ì˜ <strong>linear root velocity</strong>ë¥¼ ì˜ ì¶”ì •í•˜ê¸° ìœ„í•´ì„œ <strong>Kalman filter</strong>ë¥¼ ì‚¬ìš©í–ˆë‹¤.
<ul>
<li>ì¹¼ë§Œ í•„í„°ëŠ” IMU ì„¼ì„œì—ì„œ accelerationê³¼ orientation ê°’ë“¤ì„ ì½ì–´ì„œ foot contact sensorsë¡œ ê°’ë“¤ì„ ë³´ì •í•œë‹¤.</li>
<li>ì²˜ìŒì— ë°œ ëì˜ ì†ë„ë¥¼ 0ìœ¼ë¡œ ìƒê°í•´ì„œ ê° ë‹¤ë¦¬ì˜ joint velocitiesë¥¼ ê³ ë ¤í•˜ì—¬ ëª¸ì²´ì˜ ì†ë„ë¥¼ ê³„ì‚°í•˜ê³  IMUìœ¼ë¡œë¶€í„° ì¶”ì •í–ˆë˜ ê°’ì„ ë³´ì •í•œë‹¤.</li>
</ul></li>
<li>ì´ë ‡ê²Œ ê³„ì‚°ëœ <strong>linear velocity</strong>ë¥¼ ë¡œë´‡ì˜ position ì¶”ì •ê°’ì— í†µí•©ì‹œí‚¨ë‹¤.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://i.imgur.com/1DW4hsQ.png?1" class="img-fluid figure-img"></p>
</figure>
</div>
<p>ìœ„ì˜ ê·¸ë˜í”„ë“¤ì— ë³¼ ìˆ˜ ìˆë“¯ì´(ì•„ë˜ì—ì„œ ìœ„ ë°©í–¥ìœ¼ë¡œ),</p>
<ul>
<li><strong>angular velocityì™€ orientation</strong> ì„¼ì„œ ê°’ë“¤ì€ ë§¤ìš° ì •í™•í–ˆë‹¤.</li>
<li><strong>linear velocity</strong>ëŠ” ë§¤ìš° ì •í™•í•˜ì§„ ì•Šì•˜ì§€ë§Œ í—ˆìš©ê°€ëŠ¥í–ˆë‹¤.(reasonable)</li>
<li><strong>position drifts</strong>ëŠ” ìƒë‹¹íˆ ë²—ì–´ë‚˜ëŠ” ë¶€ë¶„ì´ ìˆì—ˆì§€ë§Œ, ê° ì—í”¼ì†Œë“œì—ì„œ reward functionì„ ê³„ì‚°í•  ì •ë„ë¡œì˜ ì í•©í•œ ê°’ë“¤ì„ ë³´ì—¬ì£¼ì—ˆë‹¤.</li>
</ul>
</section>
<section id="c.-reset-controller" class="level2">
<h2 class="anchored" data-anchor-id="c.-reset-controller">C. Reset Controller</h2>
<ul>
<li><strong>reset policy</strong>ë¥¼ ì‹œë®¬ë ˆì´ì…˜ì—ì„œ í•™ìŠµí•˜ê¸° ìœ„í•´ ë‹¤ì–‘í•œ <strong>initial states</strong>ì—ì„œ ì‹œì‘í•˜ë„ë¡ í–ˆë‹¤.</li>
</ul>
<p>â†’ ë¡œë´‡ì„ randomí•œ height &amp; orientationì—ì„œ ë–¨ì–´ëœ¨ë ¤ì„œ ì•„ë˜ ì‚¬ì§„ì—ì„œ ë³¼ ìˆ˜ ìˆë“¯ì´ ë‹¤ì–‘í•œ <strong>initial states</strong>ë¥¼ ì„¤ì •</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://i.imgur.com/2soOO1g.png?1" class="img-fluid figure-img"></p>
</figure>
</div>
<ul>
<li><p>Motion imitation ëª©ì í•¨ìˆ˜ë¥¼ ìˆ˜ì •í•´ì„œ <strong>single, streamlined reset policy</strong>ë¥¼ í•™ìŠµì‹œì¼°ë‹¤.</p></li>
<li><p>Reference motionì„ ê°€ì§€ê³  ë¡œë´‡ì´ ì •í™•íˆ ì–´ë–»ê²Œ ì¼ì–´ë‚˜ì•¼ í• ì§€ë¥¼ ì•Œë ¤ì£¼ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ì•„ë˜ì™€ ê°™ì€ ë°©ë²•ìœ¼ë¡œ reset policyë¥¼ í•™ìŠµì‹œì¼°ë‹¤.</p></li>
</ul>
<ol type="1">
<li>policyê°€ <strong>rolling right side up</strong>ì„ ìœ„í•œ rewardë§Œì„ ê°€ì§€ê³  í•™ìŠµí•œë‹¤.</li>
<li>ë§Œì•½ ë¡œë´‡ì´ <strong>upright</strong>í•˜ëŠ”ë° ì„±ê³µí•˜ë©´ ì´í›„ì— <strong>motion imitation reward</strong>ë¥¼ ì¶”ê°€ì‹œì¼œì„œ í•™ìŠµë‹ˆë‹¤.
<ul>
<li>ì´ë•Œì˜ reference motionì€ <strong>standing pose</strong>ê°€ ë˜ê³  ë¡œë´‡ì´ ë˜‘ë°”ë¡œ ì„¤ ìˆ˜ ìˆë„ë¡ í•™ìŠµì‹œí‚¨ë‹¤.</li>
</ul></li>
</ol>
<ul>
<li>ì´ëŸ° ë°©ì‹ìœ¼ë¡œ í•™ìŠµëœ <strong>reset policy</strong>ëŠ” ë‹¤ì–‘í•œ test ì§€í˜•ì—ì„œ fine-tuning ì—†ì´ë„ ì˜ ë™ì‘í–ˆë‹¤.(tranfered well)</li>
</ul>
</section>
</section>
<section id="iv.-experiments" class="level1">
<h1>IV. Experiments</h1>
<p>ğŸ’¡ ì‹¤í—˜ ê²°ê³¼ì—ì„œ ì£¼ëª©í•´ì„œ ë´ì•¼í•  ì§ˆë¬¸ 3ê°€ì§€!</p>
<ol type="1">
<li><p>ë³¸ ë…¼ë¬¸ì—ì„œ ì œì‹œí•œ finetuning-based methodê°€ ì´ì „ì˜ ë°©ë²•ë“¤ì— ë¹„í•´ <code>ì‹œë®¬ë ˆì´ì…˜ trianingì„ ì¶©ë¶„íˆ í™œìš©</code>í•˜ê³  <code>ì‹¤ì œ ë¬¼ë¦¬ í™˜ê²½ì—ì„œ ì ì‘</code>í•  ìˆ˜ ìˆì—ˆëŠ”ê°€?</p></li>
<li><p>ë³¸ ë…¼ë¬¸ì—ì„œ ì œì‹œí•œ ì‹œìŠ¤í…œ ë””ìì¸ ìš”ì†Œë“¤ì´ <code>feasibility of real-world training</code>ì— ì–´ë–¤ ì˜í–¥ì„ ì£¼ì—ˆëŠ”ê°€?</p></li>
<li><p><code>ì–¼ë§ˆë‚˜ ë‹¤ì–‘í•œ ì‹¤ì œ ë¬¼ë¦¬ì ì¸ í™˜ê²½ë“¤</code>ì—ì„œ autonomous, online fine-tuning ë°©ë²•ì´ ë¡œë´‡ì˜ skillì„ í–¥ìƒì‹œì¼°ëŠ”ê°€?</p></li>
</ol>
<section id="a.-simulation-experiments" class="level2">
<h2 class="anchored" data-anchor-id="a.-simulation-experiments">A. Simulation Experiments</h2>
<ul>
<li><p>agentì˜ policyë¥¼ ë¨¼ì € íŠ¹ì • ì‹œë®¬ë ˆì´ì…˜ ì…‹íŒ…ì—ì„œ í•™ìŠµì‹œí‚¨ í›„ì— <strong>í•™ìŠµëœ ì‹œë®¬ë ˆì´ì…˜ê³¼ ë˜ ë‹¤ë¥¸</strong> ì‹œë®¬ë ˆì´ì…˜ í™˜ê²½ ì…‹íŒ…ì— â€œdeployedâ€í•œ í›„ ê²°ê³¼ë¥¼ ì‚´í´ë³´ì•˜ë‹¤.</p></li>
<li><p><strong>Learned forward pacing gait</strong>ê°€ í…ŒìŠ¤íŠ¸ í™˜ê²½ë“¤ì—ì„œ ì–¼ë§ˆë‚˜ ë¹¨ë¦¬ ì ìš©ë˜ëŠ”ì§€ í™•ì¸í•´ë³´ì•˜ë‹¤.</p></li>
<li><p><strong>Standard dynamics randomization (mass, inertia, motor strength, friction, latency ë³€ë™)</strong>ìœ¼ë¡œ Pre-trainì„ <strong>flat</strong> groundì—ì„œ ì§„í–‰í–ˆë‹¤.</p></li>
<li><p>The test terrains : test í™˜ê²½ë“¤ë¡œëŠ” ì´ 3ê°€ì§€ë¡œ ì‹¤í—˜í•˜ì˜€ë‹¤.</p>
<ol type="1">
<li><strong>a flat ground</strong> : pre-training ê³¼ì •ì˜ ì‹œë®¬ë ˆì´ì…˜ ì…‹íŒ…ê³¼ ìœ ì‚¬í•œ test í™˜ê²½</li>
<li>pre-training ê³¼ì •ì˜ ì‹œë®¬ë ˆì´ì…˜ ì…‹íŒ…ê³¼ ë‹¤ì†Œ ë‹¤ë¥¸ test í™˜ê²½ :
<ol type="1">
<li><strong>randomized heightfield</strong> : ëœë¤í•˜ê²Œ ì§€í˜•ì˜ ë†’ì´ë¥¼ ì„¤ì •í•œ ìš¸í‰ë¶ˆí‰í•œ ì§€í˜•</li>
<li><strong>a low friction surface</strong> : ë‚®ì€ ë§ˆì°°ê³„ìˆ˜ë¥¼ ê°€ì§€ëŠ” ì§€í˜•, ë¹™íŒê¸¸ê³¼ ê°™ì€ ë¯¸ë„ëŸ¬ìš´ ì§€í˜•(Training ê³¼ì •ì—ì„œ ê²½í—˜í•œ ë§ˆì°°ê³„ìˆ˜ ë¶„í¬ì™€ í•œì°¸ ë™ë–¨ì–´ì§„ ë§ˆì°°ê³„ìˆ˜ë¥¼ ê°€ì§€ê³  ìˆìŒ)</li>
</ol></li>
</ol></li>
<li><p>ë¹„êµêµ°</p>
<ol type="1">
<li><code>latent space</code> : í˜¸ìœ¨ì ì¸ ë‹¤ì–‘í•œ dynamics parametersì— ëŒ€í•œ í•™ìŠµì„ í•˜ê¸° ìœ„í•´ latent spaceì— í‘œí˜„ëœ behaviorsì„ í•™ìŠµ</li>
<li><code>RMA</code>: dynamics randomizationí•œ ëª¨ë¸. ìœ„ì—ì„œ ì–¸ê¸‰í•œ <code>Adaptation Module</code>ì„ ê°€ì§€ê³  í•™ìŠµ</li>
<li><code>Vanilla SAC</code> : Soft Actor-Critic ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ í•™ìŠµ</li>
<li><code>Ours(REDQ)</code>: 10ê°œì˜ Q-functionsì„ ê°€ì§€ê³  randomly sample 2ë¡œ í•™ìŠµ</li>
</ol></li>
</ul>
<hr>
<p>ì‹¤í—˜ ê²°ê³¼ëŠ” ì•„ë˜ì™€ ê°™ì•˜ë‹¤.</p>
<ul>
<li><code>RMA</code>ëŠ” training í™˜ê²½ì—ì„œë§Œ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ì–´ Adaptation Moduleì˜ í•œê³„ì ì„ ëª…í™•íˆ ë³´ì—¬ì£¼ì—ˆë‹¤.</li>
<li><code>SAC</code>ì— ë¹„í•´ì„œ <code>Ours</code>ê°€ sample efficiencyê°€ ì¢‹ì„ ë¿ë§Œ ì•„ë‹ˆë¼ ìˆ˜ë ´í•˜ëŠ” Return ê°’ë„ ë†’ì•˜ë‹¤.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://i.imgur.com/BCyV1Xk.png?1" class="img-fluid figure-img"></p>
</figure>
</div>
</section>
<section id="b.-real-world-experiments" class="level2">
<h2 class="anchored" data-anchor-id="b.-real-world-experiments">B. Real-World Experiments</h2>
<ul>
<li><p>ì‹œë®¬ë ˆì´ì…˜ì—ì„œ í•™ìŠµëœ Agentë¥¼ 4ê°œì˜ real-world í™˜ê²½(Outdoor 1ê°œ, Indoor 3ê°œ)ì—ì„œ test í–ˆë‹¤.</p></li>
<li><p>ëª¨ë“  (real-world) test ì§€í˜• ì‹¤í—˜ì€ ì‹œë®¬ë ˆì´ì…˜ì˜ flat groundì—ì„œ pre-trainingëœ agentë¡œ ì‹¤í—˜í•œ ê²ƒì´ì—ˆìœ¼ë©°, ì²˜ìŒì— bufferë¥¼ 5000 samplesë¡œ ì´ˆê¸°í™” í•´ì£¼ê³  ì‹œì‘í•œ ë‹¤ìŒ test real world í™˜ê²½ì—ì„œ policyë¥¼ <strong>fine-tuning</strong> í•´ì£¼ì—ˆë‹¤.</p></li>
</ul>
<ol type="1">
<li><p>Outdoor <code>grassy lawn</code>:</p>
<ul>
<li><p><strong>slippery surface</strong>ë¥¼ ê°€ì§€ê³  ìˆì–´ì„œ ë°œì´ ì”ë””ì—ì„œ ë¯¸ë„ëŸ¬ì§€ê±°ë‚˜ í™ì— ë¹ ì§ˆ ìˆ˜ ìˆë‹¤.</p></li>
<li><p>ì• í˜¹ì€ ë’¤ë¡œ ì›€ì§ì´ëŠ” <strong>pacing gait</strong>ë¥¼ fine-tuning í•˜ë„ë¡ í–ˆë‹¤.</p>
<ul>
<li>pacing gait: ì¢Œë‚˜ ìš°ì˜ 2ê°œì˜ ë‹¤ë¦¬ê°€ í•œë²ˆì— ì›€ì§ì´ëŠ” ê±¸ìŒìƒˆ</li>
</ul></li>
<li><p>Pre-trained <strong>forward</strong> pacing policyëŠ” ë§¤ìš° ì¡°ê¸ˆë§Œ ì•ìœ¼ë¡œ ê°ˆ ìˆ˜ ìˆì—ˆê³ , pre-trained <strong>backward</strong> pacing policyëŠ” ì˜ ë„˜ì–´ì§€ëŠ” ê²½í–¥ì´ ìˆì—ˆë‹¤.</p></li>
<li><p><strong>ì‘ë™í•œ ì§€ ì•½ 2ì‹œê°„ ë§Œì—</strong>, ë¡œë´‡ì€ (ì•„ì£¼ ì¡°ê¸ˆì˜ ë„˜ì–´ì§ì€ ìˆì—ˆì§€ë§Œ) ì§€ì†ì ì´ê³  ì•ˆì •ì ìœ¼ë¡œ ì• í˜¹ì€ ë’¤ë¡œ pacing gaitë¥¼ í•  ìˆ˜ ìˆì—ˆë‹¤.</p></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://i.imgur.com/EeTTRF8.png?2" class="img-fluid figure-img"></p>
</figure>
</div></li>
<li><p>Indoor</p>
<ul>
<li><code>Carpeted room</code>: ë†’ì€ ë§ˆì°°ê³„ìˆ˜ë¥¼ ê°€ì§€ëŠ” ì§€í˜•ìœ¼ë¡œ (ì¹´í«ì´ í‘¹ì‹ í•˜ë¯€ë¡œ) ë¡œë´‡ì˜ ê³ ë¬´ë¡œ ë§ˆê°ë˜ì–´ ìˆëŠ” ë°œì´ ì‹œë®¬ë ˆì´ì…˜ì—ì„œ í•™ìŠµëœ ê²ƒê³¼ ë‹¤ë¥´ê²Œ ì•ˆì •ì ì´ì§€ ì•Šì€ ì»¨íƒì„ í•˜ê²Œ ë  ìˆ˜ ìˆë‹¤.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://i.imgur.com/Pviw7be.png?1" class="img-fluid figure-img"></p>
</figure>
</div>
<ul>
<li><code>Doormat with crevices</code>: ë§¤íŠ¸ í‘œë©´ì— ë°œì´ ë¹ ì§ˆ ìˆ˜ë„ ìˆëŠ” í™˜ê²½ì´ë‹¤.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://i.imgur.com/865kXHv.png?1" class="img-fluid figure-img"></p>
</figure>
</div>
<ul>
<li><code>Memory foam</code>: 4cm ì •ë„ì˜ ë‘ê»˜ì˜ ë©”ëª¨ë¦¬í¼ìœ¼ë¡œ ë°œì´ ë§¤íŠ¸ë¦¬ìŠ¤ì— ë¹ ì§€ê³  í‰í‰í•˜ê³  ë”±ë”±í•œ ë°”ë‹¥ê³¼ ë¹„êµí–ˆì„ ë•Œ ì´ í™˜ê²½ì—ì„œëŠ” gait(ê±¸ìŒìƒˆ)ê°€ ìƒë‹¹íˆ ë³€í™”ê°€ ë§ì´ ì¼ì–´ë‚  ìˆ˜ ìˆë‹¤.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://i.imgur.com/EfZvlS5.png?1" class="img-fluid figure-img"></p>
</figure>
</div>
<ul>
<li><p><code>Indoors</code>ì—ì„œëŠ”, pre-trained side stepping policyê°€ ì›€ì§ì¼ ë•Œ ë§¤ìš° ë¶ˆì•ˆì •í–ˆê³  motionì„ ëë‚´ê¸° ì „ì— ë„˜ì–´ì¡Œë‹¤.</p></li>
<li><p>ê·¸ëŸ¬ë‚˜ ê° ì§€í˜• ì…‹íŒ…ì—ì„œ <strong>2.5 ì‹œê°„ ì´ë‚´ë¡œ</strong> ë¡œë´‡ì´ ë¹„í‹€ê±°ë¦¼ ì—†ì´ skillì„ ìˆ˜í–‰í•  ìˆ˜ ìˆì—ˆë‹¤.</p></li>
</ul></li>
</ol>
<hr>
<p>ì‹¤í—˜ ê²°ê³¼ëŠ” ì•„ë˜ì™€ ê°™ì•˜ë‹¤.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://i.imgur.com/NRNMAex.png?1" class="img-fluid figure-img"></p>
</figure>
</div>
</section>
<section id="c.-semi-autonomous-training" class="level2">
<h2 class="anchored" data-anchor-id="c.-semi-autonomous-training">C. Semi-autonomous training</h2>
<ul>
<li>ì „ë°˜ì ì¸ ëª¨ë“  ì‹¤í—˜ë“¤ì—ì„œ, the recovery policyëŠ” 100% ì„±ê³µì ì´ì—ˆë‹¤.</li>
<li>ë³¸ ë…¼ë¬¸ì—ì„œ ì œì‹œëœ ë°©ë²•ìœ¼ë¡œ í•™ìŠµëœ reset controllerì™€ Unitreeì—ì„œ ì œê³µí•œ built-in rollover controllerë¥¼ ë¹„êµí•´ë³´ì•˜ë‹¤.
<ul>
<li><strong>On hard surfaces</strong> : ë‘ ê°€ì§€ controllers ëª¨ë‘ íš¨ê³¼ì ìœ¼ë¡œ ì˜ ì‘ë™í–ˆì§€ë§Œ <strong>built-in</strong> ì»¨íŠ¸ë¡¤ëŸ¬ëŠ” <strong>learned policy</strong>ì— ë¹„í•´ ìƒë‹¹íˆ ëŠë ¸ë‹¤.</li>
<li><strong>On the memory foam</strong> : <strong>built-in</strong> ì»¨íŠ¸ë¡¤ëŸ¬ëŠ” ë” ì„±ëŠ¥ì´ ì¢‹ì§€ ëª»í–ˆë‹¤.</li>
</ul></li>
</ul>
</section>
</section>
<section id="v.-conclusion" class="level1">
<h1>V. Conclusion</h1>
<ul>
<li>grass, carpets, doormats and memory foamê³¼ ê°™ì€ ë‹¤ì–‘í•œ <strong>real-world settings</strong>ì—ì„œ <strong>finetune locomotion policies</strong>ì„ í•™ìŠµí•  ìˆ˜ ìˆëŠ” ì‹œìŠ¤í…œì„ ì œì•ˆí•˜ì˜€ë‹¤.</li>
<li><strong>autonomous data collection</strong>ê³¼ <strong>data-efficient model-free RL</strong>ì˜ ê²°í•©ì„ ë³´ì—¬ì£¼ì—ˆë‹¤.</li>
<li>ë¡œë´‡ì˜ ë„˜ì–´ì§ì—ì„œ <strong>automated recoveries</strong>ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆë„ë¡, ë¡œë´‡ì˜ <strong>on-board sensors</strong>ë“¤ì„ ê°€ì§€ê³  <strong>state estimation</strong>ì„ í–ˆìœ¼ë©°, ì´ ì •ë³´ë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ íš¨ê³¼ì ì¸ <strong>reward calculation</strong>ì„ ì œì•ˆí•˜ì˜€ë‹¤.</li>
<li>ë‹¤ì–‘í•œ locomotion skillì— ëŒ€í•œ <strong>data-efficient fine-tuning</strong> ë°©ë²•ì„ ë³´ì—¬ì£¼ì—ˆë‹¤.</li>
<li>ë³µì¡í•˜ê³  ë‹¤ì–‘í•˜ë©° <strong>ëŠì„ì—†ì´</strong> ë³€í™”í•˜ëŠ” <strong>real-world environments</strong>ì— ëŒ€ì‘í•  ìˆ˜ ìˆëŠ” <code>a lifelong learning system for legged robots</code>ë¥¼ future workë¡œ ë³´ê³  ìˆë‹¤.</li>
</ul>
</section>
<section id="review" class="level1">
<h1>Review</h1>
<blockquote class="blockquote">
<p>ë…¼ë¬¸ ë¦¬ë·°í›„ì˜ ì£¼ê´€ì ì¸ ì¥ë‹¨ì ì„ ì •ë¦¬í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.</p>
</blockquote>
<ul>
<li>Pros ğŸ‘
<ul>
<li>ë¡œë´‡ operationì˜ ëª…í™•í•œ í•œê³„ì , ê²°êµ­ ë¡œë´‡ì´ ë™ì‘í•´ì•¼ í•˜ëŠ” í™˜ê²½ì´ ê³„ì† ë³€í™”í•  ìˆ˜ ë°–ì— ì—†ë‹¤ëŠ” ë¬¸ì œì  ì¸ì‹ì´ ì¢‹ì€ ê²ƒ ê°™ìŒ</li>
<li>ì‹¤ì œ ì‚°ì—…ì—ì„œë„ íš¨ìœ¨ì ì¼ ê²ƒ ê°™ì€ ë°©ë²•ì´ë¼ê³  ìƒê°ì´ ë“¤ì—ˆìŒ</li>
<li>rest policyì˜ ì„±ê³µë¥ ì´ ëŒ€ë‹¨í–ˆìŒ</li>
</ul></li>
<li>Cons ğŸ‘
<ul>
<li>Out door ì‹¤í—˜ì—ì„œëŠ” ì—¬ëŸ¬ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ë¹„êµí•´ë³´ì§„ ì•Šì•˜ìŒ</li>
<li>ì•Œê³ ë¦¬ì¦˜ì€ ë™ì¼í•˜ê²Œ í•˜ê³  3ê°œì˜ policyë¥¼ ë”°ë¡œ ë‘ì§€ ì•Šê³  1ê°œì˜ policyë¡œ ë§Œë“¤ì—ˆì„ ë•Œë„ ë¹„êµêµ°ìœ¼ë¡œ ë¹„êµí•´ì„œ ì‹¤í—˜ê²°ê³¼ê°€ ìˆì—ˆìœ¼ë©´ ë” ì¢‹ì•˜ì„ ê²ƒ ê°™ìŒ</li>
</ul></li>
</ul>
</section>
<section id="reference" class="level1">
<h1>Reference</h1>
<ul>
<li><p><a href="https://arxiv.org/abs/2110.05457">Original Paper</a></p></li>
<li><p><a href="https://sites.google.com/berkeley.edu/fine-tuning-locomotion">Project Homepage</a></p></li>
<li><p><a href="https://arxiv.org/abs/2101.05982">Randomized Ensembled Double Q-Learning: Learning Fast Without a Model</a></p></li>
<li><p><a href="https://github.com/utilForever/rl-paper-study/blob/main/4th/210510%20-%20Randomized%20Ensembled%20Double%20Q-Learning%20Learning%20Fast%20Without%20a%20Model%2C%20X.%20Chen%20et%20al%2C%202021.pdf">REDQ REVIEW</a></p></li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "î§‹";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
<script src="https://giscus.app/client.js" data-repo="curieuxjy/curieuxjy.github.io" data-repo-id="R_kgDOIa8jzg" data-category="General" data-category-id="DIC_kwDOIa8jzs4CShZ1" data-mapping="title" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light_high_contrast" data-lang="en" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->



</body></html>