<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.33">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2025-09-20">
<meta name="description" content="Tactile In-Hand Manipulation with LLM-Designed Reward Functions">

<title>📃DEXOP 리뷰 – Curieux.JY</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../profile.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-ea385d0e468b0dd5ea5bf0780b1290d9.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark-bc185b5c5bdbcb35c2eb49d8a876ef70.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-ea385d0e468b0dd5ea5bf0780b1290d9.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-23aef1c2a45953e85f3378e7ccfb1407.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark-5a614c35f1f90bfd0a5b2992298a8538.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-23aef1c2a45953e85f3378e7ccfb1407.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-2NVZN2MJZT"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-2NVZN2MJZT', { 'anonymize_ip': true});
</script>


</head>

<body class="nav-fixed quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Curieux.JY</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../post.html"> 
<span class="menu-text">Post</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../note.html"> 
<span class="menu-text">Note</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">Jung Yeon Lee</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/curieuxjy"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#brief-review" id="toc-brief-review" class="nav-link active" data-scroll-target="#brief-review">Brief Review</a></li>
  <li><a href="#detail-review" id="toc-detail-review" class="nav-link" data-scroll-target="#detail-review">Detail Review</a>
  <ul class="collapse">
  <li><a href="#서론-및-개요" id="toc-서론-및-개요" class="nav-link" data-scroll-target="#서론-및-개요">서론 및 개요</a></li>
  <li><a href="#dexop-시스템의-설계와-구성" id="toc-dexop-시스템의-설계와-구성" class="nav-link" data-scroll-target="#dexop-시스템의-설계와-구성">DEXOP 시스템의 설계와 구성</a></li>
  <li><a href="#데이터-수집-및-로봇-전이-프로세스" id="toc-데이터-수집-및-로봇-전이-프로세스" class="nav-link" data-scroll-target="#데이터-수집-및-로봇-전이-프로세스">데이터 수집 및 로봇 전이 프로세스</a></li>
  <li><a href="#실험-및-성능-평가" id="toc-실험-및-성능-평가" class="nav-link" data-scroll-target="#실험-및-성능-평가">실험 및 성능 평가</a></li>
  <li><a href="#기존-연구와의-차별성-분석" id="toc-기존-연구와의-차별성-분석" class="nav-link" data-scroll-target="#기존-연구와의-차별성-분석">기존 연구와의 차별성 분석</a></li>
  <li><a href="#논문의-핵심-기여" id="toc-논문의-핵심-기여" class="nav-link" data-scroll-target="#논문의-핵심-기여">논문의 핵심 기여</a></li>
  <li><a href="#한계점-및-향후-전망" id="toc-한계점-및-향후-전망" class="nav-link" data-scroll-target="#한계점-및-향후-전망">한계점 및 향후 전망</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-page-left" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">📃DEXOP 리뷰</h1>
  <div class="quarto-categories">
    <div class="quarto-category">exoskeletons</div>
    <div class="quarto-category">perioperation</div>
  </div>
  </div>

<div>
  <div class="description">
    Tactile In-Hand Manipulation with LLM-Designed Reward Functions
  </div>
</div>


<div class="quarto-title-meta column-page-left">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">September 20, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<ul>
<li><a href="https://arxiv.org/abs/2509.04441">Paper Link</a></li>
<li><a href="https://dex-op.github.io/">Homepage</a></li>
</ul>
<ol type="1">
<li>본 논문은 로봇의 정교한 조작 기술 전이를 위한 새로운 데이터 수집 패러다임인 “perioperation”과 이를 구현하는 수동형 손 외골격 DEXOP를 소개합니다.</li>
<li>DEXOP는 인간의 손 움직임을 수동형 로봇 손에 기계적으로 연결하여 직접적인 접촉 피드백을 제공하며, 시각 및 촉각 데이터를 풍부하게 수집하여 로봇 기술 전이 효율을 극대화합니다.</li>
<li>사용자 연구 및 정책 학습 실험 결과, DEXOP는 텔레오퍼레이션 방식보다 월등히 높은 데이터 수집 효율성과 정교한 조작 능력을 보였고, 이를 통해 학습된 정책이 로봇의 복잡한 조작 성능을 크게 향상시킴을 입증했습니다.</li>
</ol>
<center>
<img src="../../images/2025-09-20-dexop/hand_tactile-small.gif" width="70%">
</center>
<center>
<img src="../../images/2025-09-20-dexop/0.png" width="100%">
</center>
<hr>
<section id="brief-review" class="level1">
<h1>Brief Review</h1>
<p>본 논문은 로봇 데이터 수집의 새로운 패러다임인 “perioperation”을 소개하며, 이를 구현한 수동형 손 외골격 시스템인 DEXOP를 제안합니다. Perioperation은 인간의 정교한 조작(manipulation)을 센서화하여 시각, 고유수용성 감각, 촉각, 행동을 포함한 풍부한 다중 감각 데이터를 수집하고, 이 데이터의 로봇으로의 전이 가능성을 극대화하는 데 중점을 둡니다.</p>
<p>DEXOP는 사용자가 자연스러운 환경에서 다양한 정교한 조작 작업을 수행하는 동안 인간의 손 조작을 센서화하도록 설계된 수동형 손 외골격입니다. 이 시스템은 인간의 손가락을 수동형 로봇 손가락에 기계적으로 연결하여 사용자에게 직접적인 접촉 피드백(고유수용성 감각을 통해)을 제공하고, 인간 손의 포즈를 수동형 로봇 손에 미러링하여 시연된 기술의 로봇으로의 전이를 극대화합니다. 이러한 힘 피드백과 포즈 미러링은 원격 조작(teleoperation)에 비해 과제 시연을 더 자연스럽게 만들어 속도와 정확성을 모두 향상시킵니다.</p>
<p><strong>핵심 방법론 및 설계:</strong></p>
<p>DEXOP의 디자인은 세 가지 주요 목표를 따릅니다.</p>
<ol type="1">
<li><strong>데이터 수집의 자연스러움 증대:</strong>
<ul>
<li><strong>높은 힘 투명성 (Force Transparency):</strong> DEXOP는 로봇 손을 통해 실시간, 관절 수준의 고유수용성 피드백을 사용자에게 제공하여 현재 원격 조작 방법의 주요 한계점인 햅틱 피드백 부재를 해결합니다. 이는 더 빠르고 정교한 과제 시연을 가능하게 합니다.</li>
<li><strong>운동학적 커플링 (Kinematic Coupling):</strong> 인간 손의 포즈를 수동형 로봇 손의 포즈에 기계적으로 매핑하여, 원격 조작에서 흔히 발생하는 부정확한 포즈 리타겟팅(retargeting)이나 운동학적 불일치로 인한 직관적이지 않은 시각적 손 포즈 수정의 필요성을 제거합니다.</li>
<li><strong>로봇 없이 데이터 수집:</strong> 실제 로봇 없이도 데이터 수집이 가능하여 비용 효율적이며 다양한 환경에 확장 가능합니다.</li>
</ul></li>
<li><strong>수집된 데이터의 높은 전이 가능성 (High Transferability):</strong>
<ul>
<li><strong>인간 손과 수동형 로봇 손의 분리:</strong> 기존 촉각 장갑의 한계점(로봇 손과의 형태/물리적 특성 불일치, 낮은 해상도 센서)을 극복하기 위해 인간 손과 수동형 로봇 손을 분리합니다. 이를 통해 수동형 로봇 손과 실제 로봇 손의 운동학적 체인, 모양, 센서를 일치시켜 데이터 전이 가능성을 극대화하는 공동 설계(co-design)가 가능해집니다.</li>
<li><strong>전체 손 촉각 센싱 (Whole-hand Tactile Sensing):</strong> 관절 위치만으로는 객체와의 동일한 상호작용 힘을 보장할 수 없기 때문에, 정확하고 신뢰할 수 있는 로봇 재생을 위해 손 전체에 걸쳐 힘과 접촉 정보를 상세하게 포착하는 GelSim(ple) 기반 카메라 센서를 장착합니다. 본 논문에서는 전체 손 센싱을 통한 힘 복원(force recovery)에 집중하기보다는 다양한 과제를 시연하는 능력에 초점을 맞춥니다.</li>
</ul></li>
<li><strong>수행 가능한 과제의 다양성 증대:</strong>
<ul>
<li><strong>기계적 강화:</strong> 손톱(fingernails) 추가로 얇거나 작은 객체 조작 가능, 집게/가운데/약지 손가락의 외전(abduction) 관절 추가로 손 내부 재배치(in-hand reorientation) 및 다양한 크기 객체 조작 지원, 패딩 처리된 손바닥(padded palm)으로 전체 손 조작 시 객체 고정 능력 향상 등 다양한 기능을 통합합니다. 이러한 기능들은 기존 로봇 손 디자인에서는 탐구되었지만, 인간이 효과적으로 조작하면서도 데이터 수집에 활용하기는 어려웠던 과제들을 DEXOP를 통해 가능하게 합니다.</li>
</ul></li>
</ol>
<p><strong>하드웨어 설계 (Hardware Design):</strong></p>
<p>DEXOP는 객체와 상호작용하는 수동형 로봇 손과 인간 손에 착용하는 외골격의 두 가지 주요 구성 요소로 이루어져 있습니다. 이 둘은 링크 시스템으로 기계적으로 연결됩니다. 인간 손가락에 의해 외골격에 가해진 힘은 로봇 손으로 전달되어 움직임을 구동하며, 로봇 손이 경험하는 상호작용 힘은 동일한 링크 시스템을 통해 다시 인간 사용자에게 전달됩니다.</p>
<ul>
<li><strong>DEXOP 변형:</strong> 4개의 손가락과 12개의 자유도(DoF)를 가진 DEXOP-12, 약지 손가락이 없는 3개의 손가락과 9개의 DoF를 가진 DEXOP-9, 그리고 집게/가운데 손가락의 외전 관절이 없는 3개의 손가락과 7개의 DoF를 가진 DEXOP-7 세 가지 변형이 있습니다. DEXOP-7은 실제 로봇 손인 EyeSight Hand [29]와 공동 설계되어 기술 전이를 용이하게 합니다.</li>
<li><strong>운동학 (Kinematics):</strong> 수동형 로봇 손은 인간 손가락의 운동학적 체인을 밀접하게 일치시키는 것을 목표로 합니다. DEXOP-12는 손가락당 3 DoF씩 총 12개의 DoF를 가집니다. 집게/가운데/약지 손가락은 2 DoF의 MCP(Metacarpophalangeal) 관절(외전 포함)과 1 DoF의 PIP(Proximal Interphalangeal) 관절을 가집니다. 엄지손가락은 2 DoF의 TM(Trapeziometacarpal) 관절과 1 DoF의 IP(Interphalangeal) 관절을 가집니다. DIP(Distal Interphalangeal) 관절은 복잡성 증가 대비 효용성이 낮아 제외됩니다. 착용 가능한 외골격의 운동학적 설계는 수동형 로봇 손과 일치하여 4-bar 링크를 통한 움직임 전달을 가능하게 합니다.</li>
<li><strong>링크 설계 (Linkage Design):</strong> 외골격과 수동형 로봇 손의 베이스를 스탠드오프(standoff)로 연결하여 가상 접지 프레임(virtual ground frame)을 형성합니다. 집게/가운데/약지 손가락에는 각각 두 개의 4-bar 링크 시스템이 적용되어 두 마디뼈(phalanges)를 구동합니다. 엄지손가락에는 두 개의 수직 축을 가진 TM 관절에 단일 커플러 링크가 사용되고, IP 관절 제어를 위해 두 번째 공간 4-bar 링크가 도입됩니다.</li>
<li><strong>공동 설계 (Co-design):</strong> DEXOP-7은 EyeSight Hand [29]와 공동 설계되었습니다. 초기 설계에서 엄지손가락 IP 관절의 굽힘 방향이 인간 해부학과 달라 불편함이 있었고, 이를 인간 해부학에 맞게 재설계했습니다. 이에 따라 줄어든 엄지손가락과 가운데 손가락의 접촉 면적을 보상하기 위해 가운데 손가락 끝부분의 기울기를 조정하여 정밀한 잡기 시 넓은 접촉 면적을 확보했습니다. 이러한 수정사항은 EyeSight Hand에도 다시 통합되어 외골격과 로봇 손 사이의 일관성을 보장하고 정책 전이를 원활하게 합니다.</li>
</ul>
<p><strong>실험 및 결과:</strong></p>
<p>본 논문은 DEXOP의 하드웨어 특성을 평가하고 원격 조작과의 데이터 수집 효율성을 비교하며, DEXOP가 가능하게 하는 다양한 정교한 과제들을 시연합니다.</p>
<ul>
<li><strong>하드웨어 특성:</strong> DEXOP-7은 EyeSight Hand와 비교하여 최대 힘, 작업 공간(workspace), 손가락 속도 등에서 유사한 성능을 보입니다. DEXOP-7은 엄지손가락 끝에서 약 70N, 집게/가운데 손가락 끝에서 약 60N의 힘을 전달할 수 있으며, 이는 로봇 손과 유사합니다. 작업 공간은 MCP 관절에서 110-120도, PIP 관절에서 105도를 가지며, 손가락 속도 또한 로봇 손과 비교할 만합니다.</li>
<li><strong>원격 조작과의 비교:</strong> 네 명의 참가자를 대상으로 드릴링, 전구 설치, 상자 포장, 병 열기 네 가지 과제에 대해 DEXOP 시스템, 원격 조작 시스템, 맨손 조작의 세 가지 제어 방식을 비교하는 사용자 연구를 수행했습니다.
<ul>
<li>DEXOP는 원격 조작 시스템에 비해 훨씬 높은 과제 처리량(task throughput)을 달성했습니다. 특히 드릴링과 같은 정교한 고유수용성 피드백이 필요한 과제에서 원격 조작은 거의 성공하지 못한 반면, DEXOP는 분당 6회 성공을 보였습니다. 전구 설치, 상자 포장, 병 열기 과제에서도 DEXOP는 원격 조작보다 2.4배에서 8배 빠른 처리량을 기록했습니다.</li>
<li>이 결과는 DEXOP가 조작 중 고유수용성 피드백이 필요한 과제 수행에 있어 원격 조작보다 훨씬 효율적이며, 단순한 과제에서도 더 나은 데이터 수집 옵션임을 시사합니다.</li>
</ul></li>
<li><strong>정교한 Perioperation 능력:</strong> DEXOP는 다음 두 가지 유형의 과제를 시연하여 정교한 조작 능력을 보여줍니다.
<ul>
<li><strong>정밀 손가락 조작 (Precise Finger Manipulation):</strong> 객체 재배치, 주사기 조작, 작은 나사 및 캡 조작 등 손끝 제어와 객체 포즈 조정의 정밀함이 요구되는 과제들.</li>
<li><strong>전체 손 조작 (Whole-hand Manipulation):</strong> 손가락과 손바닥의 협응이 필요한 과제로, 양념통 뚜껑 열기, 스프레이어 누르기, 종이 커터 사용 등 복잡한 손-환경 상호작용과 힘 적용이 필수적인 과제들.</li>
</ul></li>
</ul>
<p><strong>정책 학습 실험 (Policy Learning Experiments):</strong></p>
<p>DEXOP 데이터가 로봇 학습에 효과적으로 사용될 수 있는지 평가하기 위해 행동 복제(behavior cloning)를 사용하여 정책을 학습시켰습니다.</p>
<ul>
<li><strong>로봇 플랫폼:</strong> Unitree H1 휴머노이드 로봇에 두 개의 EyeSight Hand [29] (3손가락, 7 DoF)를 장착하여 총 22 DoF 시스템을 구축했습니다. DEXOP와 공동 설계된 EyeSight Hand를 사용하여 운동학 및 센싱 호환성을 보장했습니다.</li>
<li><strong>데이터 수집 방법:</strong> DEXOP는 손가락 관절 위치, 촉각 이미지, 손목 이미지(시각적 관찰용)를 기록합니다. 전신 외골격(AirExo-2 [52])에 DEXOP를 장착하여 전역 손 위치를 캡처했습니다. 전신 촉각 센싱의 복잡성 때문에, 각 손의 말단 지골(distal phalanx)에만 촉각 센서를 활성화했습니다.</li>
<li><strong>데이터 후처리:</strong> DEXOP 시스템은 EyeSight Hand와 동일한 센서, 운동학, 시각 구성을 공유하며, AirExo-2는 Unitree H1과 운동학적 구조를 공유하므로 추가적인 데이터 처리가 필요하지 않습니다.</li>
<li><strong>과제 설정:</strong> 복잡한 양손 조작 과제인 “전구 설치(bulb installation)”를 6단계로 분해하여 평가했습니다: (A) 베이스 잡기, (B) 전구 잡기, (C) 전구 삽입, (D) 전구 설치(돌려서 끼우기), (E) 램프 덮개 잡기, (F) 덮개 씌우기. 이 과제는 잡기 강건성, 손가락 협응, 정밀 정렬, 촉각 기반 의사 결정, 양손 협응 등 다양한 정교한 능력을 테스트합니다.</li>
<li><strong>학습 설정:</strong> ACT (Action Chunking Transformer) [37] 정책 아키텍처를 사용했습니다. 입력으로는 손목 카메라 이미지, 촉각 슈퍼 이미지(각 손의 엄지/집게/가운데 손가락 말단 지골에서 얻은 델타 이미지), 현재 관절 상태가 사용됩니다. 출력은 로봇 팔의 델타 관절 위치(상대적 움직임)와 손의 절대 관절 위치입니다. 학습 시 조명 변화, 팔 자세 변동, 시각 의존성 방지를 위한 증강 기법을 적용했습니다.</li>
<li><strong>결과:</strong> DEXOP 데이터만으로는 팔 외골격 조립 오류와 인간 조작자의 가변성으로 인한 누적 관절 오류가 발생할 수 있음을 확인했습니다. 이를 완화하기 위해 소량의 원격 조작 데이터를 DEXOP 데이터와 혼합하여 공동 학습했습니다.
<ul>
<li>160개의 DEXOP 시연과 40개의 원격 조작 시연을 혼합한 정책이 모든 단계에서 가장 높은 누적 성공률을 달성했습니다 (0.513).</li>
<li>동일한 총 시연 횟수를 가진 200개의 원격 조작 정책(0.425)이나 유사한 데이터 수집 시간을 가진 100개의 원격 조작 정책(0.355)보다 성능이 우수했습니다.</li>
<li>특히 전구 삽입 및 램프 덮개 잡기 단계에서 DEXOP 혼합 정책이 뛰어난 성능을 보였습니다. 원격 조작은 햅틱 피드백 부족으로 전구 조임 상태를 판단하기 어려워 과도한 회전이 발생하는 등 데이터에 편향을 도입하여 정책 성능 저하를 초래했습니다.</li>
<li>이 결과는 DEXOP가 더 효율적인 데이터 수집 방식일 뿐만 아니라, 조작자에게 풍부한 힘 피드백을 제공하여 더 깨끗하고 편향되지 않은 데이터를 생성하고, 결과적으로 정책의 일반화 및 다운스트림 과제 성능을 향상시킨다는 것을 시사합니다.</li>
</ul></li>
</ul>
<p><strong>결론적으로,</strong> DEXOP는 정교한 로봇 조작을 위한 고품질 데이터를 대규모로 수집하는 데 강력한 도구이며, 원격 조작에 비해 우수한 제어 능력과 데이터 수집 처리량을 제공합니다. Perioperation 패러다임과 DEXOP 시스템은 더 나은 데이터, 더 나은 하드웨어, 궁극적으로 더 정교한 로봇의 공동 발전을 가속화할 잠재력을 가지고 있습니다.</p>
<hr>
</section>
<section id="detail-review" class="level1">
<h1>Detail Review</h1>
<section id="서론-및-개요" class="level2">
<h2 class="anchored" data-anchor-id="서론-및-개요">서론 및 개요</h2>
<p>DEXOP(Dexterous OPeration)은 인간의 섬세한 조작(dexterous manipulation) 데이터를 로봇으로 효과적으로 전이하기 위한 새로운 패러다임인 “페리오퍼레이션(perioperation)”을 제시한 연구입니다. 페리오퍼레이션이란 기존의 원격 조작(텔레오퍼레이션이라 불리는 remote teleoperation)과 달리, 사람이 로봇과 직접 연결된 장치를 착용하고 현실 환경에서 물체를 조작함으로써 로봇 학습에 필요한 다양한 센서 데이터를 수집하는 접근입니다. 이를 통해 인간의 섬세한 조작 시 발생하는 시각, 촉각, 고유수용감각(프로프리오셉션) 정보를 풍부하게 기록하면서도, 이 데이터가 실제 로봇에 직접 활용될 수 있도록 전이 가능성을 극대화하는 것이 목적입니다. 연구의 핵심은 사람 손에 장착하는 수동형 손 외골격 장치와 그것에 기계적으로 연결된 수동 로봇 손으로 구성된 시스템 DEXOP을 구현하고, 이를 통해 사람이 마치 자신의 손으로 직접 물체를 다루듯 자연스럽고 정확하게 로봇 시연 데이터를 생성하도록 한 점입니다.</p>
<p>인간이 DEXOP 장치를 착용한 모습과 이를 통해 섬세한 물체 조작을 시연하는 예시입니다. 사람의 손가락 움직임이 기계식 링크를 통해 동일하게 로봇 손가락에 미러링되며, 사람이 물체를 조작할 때 로봇 손가락에 부착된 센서들이 시각 정보(손바닥 카메라)와 촉각 정보(손가락 전면의 촉각 센서)를 실시간 수집합니다. DEXOP 시스템은 실제 로봇 손과 동일한 형태와 센서 구성을 가진 수동 로봇 손을 사람이 움직이는 외골격에 연결함으로써, 인간의 조작 데이터가 추가적인 변환이나 보정 없이도 곧바로 로봇에 적용될 수 있게 설계되었습니다. 이러한 기계적 자세 미러링(pose mirroring)과 힘 투명성(force transparency) 덕분에 사용자는 마치 맨손으로 물체를 다루는 듯한 감각, 즉 관절 움직임에 대한 고유수용성 힘 피드백을 느끼면서 시연을 진행할 수 있습니다. 논문에서는 이러한 DEXOP의 설계 철학과 구현, 그리고 이를 활용한 다양한 과제 수행 및 학습 실험을 제시하며, 기존 방법들 대비 자연스럽고 빠른 시연 데이터 수집과 우수한 로봇 학습 성능 향상을 입증하였습니다.</p>
</section>
<section id="dexop-시스템의-설계와-구성" class="level2">
<h2 class="anchored" data-anchor-id="dexop-시스템의-설계와-구성">DEXOP 시스템의 설계와 구성</h2>
<p>DEXOP은 하드웨어 측면에서 크게 세 부분으로 이루어집니다:</p>
<ol type="1">
<li>인간의 손에 착용되는 수동형 손가락 외골격(exoskeleton)</li>
<li>외골격에 기계적으로 연결된 수동 로봇 손(데이터 수집용 로봇 손)</li>
<li>이 둘을 이어주는 링크 메커니즘</li>
</ol>
<p>수동 로봇 손은 인간 조작 데이터를 기록하기 위한 센서 플랫폼 역할을 하며, DEXOP 논문에서는 MIT에서 개발한 EyeSight 로봇 손의 설계를 계승하여 제작되었습니다. 인간이 외골격에 손가락을 넣고 움직이면 링크를 통해 로봇 손의 각 관절이 동일하게 움직이는데, 이때 사람 손가락에 가해지는 힘이 로봇 손가락에도 전달되고 반대로 로봇 손가락이 물체와 접촉하여 받는 저항력은 다시 링크를 통해 사람 손가락으로 느껴지게 됩니다. 이러한 양방향 기계 연결은 로봇의 접촉력을 사람에게 직접적인 고유수용성 피드백으로 전달하여, 별도의 전기식 햅틱 장치 없이도 사람에게 정밀한 힘 감각을 제공하는 것이 특징입니다. 특히 DEXOP에서는 일반적인 텔레오퍼레이션의 제한점인 제한적 햅틱 피드백(진동 등 단순 신호에 국한되거나 손끝 압력만 제공되는 문제)을 극복하고자, 손가락 각 마디까지 전해지는 풍부한 힘 피드백(법선력+전단력)을 구현하였다고 보고하고 있습니다.</p>
<p>하드웨어 기구학 설계 측면에서, DEXOP의 수동 로봇 손과 외골격 장치는 인간 손의 관절 구조를 가능한 충실히 모사하도록 공동 설계되었습니다. 이번 연구에서는 총 3가지 DEXOP 변형 모델이 제작되었는데, 가장 완성도가 높은 DEXOP-12는 4개의 손가락(엄지, 집게, 중지, 약지)에 총 12개의 자유도(관절)를 구현하였습니다. 각 손가락 별로 굽힘/폄(flexion)과 벌림/모음(abduction)을 위한 2 자유도의 첫째 마디(MCP 관절)와 굽힘만 가능한 둘째 마디(PIP 관절)를 포함하며, 엄지의 경우 손바닥과의 접합부(TMC 관절) 2자유도와 끝마디(IP 관절) 1자유도를 갖습니다. 이는 인간 손의 원위지절(DIP)이나 엄지의 일부 관절은 생략된 구성이지만, 설계 복잡도 증가 대비 조작 다양성 기여가 낮다고 판단되는 관절을 제외하여 설계 단순성과 기능성의 균형을 맞춘 결과입니다. 이러한 결정에도 불구하고 DEXOP-12는 인간 손과 유사한 넓은 작업 범위(예: 손가락 관절 가동각 약 110° 이상)와 충분한 힘 전달 능력(집게/중지 손끝에서 약 60N, 엄지 손끝에서 70N까지 힘 전달)으로 실제 로봇과 유사한 조작을 가능케 했습니다. 아울러 덱스터러스 조작을 위해 중요한 엄지의 대향 운동(다른 손가락과 마주보게 움직이는 능력)과 손가락 사이 간격 조절(벌림)을 포함함으로써, 작은 물체 집기부터 손바닥을 활용한 파지까지 다양한 형태의 작업이 가능하도록 디자인되었습니다.</p>
<p>DEXOP의 기계적 링크 설계는 여러 개의 4-bar 링크 장치를 직렬 및 병렬로 배치하여 사람 손가락의 움직임을 동일 비율로 로봇 손가락에 전달하도록 구성되었습니다. 예를 들어 집게/중지/약지에 대해서는 두 개의 4-bar 링크를 직렬 연결하여 첫째 마디(MCP)와 둘째 마디(PIP)의 각도를 각각 제어하며, 엄지의 경우 두 자유도의 관절을 한 개 링크로 묶고 추가 링크를 직교하게 배치해 엄지 끝마디를 제어하는 독특한 구조를 적용했습니다. 이러한 링크 구조는 외골격과 로봇 손 사이에 가상의 기준 좌표계(ground frame)를 설정하여 사람 손의 움직임이 로봇 손에 일대일 대응되도록 합니다. 또한 손가락 끝 켑(fingertip cot)을 통해 사람 손가락 끝을 외골격에 고정함으로써, 손끝 위치까지 정확히 대응시키는 것이 가능해졌습니다. 이처럼 정교한 기구학 매핑 덕분에 DEXOP 사용자는 시연 중에 손과 로봇 손의 자세 불일치를 보정하기 위해 시선을 떼어 확인하거나 인지적으로 부담을 느낄 필요 없이, 본능적인 동작만으로 정확한 로봇 조작 데이터를 생성할 수 있습니다. 이는 기존 텔레오퍼레이션에서 흔히 발생하는 인간 손 vs 로봇 손의 형상/관절 차이로 인한 자리꼬임(kinematic mismatch) 문제를 근본적으로 해소하여, 시연 과정의 직관성과 신뢰성을 크게 높인 점이라 평가됩니다. 더불어 DEXOP는 능동 구동부(모터)가 없기 때문에 시스템이 비교적 경량이고 안전하며, 여러 환경으로 쉽게 운반하여 사용할 수 있다는 장점도 있습니다.</p>
<p>한편, DEXOP 수동 로봇 손에는 다양한 센서 모듈이 통합되어 멀티모달 데이터 수집이 가능하게 합니다. 우선, 각 손가락의 마디와 관절 각도는 고해상도 엔코더로 계측되어 정확한 관절 궤적 데이터가 저장됩니다. 더욱 특筆할 만한 것은 손가락과 손바닥 전반에 장착된 전체 손 촉각 센싱 시스템인데, 이는 MIT Adelson 교수팀의 GelSight 기반 광학식 촉각 센서 기술을 활용한 GelSim(ple) 센서들로 구성됩니다. 각 손가락의 끝마디, 손바닥 면, 손가락의 첫 마디 부분까지 총 수 개의 GelSim(ple) 유닛이 분포하여, 손이 물체를 쥐는 동안 발생하는 세밀한 접촉 면적 분포와 힘 패턴을 카메라 기반으로 시각화해 기록합니다. 예를 들어 손가락 끝의 촉각센서는 물체의 미세한 질감이나 힘의 크기 변화를 영상(frame) 형태로 담아내고, 손바닥에 접촉된 부분도 모두 이미지로 저장되기 때문에, 이후 로봇 학습 단계에서 접촉력의 추정이나 접촉 지점 판별에 중요한 데이터를 제공합니다. 논문에서는 이러한 전체 손의 촉각 센싱(whole-hand tactile sensing)이 정교한 조작 재현에 필수적임을 강조하는데, 단순히 관절 위치 정보만 일치시키는 것으로는 동일한 힘 조절을 보장할 수 없기 때문에 물체가 미끄러지거나 부서지는 등의 문제가 생길 수 있지만, 손 전체의 힘 분포를 기록하면 나중에 로봇이 물체를 잡을 때 어느 부위에 얼마나 힘을 주었는지까지 재현할 수 있어 성공률과 안정성이 높아진다는 것입니다. 끝으로, DEXOP의 손바닥에는 어안 카메라(fisheye camera)가 부착되어 시야각이 넓은 1인칭 시각 영상을 획득합니다. 이 카메라는 작업 중인 물체와 손의 상호작용을 손목 부근에서 촬영하여, 시각 정보와 촉각 정보를 동기화한 데이터를 생성합니다. 필요에 따라 DEXOP는 전완부나 몸통의 움직임까지 포착하기 위해 별도의 팔 외골격(AirExo)이나 IMU/SLAM 기반 트래킹으로 손의 글로벌 위치/자세도 기록할 수 있습니다. 종합하면, DEXOP 시스템은 관절각도(time-series), 손목 위치 궤적, 손바닥 카메라 영상, 여러 지점의 촉각 영상 등 다양한 모달리티의 데이터를 동시에 수집하여, 로봇 학습에 필요한 풍부한 정보를 제공합니다.</p>
<p>DEXOP 설계에는 이러한 기본 구조 외에도, 조작 과제의 다양성을 높여줄 몇 가지 기계적 아이디어가 적용되었습니다.</p>
<ol type="i">
<li>손톱(fingernail): 로봇 손가락 끝에 작은 인공 손톱을 부착하여, 높이가 낮은 얇은 물체를 밑에서 긁어 들어올리거나 M2 나사와 같이 아주 작은 부품도 쉽게 집을 수 있게 했습니다.</li>
<li>손가락 벌림 관절(abduction joints): 집게, 중지, 약지의 첫째 관절에 좌우로 벌어지는 자유도를 추가하여, 손가락들 사이 간격을 조절함으로써 손 안에서의 물체 재배열(in-hand reorientation)이나 다양한 크기의 물체 파지에 용이하도록 했습니다.</li>
<li>푹신한 손바닥 패드(padded palm): 손바닥 표면에 쿠션 재질을 추가하여 물체를 감쌀 때 밀착력을 높였습니다. 이를 통해 예를 들어 한 손으로 병뚜껑을 딸 때 병 몸체를 손바닥으로 더욱 안정적으로 잡거나, 스프레이 통을 손에 쥐고 손가락으로 꼭지 부분을 누르는 등의 전체 손 파지 작업의 안정성이 향상되었습니다.</li>
</ol>
<p>이 세 가지 기능들은 이미 일부 로봇 핸드 연구에서 섬세함을 높이기 위한 장치들로 시도된 바 있으나, 데이터 수집용 인터페이스에 인간이 착용한 상태로 적용된 것은 DEXOP이 최초입니다. 인간 손과 로봇 손을 분리하여 설계한 DEXOP 구조 덕분에 이러한 기능들을 통합해도 사용자가 물체를 조작하는 데 지장이 없도록 만들 수 있었으며, 이는 정밀하고 다양한 작업 데이터를 수집하는 데 기여하는 중요한 혁신이라 볼 수 있습니다.</p>
</section>
<section id="데이터-수집-및-로봇-전이-프로세스" class="level2">
<h2 class="anchored" data-anchor-id="데이터-수집-및-로봇-전이-프로세스">데이터 수집 및 로봇 전이 프로세스</h2>
<p>DEXOP의 가장 큰 강점 중 하나는 수집한 인간 조작 데이터를 별 어려움 없이 실제 로봇에 전이할 수 있다는 점입니다. 앞서 언급했듯 DEXOP의 수동 로봇 손은 목표로 하는 실제 로봇 손과 동일한 형태의 기구학 구조와 센서 구성을 가지도록 공동 설계되었습니다. 예컨대 DEXOP-7 모델은 이후 실험에서 사용된 EyeSight 로봇 핸드와 1대1로 대응되게 만들어져, DEXOP-7로 모은 데이터가 곧바로 EyeSight 손이 장착된 로봇에 적용될 수 있었습니다. 인간 손과 로봇 손의 분리라는 발상의 장점은, 사람이 장비를 착용해 시연하는 시점부터 이미 로봇과 동일한 좌표계, 동일한 접촉 지점 정보로 기록이 이루어진다는 것입니다. 따라서 텔레오퍼레이션처럼 시연 후에 복잡한 좌표 변환이나 역기구학 계산, 추가 보정 등을 할 필요가 거의 없습니다. 실제 논문에서도 DEXOP+DexArm(AirExo) 시스템으로 수집된 데이터는 “별도의 embodiment gap 보정 없이 바로 정책 학습에 사용될 수 있었다”고 언급합니다. 이는 데이터 전처리 부담을 크게 줄이고, 사람이 시연하면서 느낀 감각과 로봇이 실행 시 필요한 정보 사이의 단절을 최소화한다는 점에서 의미가 큽니다.</p>
<p>데이터 수집 과정은 다음과 같이 이뤄집니다. 사용자가 DEXOP를 착용하고 목표 작업(예: 드릴로 구멍 뚫기, 전구 끼우기 등)을 수행하면, 실시간으로 모든 센서 데이터와 관절 정보가 동기화되어 기록됩니다. DEXOP는 자체 제어용 능동 부품이 없기 때문에, 별도의 제어 소프트웨어보다는 데이터 로깅 소프트웨어 아키텍처가 중요합니다. 연구진은 촉각 카메라 여러 대에서 오는 고속 영상 데이터와 관절각 센서 데이터, 팔 움직임 데이터 등을 수집하기 위해 여러 대의 온보드 컴퓨터(Raspberry Pi 등)와 GPU 워크스테이션을 활용한 분산 데이터 수집 시스템을 구성하였습니다. 이를 통해 전 손 촉각영상, 손바닥 시야 영상, 관절 각도 로그 등이 누락 없이 저장되었고, 후처리를 통해 각 프레임에 시각-촉각-포즈 정보가 정합된 시연 데이터셋이 구축되었습니다. 특히 과제에 따라 한 팔이 아닌 양손 조작(bimanual manipulation)이 필요한 경우, 한쪽 손에 DEXOP를 장착하고 다른 한 손으로는 보조 동작을 수행하여 데이터를 모으거나, 또는 두 개의 DEXOP 장치를 활용하는 방식도 고려될 수 있습니다. 본 논문에서는 주로 한 손에 DEXOP를 사용하고 나머지 한 손은 일반적으로 보조 역할을 하는 시나리오(예: 한 손으로 병을 잡고 DEXOP 낀 손으로 뚜껑을 여는 식)를 다루었으며, AirExo-2라는 팔 외골격을 함께 사용하여 DEXOP 손의 글로벌 위치 이동까지 기록함으로써 이후 로봇 팔+손 전체를 모방 제어할 수 있도록 하였습니다.</p>
<p>수집된 데이터는 로봇 학습 알고리즘에 투입되어 정책(policy) 또는 모델로 학습됩니다. 논문에서는 행동 청크 변환기(Action Chunking Transformer, ACT) 구조를 활용한 Behavior Cloning(행동 모방학습) 방식을 채택하여, DEXOP로 모은 시演 데이터를 로봇의 정책으로 학습시켰습니다. 학습에는 DEXOP로 수집한 데모 외에도, DEXOP와 약간 차이가 있는 부분(예: 팔 외골격의 미세한 차이로 인한 로봇 팔 보정)을 보완하기 위해 소량의 텔레오퍼레이션 데모 데이터를 혼합하였습니다. 이러한 과정을 거쳐 학습된 정책은 실험용 휴머노이드 로봇(Unitree H1, 양팔에 EyeSight 로봇 손 장착)에 이식되어, 사람 없이 로봇 스스로 여러 단계의 작업을 수행하도록 평가되었습니다. 중요한 것은, DEXOP 덕분에 수집된 데이터가 질적으로 높아 짧은 시간 내에 학습이 가능했고, 또 로봇 손의 실제 센서정보(촉각 등)까지 포함하고 있어 현실 환경에 강인한 정책을 얻을 수 있었다는 점입니다. 이는 곧이어 살펴볼 실험 결과에서 구체적으로 드러납니다.</p>
</section>
<section id="실험-및-성능-평가" class="level2">
<h2 class="anchored" data-anchor-id="실험-및-성능-평가">실험 및 성능 평가</h2>
<p>논문에서는 DEXOP 시스템의 유용성을 검증하기 위해 다양한 실험을 수행했습니다. 첫째, 기본 하드웨어 성능 평가로서 DEXOP와 목표 로봇 손(EyeSight Hand)의 기계적 성능 비교가 이뤄졌습니다. DEXOP-7 (3손가락, 7자유도 모델)을 착용한 사용자가 낼 수 있는 최대 힘, 작업 공간 범위, 속도 등을 측정하여, 실제 EyeSight 로봇 손의 사양과 유사하거나 그 이상임을 확인했습니다. 예를 들어 집게손가락 MCP 관절의 경우 DEXOP로 약 110° 이상의 굽힘 범위를 달성하였고, 각 관절의 최대 각속도도 35 rad/s 정도로 빠른 편이어서 인간 조작의 민첩성을 재현하기에 충분했습니다. 또한 손끝에 전달할 수 있는 힘은 60~70N 수준으로, 이는 작은 물체를 다루는 데 과잉일 정도로 높아 DEXOP가 로봇 손의 모든 잠재력을 충분히 이끌어낼 수 있음을 보여줍니다.</p>
<p>둘째, 사용자 실험(User Study)을 통해 DEXOP의 조작 효율이 기존 텔레오퍼레이션보다 우수함이 정량적으로 검증되었습니다. 실험 참가자들은 DEXOP와 비교군(전통적 텔레오퍼레이션 시스템)을 이용하여 드릴로 구멍뚫기, 전구 소켓에 끼우기, 박스에 물건 포장하기, 병뚜껑 열기 등 4가지 접촉이 많은 덱스터러스 작업을 수행했고, 연구진은 단위 시간당 성공적으로 작업을 완료한 횟수(처리량, throughput)를 측정했습니다. 그 결과 모든 과제에서 DEXOP 사용 시 성공 속도가 유의하게 높았으며, 텔레오퍼레이션에 비해 사람에 훨씬 가까운 성능을 보였습니다. 특히 텔레오퍼레이션으로는 전혀 성공하지 못한 작업도 DEXOP로는 원활히 수행되었는데, 예를 들어 드릴 작업의 경우 텔레오퍼레이션 성공률 0%였던 반면 DEXOP 사용 시 분당 6회의 빠른 작업 완료가 가능했습니다. 또 다른 예로 전구 설치 과제에서는 텔레오퍼레이션에서는 전혀 작업을 마치지 못했지만 DEXOP로는 다수의 전구를 짧은 시간 내 끼울 수 있었습니다. 이러한 차이는 DEXOP가 제공하는 고유수용성 힘 피드백과 정확한 자세 미러링 덕분에, 사용자가 물체와의 접촉 상태를 정확히 파악하며 신속하게 동작할 수 있기 때문으로 해석됩니다. 반면 기존 텔레오퍼레이션 인터페이스는 촉각 정보 부재로 인해 조심스럽게 천천히 동작하거나 과도한 힘/움직임을 주는 경향이 있어, 정밀한 접촉 작업에서 실패하거나 시간이 오래 걸리는 한계가 드러났습니다.</p>
<p>셋째, DEXOP의 조작 범위와 섬세함을 보여주는 질적 시연 예시들(qualitative demonstrations)이 제시되었습니다. 연구팀은 DEXOP-9 (약지 제외 3손가락, 9자유도)와 DEXOP-12 모델을 사용하여, 아주 작은 나사나 뚜껑 조작, 주사기처럼 정밀한 도구 조작, 서류봉투의 종이 클립 사용, 양손 협조 작업 등 다양한 시나리오를 수행했습니다. 예를 들어 손끝 정교성이 필요한 주사기 플런저 조작이나 M2 나사집게로 집어서 끼우기 등의 동작을 DEXOP로 성공적으로 해냈으며, 손바닥 전체를 활용하는 양손 병뚜껑 열기(한 손은 병 잡고 DEXOP 손으로 뚜껑 트는 작업), 스프레이 버튼 누르기, 종이커터 사용 등도 시연했습니다. 이들 작업은 일반적인 두손 집게(gripper)나 기존 원격 조작 손으로는 매우 수행하기 어렵거나 여러 단계로 복잡하게 해야 하는 것들인데, DEXOP 환경에서는 사람의 섬세한 손동작을 거의 그대로 재현할 수 있기 때문에 한 번의 연속 동작으로 성공시킬 수 있음을 보여주었습니다. 이는 DEXOP가 평행 크로우 그리퍼로 한계가 있는 영역(예: 한 손 안에서 물체 돌리기, 좁은 틈의 작은 부품 다루기 등)까지 데이터 수집 범위를 넓혀준다는 의미입니다.</p>
<p>넷째, 학습 실험(performance in policy learning)을 통해 DEXOP로 모은 데이터의 우수성이 입증되었습니다. 복잡한 6단계로 이루어진 양손 전구 조립 과제에 대해, 앞서 수집한 시연 데이터로 로봇 정책을 학습시키고 성능을 비교했습니다. 하나의 정책은 DEXOP 데이터 160개 + 텔레오퍼레이션 데이터 40개로 학습시켰고, 비교군으로 동일 과제의 텔레오퍼레이션 데이터 200개만으로 학습한 정책과, 텔레오퍼레이션 100개 데이터만으로 학습한 정책을 마련했습니다. 그 결과 DEXOP 데이터로 학습한 정책이 성공률 약 51.3%로, 동일 시간 동안 모을 수 있는 텔레오퍼레이션 데이터로 학습한 정책(약 35.5%)이나 두 배 많은 텔레오퍼레이션 데이터로 학습한 정책(42.5%)보다 훨씬 높은 성능을 보였습니다. 다시 말해, 같은 시간 투자 대비 DEXOP로 모은 데이터가 로봇에게 더 효과적인 학습을 제공하여 학습효율을 크게 향상시킨 것입니다. 분석 결과, 텔레오퍼레이션 데이터로 학습한 정책은 사람 조작 시의 비정상적인 동작 패턴까지 학습하여 중간에 실수를 하거나 불안정한 동작을 보였지만, DEXOP 데이터로 학습한 정책은 불필요한 동작이 적고 정확한 접촉 시점과 힘 조절이 포함되어 있어 더 신뢰성 있게 과제를 수행했다고 합니다. 예를 들어 텔레오퍼레이션 시에는 촉각이 없으므로 사용자가 전구를 소켓에 넣을 때 과도하게 여러 번 돌리는 경향이 있었고, 그 때문에 학습된 정책도 실제 로봇 실행 시 불필요하게 전구를 오래 돌리다가 시간 초과로 실패하는 경우가 있었다고 합니다.</p>
<p>반면 DEXOP 데이터에는 사람이 딱 맞는 힘과 각도로 전구를 돌려 끼운 동작들이 담겨 있어서, 정책이 정확히 적정 횟수만 돌리고 다음 단계로 넘어가는 등 효율적인 동작 시퀀스를 학습할 수 있었습니다. 이로써 DEXOP가 더 높은 품질의 시연 데이터를 빠르게 대량 수집할 수 있을 뿐 아니라, 그 데이터가 로봇의 실제 성능 향상으로 이어진다는 것을 실증했다고 볼 수 있습니다.</p>
<p>요약하면, DEXOP는 사람의 능숙한 조작을 보다 자연스러운 방식으로 기록하여, 기존 원격 조작 대비 시연 속도와 성공률을 높이고, 학습 측면에서도 적은 데이터로 더 나은 성능을 끌어내었다고 결론지을 수 있습니다. 이러한 실험결과들은 제안된 페리오퍼레이션 접근법이 로봇 덱스터러스 조작 연구에서 데이터 병목 문제를 완화하는 데 실질적인 해법이 될 수 있음을 보여줍니다.</p>
</section>
<section id="기존-연구와의-차별성-분석" class="level2">
<h2 class="anchored" data-anchor-id="기존-연구와의-차별성-분석">기존 연구와의 차별성 분석</h2>
<p>DEXOP의 접근은 휴먼-로봇 모션 트랜스퍼와 텔레오퍼레이션, 모션 캡처 등 관련 선행 연구들과 여러 측면에서 구별됩니다. 주요 비교 지점을 하나씩 살펴보겠습니다:</p>
<p><strong>원격 조작(텔레오퍼레이션) 기반 데이터 수집과의 비교:</strong></p>
<p>전통적으로 로봇 조작 데이터를 모으기 위해 VR 인터페이스나 데이터 장갑, 조이스틱 등을 활용한 텔레오퍼레이션이 널리 사용되었습니다. 그러나 이러한 방법들은 사람에게 촉각/힘 피드백이 거의 없거나 제한적이어서, 사용자들이 시각에 의존해 조심스럽게 조작하거나 진동 등 추상적 피드백만으로 추측에 의존해야 했습니다. 그 결과 미세한 힘 조절이 어렵고 조작 속도가 느리며, 시연 데이터에도 비연속적 움직임이나 부정확한 힘 적용 등의 오류가 흔히 포함되었습니다. 반면 DEXOP는 기계적 링크를 통한 손가락 레벨의 직접적인 힘/위치 피드백을 제공함으로써, 사용자가 자신의 손으로 만지는 듯한 현실감을 얻고 더 빠르고 정확하게 작업을 수행할 수 있게 합니다. 또한 텔레오퍼레이션에서는 인간 손과 로봇 손의 형태 차이로 인해 자세 맵핑 문제가 발생하여 사용자가 화면을 보며 로봇 손 자세를 미세 조정해야 하지만, DEXOP는 인간 손의 움직임이 곧 로봇 손 움직임으로 1:1 대응되므로 추가적인 보정 작업이 불필요하고 시연의 직관성이 높습니다. 이런 차이로 인해 DEXOP를 통한 데이터 수집은 동시간 대비 더 많은 시연 횟수와 성공 사례를 축적할 수 있고, 데이터 품질도 인간의 의도가 그대로 반영된 풍부한 접촉 정보 포함 고품질 데이터가 됩니다. 실제로 DEXOP 논문에서는 동일 시간 동안 DEXOP로 모은 데이터로 학습한 정책이 텔레옵 데이터 대비 성공률이 크게 향상됨을 보여주어, “전통적 텔레오퍼레이션 대비 단위 시간당 과제 성능이 유의미하게 높다”고 밝히고 있습니다.</p>
<p><strong>모션 캡처/데이터 글러브 방식과의 비교:</strong></p>
<p>사람의 손동작 데이터를 모아 로봇에 전이하려는 시도로 모션 캡처 장갑이나 비디오 기반 추출도 활용되어 왔습니다. 예를 들어, 사용자가 맨손이나 장갑을 끼고 물체를 조작하면서 손가락 관절각 센서나 비디오의 3D pose 추정으로 손 움직임을 기록한 후, 이를 로봇 손의 관절각 시퀀스로 변환하는 접근입니다. 그러나 이 경우 물체와의 상호작용 힘 정보가 기록되지 않으며, 사람 손과 로봇 손의 형태 차이를 맞추기 위해 복잡한 계산이나 휴리스틱이 필요합니다. 특히 손가락 개수나 길이, 관절범위 등이 다를 경우 정확한 모션 매핑이 어려워 로봇이 동일한 작업을 재현하지 못하거나, 미끄러짐/실패가 발생하기 쉽습니다. 또한 사람 손에 로봇과 동일한 촉각 센서를 장착하는 것은 공간 제약상 불가능하여, 로봇 입장에서 중요한 접촉면 정보가 누락됩니다. DEXOP는 수동 로봇 손을 별도로 사용함으로써 이 문제를 해결했습니다. 사람은 실제 물체를 만지지 않고 로봇 손을 통해 우회해서 조작하기 때문에, 사람 손에는 아무 센서도 없어 간편하지만 동시에 로봇 손에는 필요한 모든 센서를 장착할 수 있었습니다. 덕분에 인간 손의 움직임 데이터와 로봇 손의 접촉 데이터를 동시에 확보하여 나중에 로봇이 동일한 조건으로 작업할 수 있게 되었고, 번거로운 모션 리타게팅 없이 데이터의 전이 가능성이 크게 높아졌습니다. 한 마디로, DEXOP는 기존 모션 캡처 방식이 간과한 “로봇 관점의 데이터”(예: 로봇 촉각센서 출력)를 함께 얻는 점에서 차별화됩니다.</p>
<p><strong>단순 그리퍼 기반 데이터 수집 장치와의 비교:</strong></p>
<p>최근 연구들에서는 사람에게 간단한 외골격을 착용시켜 2핑거 그리퍼를 조작하게 함으로써 데이터 수집을 자동화하려는 시도가 있었습니다. MIT의 AirExo, UMI, DobbE 등은 비교적 저렴한 외골격을 이용해 사람의 팔이나 손 동작을 측정하고, 이를 2개의 손가락을 가진 그리퍼 로봇의 개폐 동작으로 매핑하여 데이터를 모으는 시스템입니다. 이러한 접근은 비용이 낮고 설치가 간편하다는 장점이 있지만, 얻을 수 있는 조작 데이터의 범위가 제한적입니다. 예를 들어 2핑거 그리퍼로는 손가락 사이에서 물체를 돌리는 동작이나 한 손가락이 지지하고 다른 손가락이 조작하는 복합 동작 등을 구현할 수 없으며, 작은 나사나 복잡한 부품을 다루기 어렵습니다. 또한 양손 그리퍼로 복잡한 작업을 수행하려면 여러 단계의 분할 동작이 필요해 비효율적입니다. 반면 DEXOP는 세 손가락 이상을 개별 제어할 수 있고 손바닥까지 활용 가능하여, 손 안에서의 정교한 조작, 작은 물체 조작, 관절식 물체(예: 뚜껑 달린 병) 조작 등 그리퍼로는 어려운 작업들을 수행할 수 있습니다. 논문에서도 DEXOP가 기존 병렬 그리퍼 기반 시스템 대비 (i) 손가락-물체 간 상대운동이 필요한 작업 지원, (ii) 양손 그리퍼로 여러 단계를 거쳐야 하는 작업을 한 손으로 완료 가능, (iii) 비좁은 공간의 작은 부품 조작 가능, (iv) 분사기나 도어처럼 관절부 있는 물건 조작 가능 등의 우위점을 지적하고 있습니다. 이는 DEXOP가 멀티핑거 로봇 손의 잠재력을 십분 활용하여 데이터 수집의 폭과 효율을 모두 높였음을 의미합니다.</p>
<p><strong>기존 다지 손 외골격 시스템과의 비교:</strong></p>
<p>사람 손에 힘을 주거나 재활을 돕기 위한 모터 구동식 손가락 외골격 연구도 오래 전부터 진행되어 왔습니다. 이러한 장치들은 주로 재활 의료나 힘 증강, 촉각 피드백 용도로 개발되어 사람 손가락에 능동적으로 힘을 가하거나 진동을 주는 기능이 있습니다. 최근에는 이를 확장하여 원격 로봇 조작에 적용한 사례도 있으나, 일반적으로 복잡하고 크며, 사람 손에 무거운 모터와 구조물이 붙어 있기 때문에 섬세한 물체 조작에 방해가 될 수 있습니다. DEXOP는 이와 정반대로 모터를 완전히 제거한 수동식 외골격이라는 점에서 차별화됩니다. 사람이 자신의 근력으로 움직이고 느끼는 자연스러운 상호작용을 목표로 하여, 하드웨어 간소화와 기계적 투명성을 극대화한 것이 특징입니다. 최근 발표된 몇몇 유사한 수동식 다지 외골격 연구들도 존재하지만, 이들 중 다수는 손가락의 기본적인 굽힘/폄 동작 전달에만 초점을 맞춘 초기 단계로서, 세밀한 손끝 조작이나 전손 촉각 기록까지 구현한 경우는 없었습니다. 논문에 따르면 동시대의 다른 시도들은 결국 기본적인 쥐기 동작만 가능하여 평행 그리퍼와 큰 차이가 없는 수준이었으나, DEXOP는 정밀하고 다양한 손동작을 모두 다룰 수 있고, 촉각 힘 정보까지 함께 기록함으로써 질적으로 다른 기여를 했다고 평가합니다. 즉, DEXOP는 인간 손의 섬세함을 로봇 데이터 수집 장치에 본격적으로 도입한 최초의 사례로 볼 수 있습니다.</p>
<p>요약하면, DEXOP는 기존 텔레오퍼레이션의 한계(느린 속도, 낮은 촉각 피드백), 순수 모션 캡처의 한계(힘/접촉 정보 부재), 단순 외골격/그리퍼 접근의 한계(조작 다양성 부족)를 모두 넘어서는 새로운 설계를 제시하여, 휴먼-로봇 모션 전이 분야에 독창적인 공헌을 했습니다.</p>
</section>
<section id="논문의-핵심-기여" class="level2">
<h2 class="anchored" data-anchor-id="논문의-핵심-기여">논문의 핵심 기여</h2>
<p>이 논문의 핵심 기여는 다음과 같이 정리될 수 있습니다:</p>
<p><strong>페리오퍼레이션(parioperation) 패러다임의 제안:</strong> 저자들은 인간의 조작 데이터를 로봇에 활용하기 위한 새로운 데이터 수집 패러다임을 정의하였습니다. 이는 원격 조작과 직접 시연 사이의 틈을 메우는 접근으로서, “인간이 로봇을 몸에 두르고 시연한다”는 개념을 구체화한 것입니다. 로봇 학습에서 데이터 병목 문제를 해결하기 위해 현실 세계에서 대규모로, 그리고 높은 질로 시연 데이터를 모을 수 있는 방법론을 제시한 점은 중요한 철학적 기여입니다. 저자들은 이를 통해 로봇의 일반화 능력을 높이려면 인간의 풍부한 경험을 최대한 로봇 형태로 담아내는 중간 단계가 필요함을 강조하며, DEXOP 같은 시스템이 그 중간층을 채워줄 것이라고 주장합니다.</p>
<p><strong>DEXOP 하드웨어 시스템의 구현:</strong> 논문은 위 패러다임을 실현한 구체적인 장치 DEXOP를 설계하고 제작하였습니다. 이 시스템은 세계 최초로 전손 촉각 센싱을 통합한 수동식 손 외골격으로, 인간과 로봇을 기계적으로 연결한 독창적 구조를 갖습니다. 얇은 금속 링크와 정교한 4절 링크 기구학을 통해 인간 손과 로봇 손의 움직임을 일체화하였고, 동시에 로봇 손에 인간의 감각을 실시간 피드백하는 설계를 선보였습니다. 또한 손톱, 벌림 관절, 손바닥 패드 등의 요소를 결합해 데이터 수집 장치로서의 기능성을 극대화하였으며, 7자유도부터 12자유도까지 다양한 형태의 프로토타입을 제작하여 범용성을 보여준 점도 공헌이라 할 수 있습니다. 요컨대, DEXOP는 기존 로봇 손 연구의 성과(센서, 메커니즘)를 인간 시연 장치에 이식하여 하드웨어적으로 새로운 플랫폼을 제공했다는 데 큰 의의가 있습니다.</p>
<p><strong>향상된 로봇 학습 성능 및 효율:</strong> DEXOP를 통해 수집한 데이터로 로봇 정책을 학습한 결과, 동일한 시간 대비 더 높은 성공률을 얻을 수 있음을 입증하였습니다. 이는 DEXOP 데이터가 정확하고 깨끗하며, 편향이 적은 덕분에 학습에 유리함을 보여줍니다. 반대로 기존 텔레오퍼레이션 데이터는 일관성 부족과 인간 조작상의 왜곡이 있어 비효율적임을 지적하였지요. 이러한 비교 실험을 통해, DEXOP가 로봇 학습을 가속화할 수 있는 강력한 도구임을 제시한 점은, 단순한 장치 개발을 넘어 로봇 학습 커뮤니티에 유용한 데이터셋/교본을 제공할 수 있다는 가능성을 연 것입니다. 특히 시각+촉각 통합 데이터를 이용한 학습이라는 측면에서, 향후 다중 센서퓨전 기반의 정책 개발에도 본 데이터가 중요한 역할을 할 수 있음을 시사합니다.</p>
<p><strong>관련 분야 연구 방향 제시:</strong> 본 논문은 마지막으로 DEXOP와 유사한 대규모 데이터 수집 기구들이 향후 로봇 학습의 필수 인프라가 될 것임을 언급하며, 이를 통해 더 나은 데이터-하드웨어-알고리즘의 공동 발전(coevolution)을 기대하고 있습니다. 이는 로봇 공학에서 “더 나은 손”만큼이나 “더 나은 데이터”의 중요성을 환기하는 메시지로서, 학술적 시사점이 큽니다. 요약하면, DEXOP 논문은 하나의 장치 소개에 그치지 않고, 로봇 덱스터러스 조작을 위한 데이터 문제 해결의 새 길을 제시하고 구체적으로 증명해 보인, 혁신적이고 종합적인 기여**를 했다고 평가할 수 있습니다.</p>
</section>
<section id="한계점-및-향후-전망" class="level2">
<h2 class="anchored" data-anchor-id="한계점-및-향후-전망">한계점 및 향후 전망</h2>
<p>DEXOP는 매우 유망한 시스템이지만, 논문에서 언급했거나 추후 고려해야 할 몇 가지 제한점과 향후 과제도 존재합니다.</p>
<p><strong>정량적인 힘 측정 및 보정의 한계:</strong></p>
<p>DEXOP는 사람의 감각을 통해 간접적으로 힘을 전달하지만, 절대적인 접촉력 수치나 토크를 정확히 계측하는 기능은 아직 제한적입니다. 수집된 촉각 영상으로부터 정확한 접촉력/관절 토크 추정을 하기 위해서는 별도의 보정과 센서 캘리브레이션이 필요한데, 현 단계에서는 이러한 실시간 추정이 어렵습니다. 향후에는 촉각 이미지를 정교하게 해석하여 정량적인 힘 정보를 복원하고, 이를 통해 로봇에 정밀힘 제어 피드백을 주는 연구가 필요합니다.</p>
<p><strong>로봇 손 구조적 한계:</strong></p>
<p>DEXOP가 대응하는 EyeSight 로봇 손은 인간 손보다 간단화된 구조(예: DIP 관절 없음, 새끼손가락 제외 등)이므로, 일부 매우 고난이도의 섬세한 작업에는 한계가 있습니다. 예를 들어 사람 손가락 끝마디를 활용한 정교한 물체 뒤집기나, 새끼손가락까지 쓰는 복잡한 파지 등은 현재 DEXOP-12로는 구현이 어렵습니다. 이는 DEXOP 시스템 자체의 한계라기보다 목표 로봇 플랫폼의 한계로 볼 수도 있는데, 향후 더욱 고도화된 로봇 손(예: 5손가락 20자유도 이상)이 개발되고 여기에 대응하는 DEXOP가 생긴다면 인간 손의 거의 모든 동작을 데이터화하는 것도 가능할 것입니다. 반대로, 너무 복잡한 구조는 DEXOP 장치의 착용감을 해칠 수 있으므로 설계 상쇄(trade-off)를 고려해야 합니다.</p>
<p><strong>인간에게 제공되는 촉각 피드백의 한계:</strong></p>
<p>현재 DEXOP는 기계적 링크를 통한 고유수용성 힘 피드백만을 사람에게 제공합니다. 이는 관절의 저항으로 느껴지는 힘은 전해지지만, 정교한 피부 감각(예: 질감, 미세한 진동 등)은 사람에게 전달되지 않는다는 뜻입니다. 사람 손가락 끝이 직접 물체에 닿는 것이 아니기 때문에, 촉각 센서로 측정된 정보를 다시 사람 피부에 전달해주지 않는 한 완전한 촉감 피드백은 없습니다. 향후에는 사람 쪽 장갑에 간단한 진동자나 압력 패드를 달아 텍스쳐나 미끄럼 감지 피드백을 주거나, 최소한 촉각 이벤트(예: 물체 접촉/탈촉 시각) 정도는 알려주는 방식도 고려될 수 있습니다. 다만 이러한 기능 추가는 시스템 복잡도를 높일 수 있으므로, 사람의 학습 곡선과 피로도 등에 미치는 영향도 연구해야 할 것입니다. 원격 조작 및 범용성에 대한 과제: DEXOP는 사람이 직접 장치를 착용하고 현장에서 시연해야 하므로, 완전한 원격 조작에는 한계가 있습니다. 예를 들어 위험한 원자력 시설 내부나 인간이 접근하기 어려운 우주/해저 환경에서 데이터를 모으기에는 DEXOP를 그대로 활용하기 어렵습니다. 그런 환경에서는 여전히 전통적 텔레로봇+haptic 인터페이스 조합이 필요할 수 있습니다. 따라서 DEXOP 개념을 원격 적용하려면, 사람 쪽과 원격 로봇 쪽을 동일한 링크 장치로 연결하고 원격에서 마스터-슬레이브 형태로 힘 반영을 하는 등 추가 연구가 필요할 것입니다. 또한 DEXOP 장치를 다른 로봇 손으로 변경하려면 해당 손에 맞춘 외골격/링크를 새로 설계해야 하므로, 범용 플랫폼화에도 도전이 있습니다. 이를 해결하기 위해 모듈형 DEXOP(여러 손 형상을 지원)이나 소프트(exo) 장치로의 발전도 생각해볼 수 있습니다.</p>
<p>이러한 한계들에도 불구하고, 저자들은 DEXOP류 시스템이 향후 로봇 학습 데이터 수집의 중추적인 역할을 할 것으로 기대하고 있습니다. 앞으로 촉각과 시각의 통합 학습, 정밀 힘제어가 가능한 정책 등 DEXOP 데이터 활용 연구가 이어진다면, 로봇이 사람 수준의 섬세한 조작을 학습하는 날이 앞당겨질 것으로 보입니다. DEXOP는 현재 발전 중인 분야의 흥미로운 이정표(milestone)로서, 향후 개선과 응용 여지가 매우 큰 플랫폼이라 할 수 있습니다.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<script src="https://utteranc.es/client.js" repo="curieuxjy/blog_comments" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Copyright 2024, Jung Yeon Lee</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/curieuxjy">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>