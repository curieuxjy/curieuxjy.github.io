<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.33">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2025-07-29">
<meta name="description" content="Spatio-Temporal Motion Retargeting for Quadruped Robots">

<title>📃SMTR 리뷰 – Curieux.JY</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../profile.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-ea385d0e468b0dd5ea5bf0780b1290d9.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark-bc185b5c5bdbcb35c2eb49d8a876ef70.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-ea385d0e468b0dd5ea5bf0780b1290d9.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-23aef1c2a45953e85f3378e7ccfb1407.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark-5a614c35f1f90bfd0a5b2992298a8538.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-23aef1c2a45953e85f3378e7ccfb1407.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-2NVZN2MJZT"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-2NVZN2MJZT', { 'anonymize_ip': true});
</script>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-fixed quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Curieux.JY</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../post.html"> 
<span class="menu-text">Post</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../note.html"> 
<span class="menu-text">Note</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">Jung Yeon Lee</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/curieuxjy"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#brief-review" id="toc-brief-review" class="nav-link active" data-scroll-target="#brief-review">Brief Review</a></li>
  <li><a href="#detail-review" id="toc-detail-review" class="nav-link" data-scroll-target="#detail-review">Detail Review</a>
  <ul class="collapse">
  <li><a href="#연구의-독창성-시공간-아키텍처-모션-프라이어-통합-리타게팅-전략" id="toc-연구의-독창성-시공간-아키텍처-모션-프라이어-통합-리타게팅-전략" class="nav-link" data-scroll-target="#연구의-독창성-시공간-아키텍처-모션-프라이어-통합-리타게팅-전략">연구의 독창성: 시공간 아키텍처, 모션 프라이어 통합, 리타게팅 전략</a></li>
  <li><a href="#방법의-강점-일반화-능력-강인성-학습-전략-및-설계" id="toc-방법의-강점-일반화-능력-강인성-학습-전략-및-설계" class="nav-link" data-scroll-target="#방법의-강점-일반화-능력-강인성-학습-전략-및-설계">방법의 강점: 일반화 능력, 강인성, 학습 전략 및 설계</a></li>
  <li><a href="#잠재적-약점-제한된-상황-복잡도-및-기타-고려사항" id="toc-잠재적-약점-제한된-상황-복잡도-및-기타-고려사항" class="nav-link" data-scroll-target="#잠재적-약점-제한된-상황-복잡도-및-기타-고려사항">잠재적 약점: 제한된 상황, 복잡도 및 기타 고려사항</a></li>
  <li><a href="#실험-결과의-타당성과-의미-성능-검증-및-비교-분석" id="toc-실험-결과의-타당성과-의미-성능-검증-및-비교-분석" class="nav-link" data-scroll-target="#실험-결과의-타당성과-의미-성능-검증-및-비교-분석">실험 결과의 타당성과 의미: 성능 검증 및 비교 분석</a></li>
  <li><a href="#논문-기획-및-서술의-명확성-재현-가능성-추가적-제한사항" id="toc-논문-기획-및-서술의-명확성-재현-가능성-추가적-제한사항" class="nav-link" data-scroll-target="#논문-기획-및-서술의-명확성-재현-가능성-추가적-제한사항">논문 기획 및 서술의 명확성, 재현 가능성, 추가적 제한사항</a></li>
  <li><a href="#손-로봇-분야로의-기술-확장-시공간-리타게팅의-응용" id="toc-손-로봇-분야로의-기술-확장-시공간-리타게팅의-응용" class="nav-link" data-scroll-target="#손-로봇-분야로의-기술-확장-시공간-리타게팅의-응용">손 로봇 분야로의 기술 확장: 시공간 리타게팅의 응용</a>
  <ul class="collapse">
  <li><a href="#인간-손-동작의-로봇-손으로-리타게팅-자세-및-궤적-매핑" id="toc-인간-손-동작의-로봇-손으로-리타게팅-자세-및-궤적-매핑" class="nav-link" data-scroll-target="#인간-손-동작의-로봇-손으로-리타게팅-자세-및-궤적-매핑">인간 손 동작의 로봇 손으로 리타게팅 (자세 및 궤적 매핑)</a></li>
  <li><a href="#시공간-모션-전이를-통한-조작-행동-학습-모방-및-제어" id="toc-시공간-모션-전이를-통한-조작-행동-학습-모방-및-제어" class="nav-link" data-scroll-target="#시공간-모션-전이를-통한-조작-행동-학습-모방-및-제어">시공간 모션 전이를 통한 조작 행동 학습 (모방 및 제어)</a></li>
  <li><a href="#손-로봇-적용을-위한-핵심-기법-요약" id="toc-손-로봇-적용을-위한-핵심-기법-요약" class="nav-link" data-scroll-target="#손-로봇-적용을-위한-핵심-기법-요약">손 로봇 적용을 위한 핵심 기법 요약</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-page-left" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">📃SMTR 리뷰</h1>
  <div class="quarto-categories">
    <div class="quarto-category">retargeting</div>
    <div class="quarto-category">quadruped</div>
  </div>
  </div>

<div>
  <div class="description">
    Spatio-Temporal Motion Retargeting for Quadruped Robots
  </div>
</div>


<div class="quarto-title-meta column-page-left">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">July 29, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<ul>
<li><a href="https://arxiv.org/abs/2404.11557">Paper Link</a></li>
</ul>
<ol type="1">
<li>🐾 이 연구는 사족보행 로봇을 위한 시공간 모션 리타겟팅(Spatio-Temporal Motion Retargeting, STMR) 방법을 제안하여, 다양한 소스 모션의 역동적이고 민첩한 움직임을 로봇의 형태 및 물리적 제약에 맞춰 재조정합니다.</li>
<li>🤖 STMR은 모션 리타겟팅을 공간(SMR) 및 시간(TMR) 영역의 두 단계로 분해하여, 노이즈가 있는 키포인트 궤적(baseless keypoint trajectories)으로부터 발 미끄러짐과 관절 침투를 방지하며 물리적으로 실현 가능한 전신 모션을 생성합니다.</li>
<li>🚀 시뮬레이션에서 기존 방법 대비 66.7% 향상된 추적 성능을 보였고, 실제 Unitree Go1, Go2, AlienGo, B2 로봇에 성공적으로 배포되어 지형을 고려한 백플립과 같은 역동적인 동작을 수행할 수 있음을 입증했습니다.</li>
</ol>
<center>
<img src="../../images/2025-07-29-stmr/1.png" width="100%">
</center>
<hr>
<section id="brief-review" class="level1">
<h1>Brief Review</h1>
<p>이 논문은 사족 보행 로봇을 위한 스페이시오-템포럴 모션 리타겟팅(Spatio-Temporal Motion Retargeting, STMR) 접근 방식을 제안합니다. 이 방법은 다양한 소스 모션으로부터 역동적이고 민첩한 움직임을 로봇으로 전달하며, 로봇의 형태적 차이를 해소하고 물리적 실현 가능성을 보장합니다.</p>
<p>핵심 방법론은 두 단계로 나뉩니다: 공간 모션 리타겟팅(Spatial Motion Retargeting, SMR)과 시간 모션 리타겟팅(Temporal Motion Retargeting, TMR).</p>
<p><strong>I. 공간 모션 리타겟팅 (SMR)</strong></p>
<p>SMR은 운동학적 수준에서 모션을 리타겟팅하여 발 미끄럼(foot sliding)이나 발 침투(foot penetration)와 같은 운동학적 오류를 제거하고 접촉 스케줄을 보존합니다. 이는 특히 전역 기저 자세 정보가 없는 키포인트 궤적(baseless keypoint trajectories)으로부터 전신 모션을 재구성할 때 중요합니다.</p>
<p>기존의 Unit Vector Method(UVM)는 인접 키포인트 간의 방향 벡터를 유지하지만, 발 미끄럼, 침투, 그리고 접촉 스케줄 불일치와 같은 원치 않는 오류를 유발할 수 있습니다. 또한, UVM은 로봇의 운동학적 구성에 맞춰 기저 궤적을 조정할 수 없습니다.</p>
<p>SMR은 이러한 문제를 해결하기 위해 발 제약(foot constraints)을 도입합니다. 이 제약은 접촉 중인 발의 위치를 지면에 고정(발 잠금)하고, 원본 모션과 동일한 접촉 타이밍을 보장하며 발 침투를 방지합니다(접촉 보존).</p>
<p>SMR의 과정은 다음과 같습니다:</p>
<ol type="1">
<li><strong>초기 전신 모션 생성:</strong> 먼저, 기저 궤적이 포함되지 않은 키포인트 궤적 <span class="math inline">\bar{p}_{0:T}</span>를 사용하여 비제약 역운동학(IK) 문제와 유사하게 UVM을 통해 초기 일반화된 좌표 솔루션 <span class="math inline">q_{0:T}</span>를 얻습니다.</li>
<li><strong>속도 수준 최적화:</strong> <span class="math inline">q_{0:T}</span>의 시간 미분인 <span class="math inline">\dot{q}_{0:T}</span>를 참조 속도 목표로 사용하고, 다음 단일 프레임에 대한 최적화 문제를 풉니다. 이 문제는 현재 좌표 <span class="math inline">q_i</span>와 참조 좌표 <span class="math inline">\tilde{q}_i</span> 간의 스케일된 오차 <span class="math inline">\delta \tilde{q}_i = K_q(\tilde{q}_i - q_i)</span>에 대한 속도 <span class="math inline">\dot{q}_i</span>를 최소화합니다. 이때 발 제약은 선형화되어 적용됩니다. <span class="math display">\dot{\bar{q}}_i = \arg \min_{\dot{q}_i} \frac{1}{2} \left\| \dot{q}_i - \delta \tilde{q}_i \right\|^2_Q</span> <span class="math display"> s.t. \ \  J^i_j \dot{q}_i = c_j K_p(\tilde{p}_j - FK_j(q_i)) \quad j \in [1, 2, 3, 4]</span> 여기서 <span class="math inline">J^i_j</span>는 <span class="math inline">j</span>번째 키포인트에 대한 기하 Jacobian 행렬이고, <span class="math inline">c_j</span>는 <span class="math inline">j</span>번째 발의 접촉 여부(불리언 값), <span class="math inline">K_p</span>는 제어 이득, <span class="math inline">\tilde{p}_j</span>는 발의 고정점(anchor position)입니다. 이 발 고정점은 접촉 중인 발의 위치를 지면에 투영한 값입니다.</li>
<li><strong>비행 단계 처리:</strong> 로봇의 모든 발이 공중에 있는 비행 단계에서는, 로봇의 기저가 탄도 궤적을 따른다고 가정합니다. SMR은 기저 궤적 기록에 다항 함수를 적합시켜 이탈 속도(exit velocity)를 계산하고, 중력 가속도를 통합하여 탄도 궤적을 따르도록 합니다.</li>
</ol>
<p><strong>II. 시간 모션 리타겟팅 (TMR)</strong></p>
<p>TMR은 SMR을 통해 얻은 운동학적으로 실현 가능한 모션을 동적 제약 조건에 맞춰 시간 영역에서 더 정교하게 다듬어 동적으로 실현 가능한 모션을 생성합니다. 이는 특히 공중 동작(flight phases)이 포함된 모션에 중요하며, 로봇의 크기나 구동력에 따라 공중 체공 시간이 달라져야 합니다.</p>
<p>TMR은 SMR의 결과인 <span class="math inline">\bar{p}_{0:T}</span>를 기반으로 최적의 시간 매개변수 <span class="math inline">\alpha</span>와 제어 시퀀스 <span class="math inline">u_{0:T_\alpha}</span>, 로봇 상태 <span class="math inline">x_{0:T_\alpha}</span>를 탐색하는 중첩 최적화 문제(nested optimization problem)로 정의됩니다.</p>
<p><span class="math display">\min_{\alpha \in I}\left(\min_{u_{0:T_\alpha}, x_{0:T_\alpha}} \frac{1}{2T_\alpha} \sum_{k=0}^{T_\alpha} \left\| FK(x_k) - LI(s_\alpha(t_k); \bar{p}_{0:T}) \right\|^2_Q\right.</span> <span class="math display">\quad \text{s.t. } x_{k+1} = f(x_k, u_k),</span> <span class="math display">\quad h(x_k, u_k) \le 0,</span> <span class="math display">\quad g_{eq}(x_k) = 0,</span> <span class="math display">\quad g_{in}(x_k) \le 0 \quad \left. \vphantom{\min_{u_{0:T_\alpha}, x_{0:T_\alpha}} \frac{1}{2T_\alpha} \sum_{k=0}^{T_\alpha} \left\| FK(x_k) - LI(s_\alpha(t_k); \bar{p}_{0:T}) \right\|^2_Q} \right)</span> 여기서 <span class="math inline">s_\alpha(t)</span>는 시간 변형 함수로, 소스 모션을 <span class="math inline">S</span>개의 세그먼트로 나누고 각 세그먼트를 <span class="math inline">\alpha</span>의 각 요소에 따라 시간적으로 스케일링합니다. <span class="math inline">LI(\cdot)</span>는 선형 보간 함수입니다.</p>
<p>TMR의 과정은 다음과 같습니다:</p>
<ol type="1">
<li><strong>매개변수 샘플링:</strong> 시간 매개변수 <span class="math inline">\alpha</span>를 초기 구간 <span class="math inline">[ \alpha_{min}, \alpha_{max} ]</span> 내에서 무작위로 샘플링합니다.</li>
<li><strong>시간 변형(Temporal Deformation):</strong> 샘플링된 <span class="math inline">\alpha</span>를 사용하여 SMR을 통해 얻은 키포인트 궤적 <span class="math inline">\bar{p}_{0:T}</span>에 시간 변형을 적용합니다.</li>
<li><strong>모델 기반 최적 제어 (MBOC) 및 스코어링:</strong> 변형된 모션을 추적하기 위해 Differential Dynamic Programming(DDP)을 활용한 MBOC를 수행합니다. 추적 결과는 다음 스코어링 함수 <span class="math inline">C(\alpha)</span>로 평가됩니다. <span class="math display">C(\alpha) = -d_b(p_b, \bar{p}_b) - d_E(h, \bar{h}_b) + w_c IoU(c, \bar{c})</span> 여기서 <span class="math inline">d_b</span>는 기저 위치의 L1 거리, <span class="math inline">d_E</span>는 기저 방향의 L1 거리, <span class="math inline">IoU</span>는 접촉 스케줄 일치도를 나타내는 Intersection over Union 값입니다. 스코어링 함수는 키포인트 추적, 접촉 일치뿐만 아니라 시간 매개변수의 극단적인 값을 규제하여 모방 성능을 향상시킵니다.</li>
<li><strong>베이시안 최적화:</strong> 이전 <span class="math inline">\alpha</span> 값들과 그에 해당하는 스코어 <span class="math inline">C_k</span>를 기반으로 가우시안 프로세스 회귀(Gaussian Process Regression)를 사용하여 대리 함수(surrogate function)를 피팅합니다. 이후 기대 개선(Expected Improvement, EI)이라는 획득 함수(acquisition function)를 최대화하여 다음 <span class="math inline">\alpha</span>를 샘플링합니다. 이 과정은 <span class="math inline">\alpha</span>가 수렴할 때까지 반복됩니다.</li>
</ol>
<p><strong>III. 잔여 정책 학습 (Residual Policy Learning)</strong></p>
<p>STMR 단계에서 식별된 최적의 제어 시퀀스는 시뮬레이션에서 개방 루프 제어를 통해 리타겟팅된 모션을 성공적으로 생성할 수 있습니다. 그러나 불확실성과 모델 불일치를 극복하고 실제 환경에서 모션을 견고하게 배치하기 위해서는 피드백 정책이 필요합니다. 따라서 STMR에서 얻은 개방 루프 제어 시퀀스 <span class="math inline">\ast x_{0:T_\alpha}</span>에 보정 값을 추가하는 잔여 정책 <span class="math inline">\pi</span>를 학습합니다. 이 정책은 PD 제어기와 결합하여 모터 토크 명령을 생성합니다. <span class="math display">\tau = K_p(\ast \theta + \Delta \theta - \theta) - K_d \dot{\theta}</span> 잔여 정책은 강화 학습(Reinforcement Learning, RL)으로 훈련되며, 로봇의 관절 위치, 기저 위치, 기저 방향, 키포인트 위치에 대한 추적 측정을 기반으로 보상이 정의됩니다. 시뮬레이션-실제 간극(sim-to-real gap)을 줄이기 위해 도메인 무작위화(domain randomization)와 추가 관측(예: 기저 선형/각속도, 높이)이 적용됩니다.</p>
<p><strong>실험 결과:</strong></p>
<p>시뮬레이션 및 실제 환경 실험을 통해 제안된 방법의 효과를 검증했습니다.</p>
<ul>
<li><strong>모션 추적 성능:</strong> STMR은 기존 방법들(UVM (DeepMimic), UVM (AMP), TO)에 비해 훨씬 낮은 추적 오차를 보여주며, 특히 비행 단계가 포함된 HopTurn 및 SideSteps와 같은 동적 모션에서 탁월한 성능을 보였습니다. SMR만으로는 비행 단계 모션을 처리할 수 없었습니다.</li>
<li><strong>발 제약 강제:</strong> SMR은 평균 0.34mm의 발 미끄럼과 0.998의 IoU를 달성하여 발 미끄럼을 효과적으로 제거하고 접촉 스케줄을 보존하는 데 크게 기여했습니다.</li>
<li><strong>전신 모션 재구성:</strong> STMR은 기저 움직임이 없는 키포인트 궤적으로부터 전신 모션을 성공적으로 재구성했으며, 다른 형태의 로봇에 맞게 기저 궤적을 조정하여 높은 복구율(70-80%)을 보였습니다.</li>
<li><strong>비행 단계 동적 모션 (BackFlip):</strong> TMR의 시간 최적화는 BackFlip과 같은 역동적인 모션을 성공적으로 수행하는 데 결정적인 역할을 했습니다. 시간 최적화 없이 B2 로봇은 BackFlip에 실패했지만, 시간 최적화를 통해 모션 지속 시간을 조정(B2의 경우 47% 증가)하여 성공적인 BackFlip을 가능하게 했습니다.</li>
<li><strong>실제 환경 배치:</strong> STMR로 리타겟팅된 모션은 Unitree Go1, Go2, AlienGo, B2 네 가지 다른 로봇 플랫폼에서 성공적으로 배치되었습니다. 이 로봇들은 서로 다른 치수와 물리적 특성을 가지고 있으며, STMR은 각 로봇의 특성(예: 출력 대 질량 비율)에 맞춰 모션의 공간적 및 시간적 측면을 적절히 변형하여 HopTurn 및 SideSteps와 같은 동적 모션을 정확하게 수행했습니다.</li>
<li><strong>영상으로부터의 모션 리타겟팅 및 지형 인식 리타겟팅:</strong> 잡음이 많은 비디오 키포인트 데이터와 불규칙한 지형(예: 상자 위에서의 BackFlip)에 대해서도 STMR이 성공적으로 모션을 재구성하고 동적 실현 가능성을 보장하며 실제 로봇에서 실행될 수 있음을 보여주었습니다.</li>
</ul>
<p><strong>한계 및 미래 연구:</strong> 제안된 방법은 정확한 접촉 추정에 크게 의존합니다. 부정확한 접촉 추정은 불규칙한 움직임을 초래할 수 있습니다. 또한, TMR 문제 해결에 사용된 베이시안 최적화는 고차원 공간으로 확장될 때 한계가 있습니다. 향후 연구에서는 더 발전된 접촉 추정 방법과 확장성 있는 최적화 기술을 탐색할 계획입니다.</p>
<p><strong>결론:</strong> 이 논문은 IL 과정을 안내하기 위해 운동학적으로-동역학적으로 실현 가능한 모션을 생성하는 STMR 문제를 제시합니다. STMR은 전역 참조 원점이 알려지지 않은 모션 데이터를 사용하여 자연스러운 동물 움직임의 민첩성과 표현력을 모방하는 전신 모션을 생성할 수 있도록 돕습니다. 제안된 방법은 시뮬레이션에서 뛰어난 제어 정책 학습과 정확한 모션 추적 성능을 보여주었으며, 발 미끄럼을 제거하고 접촉 스케줄을 정확하게 보존했습니다. 궁극적으로, STMR은 네 가지 실제 로봇 하드웨어 플랫폼에서 성공적으로 배치되어 일반적인 사족 보행 로봇을 위한 자연스럽고 동적인 모션 생성의 실용적인 적용 가능성을 강조했습니다.</p>
<hr>
</section>
<section id="detail-review" class="level1">
<h1>Detail Review</h1>
<blockquote class="blockquote">
<p>사족 보행 로봇의 시공간 모션 리타게팅: 논문 리뷰 및 손 로봇 적용 분석</p>
</blockquote>
<section id="연구의-독창성-시공간-아키텍처-모션-프라이어-통합-리타게팅-전략" class="level2">
<h2 class="anchored" data-anchor-id="연구의-독창성-시공간-아키텍처-모션-프라이어-통합-리타게팅-전략">연구의 독창성: 시공간 아키텍처, 모션 프라이어 통합, 리타게팅 전략</h2>
<p><strong>「Spatio-Temporal Motion Retargeting (STMR)」</strong>은 사족 보행 로봇에 동물의 움직임을 모방시키기 위한 새로운 모션 리타게팅 기법으로, <strong>공간적 및 시간적 두 단계의 아키텍처</strong>를 도입한 점이 특징입니다. 이 방법은 먼저 <strong>공간적 모션 리타게팅(SMR)</strong> 단계를 통해 원본 동작의 <strong>운동학적 적합성</strong>을 확보합니다. 구체적으로, <strong>발 미끄러짐이나 발 관통</strong>과 같은 운동학적 부조화를 제거하고 원본 동작의 <strong>접촉 시퀀스(contact schedule)</strong>를 유지하도록 발 움직임에 제약을 가함으로써, 대상 로봇의 관절 범위 내에서 <strong>키네마틱하게 실행 가능한 전체 신체 모션</strong>을 생성합니다. 다음으로 <strong>시간적 모션 리타게팅(TMR)</strong> 단계에서는 동작의 <strong>동역학적 타당성</strong>을 보장하기 위해 모션의 <strong>시간적 파라미터를 최적화</strong>합니다. 예를 들어, 점프 동작의 경우 로봇의 크기에 따라 <strong>비행(flight) 단계의 지속시간</strong>이 달라져야 하므로, TMR은 <strong>모델 기반 제어기</strong>(예: 차분 동적 프로그래밍, DDP)를 <strong>내부 프로세스</strong>로 활용하여 모션 타이밍을 조정하고 <strong>중간 공중 체공시간 등 동역학적 일관성</strong>을 확보합니다. 이러한 <strong>이단계(공간+시간) 리타게팅 전략</strong>을 통해 원본 생물체와 형태·크기가 다른 로봇이라도, <strong>운동학적·동역학적으로 실행 가능한(reference) 모션</strong>으로 변환할 수 있습니다. 이는 기존 방법들이 형태 차이는 보정하더라도 물리적으로 불가능한 동작을 생성하는 한계를 극복하고자 한 것으로, <strong>모션 프라이어</strong>(motion prior) 활용 면에서도 새로운 접근이라 할 수 있습니다. 본 논문에서 특별히 학습된 모션 프라이어(예: GAN 기반 생성기)를 직접 사용하지는 않지만, 대신 <strong>모델 기반 최적화</strong>와 <strong>참조 모션의 물리적 타당성 확보</strong>를 통해 <strong>동작 사전 지식</strong>을 통합한 효과를 냅니다. 이는 임의의 동작 데이터베이스에 한정되지 않고도 모사 학습을 유도할 수 있는 <strong>내재적 모션 프라이어</strong>를 제공하는 셈입니다. 마지막으로, 이렇게 얻어진 <strong>kino-dynamically feasible</strong> (운동학·동역학적으로 실행 가능한) 참조 모션을 토대로 <strong>잔여 학습(residual learning)</strong>을 적용한 <strong>강화학습 정책</strong>을 훈련하는 <strong>리타게팅 전략</strong>을 제시한 점도 독창적입니다. 구체적으로, <strong>참조 모션을 기본 제어 신호로 활용하고 RL 에이전트가 보정 명령만 출력하도록</strong> 함으로써, <strong>피드백 제어 정책</strong> 학습을 효과적으로 유도하고 최종적으로 <strong>실세계 로봇에 배치 가능한 제어기</strong>를 얻어낸 것입니다. 요약하면, 해당 연구의 STMR 접근법은 <strong>공간적 최적화 + 시간적 최적화 + 잔여 RL 정책</strong>으로 구성된 <strong>새로운 시공간 모션 리타게팅 프레임워크</strong>이며, 이는 기존 모션 모방 기법들의 한계를 넘어 <strong>형태 차이 극복과 물리적 실행 가능성 보장</strong>을 동시에 달성한 점에서 학술적 의의가 있습니다.</p>
</section>
<section id="방법의-강점-일반화-능력-강인성-학습-전략-및-설계" class="level2">
<h2 class="anchored" data-anchor-id="방법의-강점-일반화-능력-강인성-학습-전략-및-설계">방법의 강점: 일반화 능력, 강인성, 학습 전략 및 설계</h2>
<p>STMR 방법은 여러 측면에서 <strong>뛰어난 강점</strong>을 보였습니다. <strong>일반화 능력</strong> 측면에서, 이 기법은 <strong>서로 다른 형태와 물리 특성을 지닌 로봇들</strong>에 대해서도 적용 가능함을 보였습니다. 저자들은 크기와 질량이 서로 다른 세 종류의 사족 로봇(예: Unitree A1, Go1, AlienGo)에 대해, <strong>6가지의 상이한 난이도의 동물 모션</strong>들을 성공적으로 리타게팅 및 모방 학습시켰습니다. 그 결과 생성된 참조 모션은 <strong>접촉 타이밍을 충실히 보존</strong>하고 <strong>발 미끄러짐이 거의 제거</strong>되어, 크기가 다른 로봇이라도 원본 동작의 의미를 잃지 않도록 했습니다. 이처럼 STMR은 <strong>동작 다양성</strong>(여러 종류의 걸음걸이: 트롯, 페이스, 옆걸음, 점프회전 등)과 <strong>로봇 플랫폼 다양성</strong>에 모두 잘 대응하여, <strong>우수한 일반화 성능</strong>을 입증했습니다.</p>
<p>Robustness 측면에서도 장점을 확인할 수 있습니다. RL 정책 학습 시 <strong>잔여 정책(residual policy)</strong> 접근을 도입함으로써, <strong>기본 PD 제어기의 추종 성능에 학습 기반 보정 정책을 더하는 형태</strong>를 취했는데, 이는 <strong>학습의 안정성과 실환경 강건성</strong>을 크게 높였습니다. 구체적으로, 참조 모션을 그대로 추종하도록 하는 <strong>피드포워드 제어 신호</strong>에, RL 에이전트가 <strong>모델 불일치나 외란을 보정하는 미세 조정 신호</strong>만 더하게 함으로써, 순수 RL에 비해 <strong>훈련이 용이하고 수렴이 빠르며</strong>, 실제 로봇 적용 시에도 <strong>균형 유지 및 외란 견디기 성능</strong>이 향상되었습니다. 실제로 시뮬레이션에서는 임의의 힘으로 로봇을 밀치는 등의 <strong>도메인 랜덤화</strong>를 적용해도 정책이 잘 작동했고, 이를 통해 <strong>모델링 오차나 환경 불확실성에 대한 견디기 능력</strong>을 강화하여 실험실 밖 <strong>실세계 조건에서도 정책이 유효</strong>함을 검증했습니다. 이러한 강인성은 <strong>모델 기반 최적화로 생성된 물리적으로 타당한 참조</strong>가 있었기에 가능했으며, 결과적으로 다른 방법보다 <strong>높은 안정성으로 실제 로봇에 적용</strong>할 수 있었습니다.</p>
<p><strong>학습 전략과 구조적 설계</strong> 또한 STMR의 중요한 강점입니다. 이 방법은 <strong>오프라인 최적화(모션 리타게팅)</strong> 단계와 <strong>온라인 학습(정책 RL)</strong> 단계를 분리하여 효율을 높였습니다. 먼저 <strong>비지도 최적화</strong>를 통해 <strong>참조 모션을 사전에 보정</strong>해 둠으로써, RL 단계에서는 복잡한 동적 제약을 만족하는 모션을 <strong>이미 확보</strong>한 상태에서 학습이 시작됩니다. 이로써 RL은 보다 <strong>용이한 보상 설계</strong>(이미 물리적 타당성 확보)와 <strong>향상된 모방 효율</strong>을 보이며, 실제 실험에서도 <strong>기존 기법 대비 적은 학습으로 높은 정확도 추종</strong>을 달성했습니다. 예를 들어, 본 연구의 RL 정책은 약 5천만 스텝(약 1시간)의 훈련으로 높은 성능을 보였으며, <strong>기존 AMP 기반 정책이 수배 더 많은 학습이 필요</strong>했던 것에 비하면 효율적입니다. 또한 <strong>공간-시간 단계별로 문제를 디컴포즈</strong>한 설계는 <strong>복잡한 모션 리타게팅 문제를 해결하기 쉽게 만든 구조적 이점</strong>이 있습니다. 각각의 단계에서 <strong>기성의 알고리즘</strong>(예: IK 기반 Unit Vector 방법, DDP 기반 최적화)을 활용하여 신뢰성을 확보했고, 최종적으로 RL 제어기를 결합하는 <strong>모듈식 설계</strong>로서 각 구성요소의 역할이 명확합니다. 이러한 구조 덕분에 <strong>새 동작 추가나 다른 로봇 적용 시에도 일부 모듈 교체/재학습으로 대응 가능</strong>하며, <strong>실시간 적용</strong>을 위한 향후 확장도 모색하기 용이한 프레임워크라고 볼 수 있습니다. 정리하면, STMR의 학습전략은 <strong>최적화된 참조로 학습 가이드</strong>를 제공하고, 아키텍처 설계는 <strong>문제 복잡도 감소와 모듈화</strong>를 통해 <strong>효율성과 확장성</strong>을 모두 갖춘 점이 큰 강점입니다.</p>
</section>
<section id="잠재적-약점-제한된-상황-복잡도-및-기타-고려사항" class="level2">
<h2 class="anchored" data-anchor-id="잠재적-약점-제한된-상황-복잡도-및-기타-고려사항">잠재적 약점: 제한된 상황, 복잡도 및 기타 고려사항</h2>
<p>한편 이 연구에는 몇 가지 <strong>약점이나 제한점</strong>도 존재합니다. 첫째로, <strong>접촉 추정에 대한 의존성</strong>이 높다는 한계가 지적됩니다. STMR은 영상 등으로부터 얻은 <strong>베이스 움직임이 없는 순수 키포인트 데이터</strong>로도 모션을 재구성할 수 있다는 장점을 보여주었지만, 이를 위해서는 발의 지면 접촉 여부(접촉 스케줄)를 정확히 판단해야 합니다. 저자들에 따르면, <strong>접촉 판정의 오류</strong>가 있을 경우 비현실적인 모션(발이 갑자기 통과하거나 붕 뜨는 등)이 생성되어, 이후 전체 모션 최적화 과정에 <strong>불규칙한 동작</strong>이 전파될 위험이 있습니다. 실제로 키포인트 속도를 임계값으로 임의 thresholding 하여 접촉 여부를 결정할 경우, <strong>연속된 프레임에서 접촉단계가 불연속적으로 바뀌는 문제</strong>가 발생할 수 있고 이로 인해 <strong>로봇이 따라갈 수 없는 빠른 접촉 전환</strong>이 나타나 모방 실패로 이어질 수 있다고 지적합니다. 이를 완화하기 위해 <strong>저역 통과 필터(low-pass filter)</strong>로 접촉 신호를 <strong>평활화</strong>하였으나, 근본적으로 <strong>신뢰성 있는 접촉 추정</strong>이 보장되지 않으면 본 기법의 성능이 저하될 수 있다는 한계가 남습니다. 이러한 점은 <strong>추후 접촉 오차에 대한 강인성 향상</strong>이나 <strong>학습을 통한 접촉 추정 보정</strong> 등의 추가 연구가 필요함을 의미합니다.</p>
<p>둘째, <strong>계산 복잡도와 실시간성</strong>의 측면에서 제한이 있습니다. STMR은 <strong>모션 하나를 리타게팅하기 위해 두 단계의 최적화(운동학 IK 및 동적 최적화)와 이후 강화학습 정책 훈련</strong>까지 거치는 <strong>비용 높은 파이프라인</strong>입니다. 논문에서 명시하진 않았지만, 각 모션마다 이러한 과정을 수행해야 하므로 <strong>새로운 동작마다 상당한 오프라인 계산과 학습 시간</strong>이 필요합니다. 즉, 본 방법은 <strong>사전 준비 단계</strong>가 긴 편이며, 사람 시연을 즉석에서 바로 로봇에 모사시키는 <strong>실시간 리타게팅</strong>에는 부적합합니다. 반면 일부 기존 연구는 <strong>사전 학습된 모델</strong>이나 <strong>모션 매핑 함수</strong>를 이용하여 <strong>실시간 온라인 리타게팅</strong>을 지향하기도 하는데, STMR은 정확성과 물리적 타당성을 추구하는 대신 <strong>속도를 양보</strong>한 접근으로 볼 수 있습니다. 이로 인해 <strong>실시간 상호작용 시나리오</strong> (예: 사람이 즉흥적으로 시범을 보이는 것을 로봇이 바로 따라하는 경우)에는 사용하기 어렵고, <strong>오프라인 모션 디자인 후 배치</strong>하는 용도에 국한될 수 있습니다. 저자들도 향후 <strong>실시간 제어 및 인지 모듈과의 통합</strong>을 언급하며, 온라인 적용 가능성은 추후 연구과제로 남겨두고 있습니다.</p>
<p>셋째, <strong>범용성의 범위</strong>에 대한 한계입니다. 본 연구는 <strong>사족보행 로봇의 동물 모션 모방</strong>에 초점을 맞추었으며, 이에 최적화된 키포인트 정의(엉덩이, 허벅지, 무릎, 발 등 16개)와 제약 조건(네 발 접지 등)을 사용했습니다. 따라서 <strong>휴머노이드나 비(非)사족형 로봇</strong> 등에 동일 기법을 적용하려면 추가적인 고려가 필요합니다. 예를 들어, 인간형 로봇의 팔 동작이나 두 발 보행에는 상이한 키포인트와 접촉 방식이 있으므로, STMR의 <strong>공간적/시간적 최적화 요소를 해당 플랫폼에 맞게 조정</strong>해야 합니다. 논문에서도 STMR 개념을 <strong>다른 형태의 로봇</strong>(예: 휴머노이드)으로 <strong>확장 적용</strong>하는 방향을 제시하고 있으나, 아직 그러한 실증은 이루어지지 않았습니다. 따라서 현재로서는 <strong>사족 보행 분야</strong>에 국한된 솔루션이며, 완전히 다른 모폴로지에 대한 <strong>범용적 보장</strong>은 미지수입니다. 또한 시험된 동작들도 <strong>달리기/점프 등 보행 동작에 한정</strong>되어 있어, 이를 넘어선 <strong>복잡한 상체 동작</strong>이나 <strong>환경과의 상호작용이 많은 동작</strong>(예: 도약하여 착지, 물체 넘기기 등)에 대해서도 효과적일지는 추가 검증이 필요합니다.</p>
<p>마지막으로, <strong>모션 프라이어 vs 물리적 타당성</strong>에 관한 논의에서 오는 시사점도 있습니다. 저자들은 <strong>기존의 Adversarial Motion Prior (AMP)</strong>와 같은 기법이 <strong>물리적으로 불가능한 참조 동작도 모방 가능하게 해주는 장점이 있지만</strong>, 결국 <strong>참조 모션 자체의 물리적 불일치로 인해 최종 성능이 제한</strong>됨을 지적합니다. STMR의 결과가 AMP 대비 월등한 추종 정확도를 보인 것은, <strong>물리적으로 일관된 참조</strong>를 쓰는 것이 <strong>학습 안정성과 성능에 중요</strong>함을 보여줍니다. 다만 AMP와 같은 기법은 <strong>스타일 상의 일반화나 데이터베이스 범위 밖 움직임 생성</strong>에 강점이 있으므로, STMR처럼 <strong>엄격한 물리 최적화 vs 모션 프라이어 기반 유연성</strong> 사이에는 트레이드오프가 존재합니다. 이 논문에서는 물리적 타당성을 택했지만, <strong>향후 두 접근의 결합</strong>(예: 물리 제약을 지키면서도 모션 프라이어를 활용한 풍부한 모션 생성)도 가능할 것이며, 이는 본 연구가 직접 다루지는 않았지만 앞으로 탐구해볼 여지가 있는 부분입니다.</p>
</section>
<section id="실험-결과의-타당성과-의미-성능-검증-및-비교-분석" class="level2">
<h2 class="anchored" data-anchor-id="실험-결과의-타당성과-의미-성능-검증-및-비교-분석">실험 결과의 타당성과 의미: 성능 검증 및 비교 분석</h2>
<p>논문의 <strong>실험 결과</strong>는 제안한 방법의 <strong>유효성</strong>을 뒷받침하며, 여러 <strong>성능 지표에서의 향상</strong>을 명확히 보여줍니다. 저자들은 6가지 동물 모션(트롯 종류 2개, 페이스 2개, 옆걸음, 점프-회전 등)을 세 로봇에 걸쳐 실험하고, <strong>3가지 기존 모방학습 기법</strong>(DeepMimic, AMP, OptMimic)을 <strong>baseline</strong>으로 선정하여 비교했습니다. <strong>모션 추종 정확도</strong>는 <strong>키포인트 경로의 DTW(dynamic time warping) L1 거리</strong>로 측정되었는데, STMR 기반 정책은 <strong>모든 동작에 걸쳐 가장 낮은 오차</strong>를 기록했습니다. 평균적으로 STMR의 추종 오차는 다른 기법들에 비해 <strong>크게 감소</strong>하였으며, 특히 난이도가 높은 동작일수록 그 <strong>격차가 더 벌어지는 경향</strong>을 보였습니다. 예를 들어, <strong>가장 복잡한 “HopTurn” (제자리 점프 회전)</strong> 동작에서 STMR의 오차는 타 기법 대비 <strong>현저히 낮아</strong>, 어려운 공중 동작에서도 제안 방법이 <strong>우수한 성능</strong>을 발휘함을 보여주었습니다. 저자들은 이러한 결과를 통해 <strong>물리적으로 정제된 참조 모션</strong>을 사용한 것이 <strong>학습 성능 향상</strong>에 핵심임을 강조합니다. 키프레임 간의 시간 스케일을 늘리거나 줄이는 <strong>TMR 단계</strong>의 존재가, 특히 <strong>비행_phase가 있는 동작</strong>에서 <strong>로봇 크기에 맞는 체공시간을 부여</strong>하여 모방 성공률을 높였음을 확인한 것입니다.</p>
<p>또 다른 중요한 지표로 <strong>발 미끄러짐(foot sliding)</strong>과 <strong>접촉 일정 보존</strong>이 있습니다. <strong>발 미끄러짐</strong>은 발이 지면에 닿은 채로 미끄러지는 정도를 나타내는 문제로, 리타게팅 과정에서 운동학적 불일치가 있을 때 흔히 발생합니다. 제안된 STMR의 <strong>공간 최적화(SMR)</strong> 단계에서 발끝의 속도와 위치 제약을 걸어주었기에, 결과 모션에서는 <strong>발이 지면에 닿아있는 동안 거의 움직이지 않게</strong> 되었습니다. 표에서 알 수 있듯이, 기존 단순 스케일링 방법(단위 벡터 UV 방법)의 경우 발 미끄러짐 지표가 매우 높았지만, STMR을 거친 모션에서는 동일 상황에서 <strong>오차가 0에 수렴</strong>할 정도로 미끄러짐이 제거되었습니다 (예: AlienGo 로봇의 HopTurn 동작에서 UV 대비 STMR의 발 이동량이 44.11→1.83mm로 대폭 감소). 동시에 <strong>접촉 스케줄 보존도</strong> 크게 향상되었습니다. 이는 원본 동작과 리타게팅된 동작의 <strong>발 지면 접촉 on/off 시퀀스가 얼마나 일치하는지</strong>를 IoU(교집합/합집합)로 측정한 것인데, STMR 결과 모션은 IoU ≈ 1.0에 가까워 <strong>거의 완벽히 동일한 접촉 패턴</strong>을 구현했습니다. 반면 기본 UV 방법의 경우 IoU가 평균 0.5 이하로 떨어져 접촉 타이밍이 어긋나는 경우가 많았습니다. 이 결과는 STMR이 <strong>원본 동작의 의미적 맥락(언제 발을 디디고 떼는지)을 충실히 살려냈음</strong>을 뜻하며, 단순히 모션을 비슷하게 흉내내는 데 그치지 않고 <strong>동작의 의도와 접촉 상호작용까지 보존하는 정교한 리타게팅</strong>이 이루어졌음을 보여줍니다. 요약하면, <strong>정량적 성능 지표</strong>들(추종 오차, 발 미끄러짐, 접촉 일정 등)에서 제안 방법은 <strong>모든 기준선보다 우수</strong>했으며, 특히 <strong>동적이고 난이도 높은 동작</strong>일수록 그 <strong>이점이 두드러지는 유의미한 결과</strong>를 얻었습니다.</p>
<p><strong>비교 기법 및 분석</strong>을 살펴보면, 각 baseline과의 대비를 통해 STMR 구성 요소들의 <strong>효과</strong>를 확인할 수 있습니다. <strong>DeepMimic</strong>(Peng 등, 2018)는 별도의 모션 최적화 없이 <strong>원본 모션을 바로 RL로 추종</strong>하도록 한 경우인데, 이때 참조로 사용된 모션은 UV 스케일링으로 얻은 <strong>운동학적 변환만 거친 모션</strong>입니다. 그 결과 <strong>발 미끄러짐이나 물리 불일치</strong>가 교정되지 않아 RL 정책이 <strong>불안정한 동작</strong>을 보였고, 특히 <strong>도약 동작에서 실패하거나 큰 오차</strong>를 내는 등 한계를 보였습니다. 이는 <strong>SMR/TMR 단계 없이</strong> imitation learning만으로는 한계가 있다는 점을 뒷받침하며, STMR 대비 <strong>추종 오차가 크게 높게</strong> 나타났습니다. <strong>AMP(Adversarial Motion Prior)</strong> 기법은 <strong>학습된 모션 판별자</strong>를 통해 에이전트의 모션이 <strong>데모의 분포와 유사</strong>하도록 보상 신호를 주는 접근인데, 물리적으로 infeasible한 참조 동작도 어느 정도 모방이 가능하다는 장점이 있습니다. 본 논문 실험에서 AMP 기반 정책은 <strong>DeepMimic보다는 개선된 추종</strong>을 보였으나, <strong>STMR만큼 정확한 추종에는 이르지 못했고</strong> 특히 빠른 동작 전환이 필요한 경우 <strong>정확도가 떨어지는 경향</strong>을 보였습니다. 저자들은 <strong>STMR 대비 AMP의 성능 열세</strong>를 통해, <strong>참조 모션의 물리적 일관성</strong>이 모방 학습에 필수적임을 강조합니다. 끝으로, <strong>OptMimic</strong>(Fuchioka 등, 2023) 기법은 <strong>물리 기반 최적화로 참조 모션을 개선</strong>한 후 RL을 하는 방식으로 STMR과 유사하지만, <strong>시간적 스케일 조정이 없는</strong> 점이 다릅니다. 실험 결과 OptMimic은 DeepMimic보다는 낮은 오차를 내었지만, <strong>STMR처럼 로봇 크기에 따른 동작 속도 조절이 안 되다 보니</strong> 일부 동작에서는 <strong>추종 오차가 여전히 크게 발생</strong>했습니다. 예컨대 점프 후 착지 타이밍을 원본과 동일하게 가져가다 보니 로봇 크기가 달라 생기는 불균형을 완전히 해소하지 못한 것으로 볼 수 있습니다. 이러한 비교를 통해, <strong>STMR의 공간+시간 이중 최적화 전략이 개별 구성요소들(SMR만 또는 TMR만)보다 뛰어난 성능</strong>을 낸다는 점을 확인했습니다. 더불어 <strong>영상 기반 모션 추출 실험</strong>에서는, <strong>손으로 들고 찍은 동물 영상</strong>에서 얻은 <strong>절대 위치 없는 상대적인 관절 움직임만으로도</strong> STMR이 <strong>전체 몸체 움직임을 재구성</strong>하여 모션을 만들 수 있음을 보여주었습니다. 이는 <strong>기존 방법들이 전제하는 ‘전신 모션 캡처 데이터’ 없이도</strong> 보다 폭넓은 소스에서 모션을 가져올 수 있다는 점에서 의의가 있습니다. 결국 실험 전반을 통해, 제안한 STMR 방법은 <strong>모션 리타게팅의 품질</strong>과 이를 활용한 <strong>모방 제어 정책의 성능</strong> 양면에서 <strong>유의미한 개선</strong>을 이루었고, 제시된 기법의 <strong>실용적 가치</strong>(시뮬레이션 및 실제 로봇에서의 성공)를 입증했습니다.</p>
</section>
<section id="논문-기획-및-서술의-명확성-재현-가능성-추가적-제한사항" class="level2">
<h2 class="anchored" data-anchor-id="논문-기획-및-서술의-명확성-재현-가능성-추가적-제한사항">논문 기획 및 서술의 명확성, 재현 가능성, 추가적 제한사항</h2>
<p>이 논문은 <strong>전반적으로 명확하고 체계적인 구성</strong>으로 작성되어 있어 읽는 이로 하여금 기법과 결과를 이해하기 쉽게 합니다. 서두에서 <strong>문제의식</strong>(동물 모션의 형태 차이, 기존 기법 한계)을 분명히 제시하고, 이를 해결하기 위한 <strong>핵심 아이디어(STMR)</strong>를 도식과 함께 직관적으로 설명하였습니다. 또한 <strong>관련 연구</strong>를 <strong>모션 모방</strong>과 <strong>모션 리타게팅</strong> 두 범주로 나누어 고찰함으로써, 본 연구가 어떤 지점에서 기여하는지 맥락을 분명히 했습니다. 방법론 부분에서는 <strong>수학적 공식</strong>과 알고리즘 절차를 상세히 기술하여, 제안 기법의 구현과 작동 방식을 이해할 수 있도록 했습니다. 예컨대, 공간적 리타게팅에 쓰인 <strong>Unit Vector IK 알고리즘</strong>과 시간적 최적화에 사용된 <strong>DDP 기반 최적화</strong>를 <strong>별도의 전제(section)</strong>에서 미리 설명하고, 이후 STMR 구성에 그것들이 어떻게 활용되는지 자연스럽게 연결했습니다. 이러한 <strong>프레젠테이션의 논리적 흐름</strong> 덕분에, 독자는 제안 기법이 <strong>기존 기술의 어떤 부분을 차용하고 어디서 새로움을 제공하는지</strong> 명확히 파악할 수 있습니다.</p>
<p><strong>실험 설계</strong>와 <strong>결과 제시</strong> 역시 투명하게 이루어졌습니다. 비교 대상으로 삼은 각 기법의 설정(예: DeepMimic의 보상 설계, AMP의 판별기 구성, OptMimic의 최적화 세부사항 등)도 논문에 서술하고 있어, <strong>재현 가능성</strong>을 높였습니다. 또한 정량적 결과를 테이블과 도표로 제공하고, <strong>표준편차 등 통계</strong>도 기재하여 결과의 <strong>신뢰도</strong>를 보여줍니다. 특히 다양한 평가 지표(추종 오차, 정규화 오차, 발 미끄러짐, IoU 등)를 통해 여러 각도에서 성능을 평가한 점은, 제안 방법의 <strong>다방면 성능 우위</strong>를 뒷받침함과 동시에 <strong>독자가 성능의 의미를 종합적으로 판단</strong>하는 데 도움을 줍니다. 저자들은 <strong>실험 동영상</strong>도 웹에 공개하여 누구나 결과를 직접 확인할 수 있게 했고, <strong>소스 코드</strong> 역시 깃허브에 공개되어 있어 <strong>재현성과 실용적 활용 가능성</strong>을 높였습니다. 이러한 노력은 연구 공동체가 해당 기법을 따라 구현하거나 응용 연구를 진행하는 데 큰 도움을 줄 것으로 보입니다.</p>
<p>논문에서 <strong>한계 및 향후 개선점</strong>에 대한 언급도 찾아볼 수 있습니다. 마지막 부분에 <strong>Limitation</strong> 섹션을 두어, 접촉 추정의 불완전성으로 인한 문제와 그에 대한 임시 조치(저역필터 적용)를 솔직하게 기술하였고, 이는 앞서 지적한 바와 같이 본 기법의 현실적 제약을 독자가 이해하도록 돕습니다. 또한 <strong>미래 연구 방향</strong>으로, STMR을 휴머노이드 등 다른 형태의 로봇에 일반화하거나, 실시간 제어와 결합하는 방안을 제시하여, 해당 분야 발전에 대한 통찰을 제공하고 있습니다. 다만, 본문에서 직접 다루지 않은 몇 가지 잠재적 제한도 생각해볼 수 있습니다. 예를 들어, <strong>환경과의 상호작용</strong>이 있는 시나리오(물체를 밀면서 걷는다든지)에 대해서는 접촉 대상이 지면만 있는 현재 제약으로 충분하지 않을 수 있습니다. 또한 <strong>복잡한 다관절 시스템</strong>에서 최적화가 <strong>지역해(local optimum)</strong>에 빠질 위험이나, <strong>동적 최적화의 계산 시간</strong> 문제도 존재할 수 있지만 논문에서는 크게 다뤄지지 않았습니다. 그럼에도, 이러한 부분들은 해당 연구의 범위를 벗어나는 내용이기에 언급하지 않은 것으로 보이며, 전반적으로 논문의 서술과 정보 제공은 <strong>충실하고 명확</strong>하다고 평가됩니다. <strong>재현성</strong> 측면에서도 공개된 코드와 상세한 실험 파라미터 기술이 뒷받침하고 있으므로, 연구자들이 후속 연구를 이어가기 용이할 것입니다.</p>
</section>
<section id="손-로봇-분야로의-기술-확장-시공간-리타게팅의-응용" class="level2">
<h2 class="anchored" data-anchor-id="손-로봇-분야로의-기술-확장-시공간-리타게팅의-응용">손 로봇 분야로의 기술 확장: 시공간 리타게팅의 응용</h2>
<p>본 논문의 STMR에 담긴 <strong>모션 리타게팅 기법과 시간적 동작 조정, 운동학적 제약 처리 기술</strong>은 <strong>다관절 로봇 손</strong>의 동작 모방 및 학습에도 유용하게 응용될 수 있습니다. 사람의 섬세한 손동작을 로봇 손으로 전달하거나, 인간의 조작 기술을 로봇이 학습하도록 하는 문제는 사족 보행의 모션 모방과 유사하면서도 고유한 도전과제를 가집니다. 이하에서는 <strong>(a) 인간 손의 자세 및 동작을 로봇 손으로 리타게팅하는 경우</strong>와 <strong>(b) 그런 리타게팅 모션을 활용해 로봇 손이 물체 조작을 학습/모방하는 경우</strong>로 나누어, 해당 논문의 기법을 어떻게 적용하거나 변형할 수 있을지 논의합니다.</p>
<section id="인간-손-동작의-로봇-손으로-리타게팅-자세-및-궤적-매핑" class="level3">
<h3 class="anchored" data-anchor-id="인간-손-동작의-로봇-손으로-리타게팅-자세-및-궤적-매핑">인간 손 동작의 로봇 손으로 리타게팅 (자세 및 궤적 매핑)</h3>
<p><strong>(1) SMR</strong></p>
<p><strong>사람 손의 복잡한 관절 움직임을 로봇 손에 대응시키는 리타게팅</strong>에는 STMR의 <strong>공간적 모션 리타게팅(SMR)</strong> 개념이 핵심적으로 활용될 수 있습니다. 사람 손과 로봇 손은 <strong>형태학적 차이</strong>(모양, 크기, 관절 자유도 수) 때문에 직접적인 1:1 대응이 어려운데, 이는 사족 동물과 로봇의 다리 구조 차이와 유사한 문제입니다. STMR이 제시한 <strong>“키포인트-기반 운동학적 매핑”</strong>은 손의 경우에도 적용 가능합니다. 예를 들어, 인간 손의 <strong>관절 마디 위치나 손가락 끝점(fingertip)</strong> 등을 <strong>키포인트</strong>로 정의하고, <strong>로봇 손의 대응 키포인트</strong>와 <strong>방향 단위 벡터</strong>를 맞추는 방식으로 <strong>초기 자세를 변환</strong>할 수 있습니다. 이는 논문에서 SMR 단계에 사용한 <strong>Unit Vector 방법</strong>과 유사하게, <strong>인접 마디 간 방향을 보존</strong>하도록 로봇 손가락 관절을 설정하는 방식입니다. 이렇게 하면 로봇 손이 인간 손의 <strong>손가락 뻗는 방향, 구부리는 각도 비율</strong> 등을 크게 벗어나지 않게 되어 <strong>자연스러운 초기 모션</strong>을 얻을 수 있습니다. 이후, <strong>역기구학(IK) 풀이</strong>를 통해 로봇 손의 각 관절 각도를 찾아내면, 일단 <strong>운동학적으로 유효한 로봇 손 자세 시퀀스</strong>를 얻어낼 수 있을 것입니다. 이 과정에서 <strong>로봇 손의 관절 가동 범위 제한</strong>이나 <strong>자기 충돌</strong>(손가락 끼리 겹치지 않도록) 등의 <strong>운동학적 제약</strong>을 포함시키면, 마치 STMR의 SMR이 <strong>발 관통을 방지</strong>하듯이 <strong>손가락 관통이나 비현실적 꺾임</strong>을 방지할 수 있습니다.</p>
<p>또한 <strong>접촉 관련 제약</strong>도 중요한데, 이는 뒤에서 다룰 <strong>조작 시나리오</strong>와 겹치는 부분이 있지만, 기본적으로 <strong>사람 손의 접촉 의도</strong>(예: 어느 손가락이 어떤 지점에서 물체를 터치하는지)를 파악하여 로봇 손에서도 <strong>해당 손가락(또는 대응 손가락)이 비슷한 시점에 비슷한 위치를 접촉</strong>하도록 매핑해야 합니다. 이를 위해 <strong>손가락 끝점</strong>을 키포인트로 두고, 인간 손에서 접촉했던 시공간 정보를 <strong>로봇 손 끝점의 위치/속도 제약</strong>으로 활용하면, STMR의 <strong>접촉 스케줄 보존</strong> 개념을 구현할 수 있습니다. 예컨대, 사람 검지 손가락이 1초 시점에 물체 표면을 누르는 동작이 있었다면, 로봇 손에서도 대응되는 손가락(혹은 로봇의 검지에 해당하는 링크)이 그 시점에 그 위치를 누르도록 목표를 설정하는 식입니다. 이처럼 <strong>공간적 리타게팅 단계</strong>를 거치면, 비록 로봇 손의 형태가 달라도 <strong>인간 손 동작의 형태적 특징과 접촉 의도</strong>를 최대한 유지한 <strong>전체 손가락 궤적</strong>을 생성할 수 있습니다.</p>
<p><strong>(2) TMR</strong></p>
<p>다음으로, <strong>시간적 조정(TMR)</strong> 개념을 손 동작에 적용할 수 있습니다. 인간과 로봇 손은 <strong>관절 동작 속도, 토크 능력</strong> 등이 다르기 때문에, 동일한 시간 프로파일로 움직이면 로봇이 따라가지 못하거나 과도한 힘을 내는 문제가 발생할 수 있습니다. STMR의 TMR 단계처럼, <strong>모션의 시간축을 늘이거나 줄여서</strong> 로봇 손에 <strong>동역학적으로 적합한 속도와 가속도</strong>를 찾는 최적화를 수행할 수 있습니다. 예를 들어, 사람은 순식간에 손가락을 펼쳐 물체를 놓을 수 있지만 로봇 손은 관절 속도가 한계가 있을 때, <strong>놓는 동작의 시간을 늘려</strong> 로봇이 충분히 따라할 수 있도록 합니다. 반대로, 사람 손이 천천히 움직이는 동작이라도 로봇에 매우 가벼운 부하라면 <strong>시간을 압축</strong>해도 되겠죠. 이러한 시간 최적화는 단순히 속도의 문제뿐 아니라, <strong>동역학적 일관성</strong>과 <strong>접촉 안정성</strong>을 고려해야 합니다. 예를 들어 물체를 쥐었다 놓는 시나리오에서, 로봇 손의 각 손가락이 <strong>동시에 물체를 이격</strong>해야 물체가 예상대로 떨어지지, 타이밍이 어긋나면 물체가 미끄러질 수 있습니다. 따라서 <strong>손가락들 간의 타이밍 조율</strong>, 그리고 <strong>중력 및 물체 관성에 대응한 속도 조정</strong> 등이 포함된 <strong>시간적 파라미터 최적화</strong>가 필요합니다. 이를 위해 STMR에서 활용한 방식처럼 <strong>모델 기반 시뮬레이션</strong>을 내부에 두고, 로봇 손+물체의 물리를 고려한 <strong>최적 제어(예: DDP)</strong>를 수행할 수 있습니다. 실제 논문에서는 로봇의 도약 높이와 체공시간을 DDP로 조정했듯이, 손의 경우 <strong>물체가 들렸다 놓이는 동작</strong>을 시뮬레이션하면서 <strong>손가락 접촉력, 마찰 조건</strong> 등을 만족하는 <strong>시간 스케일</strong>을 찾는 것입니다. 이러한 동적 리타게팅을 통해, 결과 모션은 로봇 손에게 <strong>과도한 힘이나 충돌 없이</strong> 실행 가능한 <strong>물리적으로 타당한 조작 모션</strong>이 될 것입니다. 기존 연구에서도 인간→로봇 손 리타게팅 시 <strong>단순 위치 매핑은 관통 및 불안정한 접촉</strong>을 초래하기 쉽고, 이를 개선하려 <strong>에너지 함수 기반 최적화</strong>로 관통을 줄였지만 <strong>인간 동작의 풍부한 제약</strong>(손가락 간 협조 움직임 등)을 충분히 반영하지 못한 문제가 지적됩니다. STMR의 접근은 <strong>인간 손의 풍부한 kinematic 제약</strong>을 보존하면서도 <strong>물리적 안정성</strong>까지 확보하도록 두 단계 최적화를 제안하므로, 로봇 손 리타게팅에서도 이러한 <strong>일련의 공간-시간 분리 접근</strong>이 효과적일 것으로 기대됩니다.</p>
<p>이 과정에서 <strong>모션 프라이어</strong>의 통합도 고려할 수 있습니다. 사족 보행의 경우 AMP 같은 방법이 참고될 수 있었던 것처럼, 손 동작의 경우도 <strong>인간 손 움직임에 대한 사전 모델</strong>을 활용하면 도움이 됩니다. 예를 들어 <strong>인간 그립(grasp) 동작의 통계적 분포</strong>나 <strong>손가락 사이의 공조 움직임(예: 손가락의 synergy)</strong>에 대한 모션 프라이어를 사용하면, 로봇 손이 더 <strong>자연스러운 자세</strong>를 취하도록 유도할 수 있습니다. STMR에서는 명시적으로 모션 프라이어를 쓰지 않았지만, 손 로봇에 적용 시에는 이러한 <strong>인간 손의 선험적 지식</strong>(예: 대부분의 그립에서 새끼손가락은 약간 굽혀진다든지)을 최적화 과정에 반영하면 리타게팅 품질을 향상시킬 여지가 있습니다. 요컨대, <strong>공간적 정합 + 시간적 조정 + (필요시) 모션 프라이어</strong>라는 세 가지 요소를 조합하는 것은 <strong>복잡한 로봇 손 동작 리타게팅</strong>에서도 핵심 원리로 적용될 수 있습니다.</p>
</section>
<section id="시공간-모션-전이를-통한-조작-행동-학습-모방-및-제어" class="level3">
<h3 class="anchored" data-anchor-id="시공간-모션-전이를-통한-조작-행동-학습-모방-및-제어">시공간 모션 전이를 통한 조작 행동 학습 (모방 및 제어)</h3>
<p>다음으로, 이렇게 리타게팅된 인간-로봇 손의 모션 데이터를 활용하여 <strong>로봇 손의 조작 행동을 학습</strong>시키는 방안을 STMR의 기법에 비추어 논의합니다. 기본 아이디어는 STMR이 <strong>물리적으로 실행 가능한 참조 모션</strong>을 만들어 RL 정책 학습을 가이드한 것처럼, 로봇 손의 경우에도 <strong>인간 시연을 로봇 버전으로 변환한 “참조 조작 모션”</strong>을 만들어 이를 <strong>학습에 활용</strong>하는 것입니다. 사람의 조작은 섬세하고 빠른 경우가 많아, 로봇이 이를 그대로 따라하려 하면 <strong>동역학적 실패</strong>(물체를 놓쳐버리거나 떨어뜨림, 충돌 등)로 이어질 수 있습니다. 따라서 앞서 언급한 리타게팅 단계를 거쳐 <strong>로봇이 따라할 수 있는 수준으로 변환된 조작 시나리오</strong>를 준비하면, 그 다음 <strong>강화학습이나 모방 학습</strong>으로 정책을 훈련시키는 것이 훨씬 수월해집니다.</p>
<p>예를 들어, 인간이 공을 집어 다른 곳에 놓는 시범 영상을 생각해봅시다. 이를 로봇 손에 모방시키고자 할 때, 먼저 <strong>공을 집는 동작</strong>의 <strong>손가락 궤적</strong>과 <strong>접촉 타이밍</strong>을 STMR 유사 방식으로 변환해 둡니다. 이렇게 얻은 <strong>로봇 손의 기준 궤적</strong>은 공을 안정적으로 잡고 옮기기에 적합하도록 <strong>시간과 공간이 조율</strong>되어 있겠지요. 이제 RL의 <strong>보상 함수</strong>를 이 참조 궤적과의 <strong>유사도</strong>로 설계하여 로봇이 이 동작을 익히게 할 수 있습니다. 구체적으로, STMR 논문에서와 마찬가지로 <strong>관절 각도, 손목(기저) 위치와 자세, 손가락 키포인트 위치</strong> 등이 참조 모션과 가까울수록 높은 보상을 주는 식입니다. 또한 <strong>접촉 유지/해제의 시점</strong>도 보상에 넣어, 예를 들어 공을 놓을 때 너무 늦게 손가락을 펴면 벌점을 주고, 참조와 같은 타이밍에 펴면 보상을 주는 형태로 설계할 수 있습니다. 이런 식의 <strong>세밀한 모방 보상 설계</strong>는 이미 참조 모션이 <strong>물리적으로 타당</strong>하기 때문에 가능해집니다. 만약 참조 모션이 부자연스럽거나 물리를 무시했다면 (예: 사람 손 동작을 그대로 써서 로봇 손엔 무리인 속도로 손가락을 편다든지), RL 단계에서 에이전트가 따라하려다 <strong>실패하거나 학습이 불안정</strong>해질 것입니다. STMR이 강조한 바와 같이, <strong>물리적으로 일관된 레퍼런스가 있을 때 RL 모방 학습이 원활</strong>해지므로, 로봇 손의 조작 학습에서도 이 원칙이 동일하게 적용됩니다.</p>
<p><strong>Residual Learning</strong> 개념 역시 로봇 손 제어에 응용할 수 있습니다. 예를 들어, 로봇 손에 <strong>기본 오픈루프 제어기</strong>를 내장하여, 앞서 얻은 참조 궤적을 따라 <strong>손가락 관절에 PD 제어</strong>로 힘을 가하는 베이스를 깔아둡니다. 그런 다음, RL로 학습된 <strong>잔여 정책</strong>이 미세 조정 (예: “약간 더 강하게 쥐기”나 “마찰 증가를 위해 각도 보정” 등)을 출力하도록 합니다. 이는 STMR에서 <strong>참조 joint 값 + RL 출력 = 최종 토크 명령</strong>으로 구성한 것과 같은 방식입니다. 이렇게 하면 로봇 손이 물체를 쥐고 이동하는 동안, 기본 제어기는 <strong>참조 궤적대로 손가락을 움직이려</strong> 하고, RL 정책은 <strong>물체의 미끄러짐을 막기 위해 필요한 추가 힘</strong>이나 <strong>모델 오차 보정 동작</strong>을 학습하게 됩니다. 결과적으로, 처음부터 모든 것을 학습시키는 것보다 <strong>안정적이고 샘플 효율적인 학습</strong>이 가능하며, 실환경에서 <strong>예기치 않은 상황</strong>(물체 무게 변화, 마찰 계수 불확실성 등)에도 더 견고한 제어 정책을 얻을 수 있습니다. 실제 STMR 실험에서도 잔여 학습 기법이 <strong>외란에 강한 정책</strong>을 만들어냈고, 로봇 손의 미끄럼 방지나 <strong>확률적 성공률</strong> 향상에도 같은 이점을 기대할 수 있습니다.</p>
<p>또 하나 고려할 점은, <strong>환경(대상 물체)과의 상호작용</strong> 자체를 학습하는 부분입니다. 사족 로봇의 경우 지면은 고정되어 있고 발이 밀리지 않게 하는 것이 주 목표였지만, 로봇 손은 <strong>잡은 물체를 안정적으로 다루는 것</strong>이 핵심입니다. 따라서 RL 보상에는 <strong>물체의 상태 안정성</strong>(예: 물체의 목표 위치 도달 여부, 잡는 동안 떨어뜨리지 않기 등)을 포함해야 하고, 모션 리타게팅 단계에서도 <strong>물체에 가해지는 힘</strong>을 고려하는 것이 좋습니다. 이를테면, TMR 단계에서 <strong>물체의 동역학까지 포함된 시뮬레이션</strong>으로 로봇 손가락 궤적을 최적화하면, 단순히 손가락 움직임뿐 아니라 <strong>물체가 미끄러지지 않는 경로</strong>를 찾게 될 것입니다. 이와 관련하여, 최근 연구들은 <strong>사람-로봇 손 동작 매핑</strong> 시 <strong>접촉력과 상호작용까지 모사</strong>하려는 시도를 하고 있습니다. 예를 들어, <strong>접촉맵(contact map)</strong> 생성이나 <strong>이중 임계값 기반 접촉 검출</strong> 및 <strong>프레임간 접촉 상태 스무딩</strong> 같은 기법이 보고되는데, 이는 STMR에서 발 접촉을 부드럽게 처리한 것과 상통합니다. DexFlow 등 기존 연구에서는 이러한 <strong>시간적 접촉 추적 및 스무딩</strong>을 통해 손-물체 간 <strong>접촉 불안정(따닥거림)</strong>을 해소했다고 합니다. 로봇 손의 조작 모방에서도, <strong>참조 모션 생성 시 접촉 사건을 안정적으로 추출 및 매핑</strong>하고, RL 학습 시에도 <strong>접촉 유지/이탈 여부</strong>를 보상으로 다루어 <strong>접촉 패턴을 제대로 모방</strong>하도록 해야 합니다. STMR에서 <strong>발바닥 접촉 IoU</strong>로 평가를 했듯이, 손에서는 <strong>물체와 손가락의 접촉 IoU</strong>나 <strong>미끄럼 정도</strong> 등을 사용해 성능을 평가하고 최적화 방향을 설정할 수 있을 것입니다.</p>
<p>정리하면, STMR의 <strong>“참조 모션 생성 + RL 정책 학습”</strong> 투-스텝 전략은 로봇 손의 복잡한 조작 학습에도 유용한 청사진을 제공합니다. 사람의 시연 동작을 <strong>운동학적으로 투영</strong>하고 <strong>동역학적으로 재조정</strong>하여 로봇이 따라하기에 적합한 <strong>시공간 모션</strong>을 얻은 뒤, 이를 <strong>모방 목표</strong>로 삼아 <strong>정책을 학습</strong>함으로써, 단순 모방보다 <strong>안정적이고 정확한 조작 정책</strong>을 얻을 수 있습니다. 이때 <strong>잔여 학습</strong>을 포함한 제어 구조를 도입하면 학습된 정책의 <strong>실제 적용성</strong>을 높일 수 있습니다. 나아가, 필요하다면 <strong>모션 프라이어</strong>나 <strong>전문가 시演 데이터</strong>를 통합하여, 사람 손의 고차원 모션에서도 <strong>스타일과 물리 타당성을 모두 살린 학습</strong>을 추구할 수 있습니다. 이런 접근은 <strong>테이블 위의 섬세한 조립 작업</strong>, <strong>수술용 로봇의 손 동작 모방</strong>, <strong>가상현실을 통한 로봇 손 원격 조작</strong> 등 다양한 응용 분야에서 활용될 수 있을 것입니다. 실제로 <strong>실시간 원격조작(teleoperation)</strong>을 위한 연구들은 속도를 중시해 단순 매핑을 쓰는 경향이 있지만, 이는 미세 작업 시 <strong>정밀도 저하</strong>를 초래하기도 합니다. STMR에서 영감을 얻은 기법은 <strong>오프라인에서 고품질의 모션 사전학습</strong>을 통해 이러한 한계를 극복하고, 이후 <strong>실시간 제어에 접목</strong>하는 형태로도 발전할 수 있습니다.</p>
</section>
<section id="손-로봇-적용을-위한-핵심-기법-요약" class="level3">
<h3 class="anchored" data-anchor-id="손-로봇-적용을-위한-핵심-기법-요약">손 로봇 적용을 위한 핵심 기법 요약</h3>
<p>아래는 본 논문의 주요 기법들과 그 <strong>로봇 손 분야로의 전이 가능성</strong>을 정리한 표입니다. 이 표에서는 STMR에서 제안된 요소들이 로봇 손의 <strong>자세 리타게팅</strong> 및 <strong>조작 행동 학습</strong>에 어떻게 활용될 수 있는지 대비하여 나타내었습니다.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 34%">
<col style="width: 65%">
</colgroup>
<thead>
<tr class="header">
<th><strong>STMR의 핵심 기법</strong></th>
<th><strong>로봇 손 응용 방안</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>공간 모션 리타게팅 (SMR)</strong><br><em>- 키포인트 기반 자세 매핑</em><br><em>- 운동학적 제약 적용</em></td>
<td>사람 손과 로봇 손의 <strong>골격 구조 차이</strong>를 극복하기 위해, 손가락 관절 마디와 끝점을 키포인트로 정의하여 <strong>방향 벡터 보존 IK</strong>로 초기 자세 변환. 로봇 손의 <strong>관절 가동 범위</strong>와 <strong>자기 충돌</strong> 제약을 포함해 <strong>운동학적으로 실행 가능한 포즈</strong> 생성.</td>
</tr>
<tr class="even">
<td><strong>시간 모션 리타게팅 (TMR)</strong><br><em>- 모션 시퀀스의 시간 스케일 최적화</em><br><em>- 모델 기반 동적 검증</em></td>
<td>로봇 손의 <strong>속도/가속도 한계</strong>와 <strong>물체 동역학</strong>을 고려하여, 인간 동작의 <strong>타이밍을 조정</strong>. DDP 등 <strong>최적제어</strong> 기법으로 손-물체 상호작용을 시뮬레이션하면서 <strong>손가락 움직임의 속도를 늘이거나 줄여</strong> <strong>동역학적으로 안정적인</strong> 궤적 생성. 예) 무거운 물체를 들 때 더 천천히 들어올려 <strong>미끄러짐 방지</strong>.</td>
</tr>
<tr class="odd">
<td><strong>운동학/동역학 제약 통합</strong><br><em>- 접촉 유지 및 관통 방지</em><br><em>- 관절 한계 및 안정성 고려</em></td>
<td>인간 손 시연의 <strong>접촉 패턴</strong>(어느 손가락이 언제 물체를 잡고 놓는지)을 분석하여 로봇 손에서도 <strong>동일한 접촉 시퀀스</strong>를 따르도록 제약 설정. 손가락 끝의 <strong>미끄러짐 거리 최소화</strong>, <strong>관통 방지 에너지</strong> 등을 최적화 목표에 포함시켜 <strong>물리적으로 타당한 그립</strong> 구현.</td>
</tr>
<tr class="even">
<td><strong>잔여 정책 학습 (Residual RL)</strong><br><em>- 기준 모션 + 보정 액션</em><br><em>- PD 제어기 기반 안정화</em></td>
<td>리타게팅된 손 모션을 <strong>피드포워드 참조</strong>로 사용하고, RL 에이전트는 <strong>보정용 미세 제스처</strong>만 학습. 예를 들어, 참조 궤적을 따라가는 <strong>PD 제어</strong>를 기본으로, RL 정책이 물체가 미끄러지지 않도록 <strong>추가 힘</strong>을 보태는 구조. 이를 통해 <strong>학습 안정성</strong> 및 <strong>실환경 강건성</strong> 확보.</td>
</tr>
<tr class="odd">
<td><strong>모션 프라이어 및 스타일 보존</strong><br><em>- (Baseline: AMP)</em><br><em>- 인간 고유 손동작의 자연스러움 유지</em></td>
<td>필요한 경우 <strong>인간 손동작 데이터베이스</strong>로부터 학습된 <strong>모션 프라이어</strong>를 통합하여, 로봇 손의 동작이 <strong>인간처럼 자연스러운 형태</strong>를 유지하도록 유도. 예) GAN 기반 <strong>스타일 디스크리미네이터</strong>를 활용해 로봇 손의 모션이 인간 시演의 분포에 속하도록 보상 부여. 다만 <strong>물리적 타당성과의 균형</strong> 필요.</td>
</tr>
<tr class="even">
<td><strong>접촉 검출 및 시간적 스무딩</strong><br><em>- 접촉 이벤트 추정</em><br><em>- Dual-threshold &amp; smoothing</em></td>
<td>시연 데이터(예: 비디오나 센서 장갑 데이터)에서 <strong>손가락-물체 접촉 여부</strong>를 <strong>이중 임계값</strong> 등으로 검출하고, 프레임 간 <strong>접촉 상태 변화를 저역통과 필터</strong>로 평활화하여 <strong>안정적인 접촉 시퀀스</strong>를 확보. 이것을 리타게팅 및 학습에 사용해 <strong>접촉 불안정 현상</strong>(빠른 붙었다 떨어졌다 등) 제거.</td>
</tr>
</tbody>
</table>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<script src="https://utteranc.es/client.js" repo="curieuxjy/blog_comments" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Copyright 2024, Jung Yeon Lee</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/curieuxjy">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>